\chapter{Lie~Algebras}


% TODO: Every derivation of a semisimple Lie algebra is inner

% TODO: solvable Lie algebras are never ss (unless 0)

% TODO: Levi decomposition

% TODO: Lie algebra of a bilinear form
%       Show that they are in general semisimple
%       Show via root space decomposition that they are simple

% TODO: sl(n, k) simple
%       Show this by considering the root space decomposition of gl(n, k)
%       to show that the only ideals are sl(n, k) and scalar matrices
%       then use that sl_n = [gl_n, gl_n] is a characteristic ideal,
%       or because sl_n is a direct summand

% TODO: Example: Construct some strange looking Lie algebras as semidirect products.

% TODO: When is a semidirect product semisimple?





\section{Definition and Examples}


\subsection{Definition and Basic Properties}


\begin{definition}
	Let~$\glie$ be a vector space over some field~$\kf$.
	A~{\bilinear{$\kf$}} map
	\[
		[\ph, \ph]
		\colon
		\glie \times \glie
		\to
		\glie
		\glsadd{lie bracket}
	\]
	is a \defemph{Lie~bracket}\index{Lie bracket} if it satisfies the following two conditions.
	\begin{enumerate}
		\item
		$[\ph, \ph]$ is alternating, i.e.~$[x,x] = 0$ for every~$x \in \glie$.
		\item
		$[\ph, \ph]$ satisfies the \defemph{Jacobi~identity}\index{Jacobi identity!for elements}%
		\footnote{
			Named after Carl Gustav Jacob Jacobi\index{Jacobi, Carl Gustav Jacob}\index{Carl Gustav Jacob Jacobi} (1804--1851).
		}
		\[
			[x,[y,z]] + [y,[z,x]] + [z,[x,y]]
			=
			0
			\qquad
			\text{for all~$x, y, z \in \glie$.}
		\]
	\end{enumerate}
	A~{\vectorspace{$\kf$}}~$\glie$\glsadd{lie algebra} together with a Lie~bracket~$[\ph, \ph]$ on~$\glie$ is a~\defemph{\liealgebra{$\kf$}}\index{Lie algebra}.%
	\footnote{
		Named after Sophus Lie\index{Lie, Sophus}\index{Sophus Lie} (1842--1899).
	}
\end{definition}


\begin{remark}
	A Lie~bracket~$[\ph, \ph]$ on a vector space~$\glie$ is always antisymmetric\index{antisymmetric}, i.e.
	\[
		[y,x] = -[x,y]
		\qquad
		\text{for all~$x, y \in \glie$,}
	\]
	because
	\[
		0
		=
		[x+y, x+y]
		=
			\underbrace{ [x,x] }_{= 0}
		+ [x,y]
		+ [y,x]
		+ \underbrace{ [y,y] }_{= 0}
		=
		[x,y] + [y,x] \,.
	\]
\end{remark}


\begin{remark}
	The Jacobi~identity can be rewritten as
	\begin{alignat*}{2}
		[x,[y,z]]
		&=
		[[x,y],z] + [y,[x,z]]
		&\qquad
		&\text{for all~$x, y, z \in \glie$}
	\intertext{and equivalently as}
		[[x,y],z]
		&=
		[[x,z],y] + [x,[y,z]]
		&\qquad
		&\text{for all~$x, y, z \in \glie$}
	\end{alignat*}
	by using the antisymmetry of the Lie~bracket.
\end{remark}


\begin{remark}
	One can more generally define the notion of an~\liealgebra{$A$}, where~$A$ is any commutative ring.
	Such a Lie~algebra consists of an~\module{$A$}~$\glie$ together with an~\bilinear{$A$} map~$[\ph, \ph] \colon \glie \times \glie \to \glie$ that is alternating and satisfies the Jacobi~identity.
\end{remark}


\begin{definition}
	\label{definitions of an algebra}
	\leavevmode
	\begin{enumerate}
		\item
			A~\defemph{\enquote{\algebra{$\kf$}}}\index{algebra@\enquote{algebra}} is a~\vectorspace{$\kf$}~$A$ together with a bilinear map~$A \times A \to A$.
			This map is the \defemph{multiplication} of~$A$.
		\item
			A~\defemph{\algebra{$\kf$}}\index{algebra} is an~\enquote{\algebra{$\kf$}} that is both associative and unital.
	\end{enumerate}
\end{definition}


\subsection{Some First Examples of Lie~Algebras}


\begin{examples}
	\label{examples for lie algebras}
	\leavevmode
	\begin{enumerate}
		\item
			Any associative \enquote{\algebra{$\kf$}}~$A$ becomes a~{\liealgebra{$\kf$}} via
			\[
				[a,b]
				\defined
				ab - ba
				\qquad
				\text{for all~$a, b \in A$.}
			\]
			Indeed, this map~$[\ph, \ph] \colon A \times A \to A$ is bilinear and alternating, and it follows from the associativity of the multiplication of~$A$ that
			\begin{align*}
				 {}&  [a,[b,c]] + [b,[c,a]] + [c,[a,b]] \\
				={}&  [a, (bc-cb)] + [b, (ca-ac)] + [c, (ab-ba)] \\
				={}&  a(bc-cb)-(bc-cb)a + b(ca-ac) - (ca-ac)b + c(ab-ba) - (ab-ba)c \\
				={}&  \underbracket{abc}_{1}
							- \underbracket{acb}_{2}
							- \underbracket{bca}_{3}
							+ \underbracket{cba}_{4}
							+ \underbracket{bca}_{3}
							- \underbracket{bac}_{5}
							- \underbracket{cab}_{6}
							+ \underbracket{acb}_{2}
							+ \underbracket{cab}_{6}
							- \underbracket{cba}_{4}
							- \underbracket{abc}_{1}
							+ \underbracket{bac}_{5} \\
				={}&  0
			\end{align*}
			for all~$a, b, c \in A$.
			The element~$[a,b]$ of~$A$ is the \defemph{commutator}\index{commutator} of the two elements~$a$ and~$b$.
			This name stems from the fact that~$[a,b] = 0$ if and only if the elements~$a$ and~$b$ commute.

			Let us emphazise some special cases of this general construction.
			\begin{enumerate}
				\item
					The~{\algebra{$\kf$}} of~$(n \times n)$-matrices,~$\Mat(n, \kf)$, becomes a Lie~algebra via
					\[
						[A,B]
						\defined
						AB - BA
						\qquad
						\text{for all~$A, B \in \Mat(n, \kf)$.}
					\]
					This Lie~algebra is the \defemph{general linear Lie~algebra}\index{general linear Lie algebra}, and it is denoted by~$\gllie(n, \kf)$.\glsadd{general linear lie algebra matrix}
				\item
					For any~{\vectorspace{$\kf$}}~$V$ the~{\algebra{$\kf$}}~$\End_{\kf}(V)$ becomes a Lie~algebra via
					\[
						[f, g]
						\defined
						f \circ g - g \circ f
						\qquad
						\text{for all~$f, g \in \End_{\kf}(V)$.}
					\]
					This Lie~algebra is the \defemph{general linear Lie~algebra}\index{general linear Lie algebra} of~$V$, and it is denoted by~$\gllie(V)$.\glsadd{general linear lie algebra endomorphism}
			\end{enumerate}
		\item
			The \defemph{Heisenberg Lie~algebra}%
			\footnote{
				Named after Werner Heisenberg\index{Heisenberg, Werner}\index{Werner Heisenberg} (1901--1976).
			}%
			~$\heisenberglie$\glsadd{heisenberg lie algebra}\index{Heisenberg Lie algebra} consists of the~\dimensional{$(2n+1)$}~{\vectorspace{$\kf$}} with basis
			\[
				p_1 \,, \dotsc \,, p_n \,,
				\quad
				q_1 \,, \dotsc \,, q_n \,,
				\quad
				c
				\label{heisenberg basis}
			\]
			together with the Lie~bracket~$[\ph, \ph]$ that is given on these basis elements by
			\begin{itemize*}
				\item
					$[p_i, p_j] = 0$ and~$[c_i, c_j] = 0$ for all~$i, j = 1, \dotsc, n$,
				\item
					$[p_i, c], [p_i, c] = 0$ for every~$i = 1, \dotsc, n$,
				\item
					$[p_i, q_j] = \delta_{ij} c$ for all~$i,j = 1, \dotsc, n$.
			\end{itemize*}
			In \cref{examples for representations} we will realize~$\heisenberglie$ as a Lie~subalgebra of~$\gllie(V)$ for a suitable~\vectorspace{$\kf$}~$V$.
			This will in particular show that~$\heisenberglie$ is indeed a Lie~algebra.
	\end{enumerate}
\end{examples}


\begin{remark}[Pre-Lie~algebras]
	Let~$A$ be an~\enquote{\algebra{$\kf$}}.
	Even if we don’t require the multiplication of~$A$ to be associative, we can still define a bilinear bracket~$[\ph, \ph]$ on~$A$ via
	\[
		[a,b]
		\defined
		ab-ba
		\qquad
		\text{for all~$a, b \in A$.}
	\]
	This bracket~$[\ph, \ph]$ is alternating.
	We have seen in \cref{examples for lie algebras} that it satisfies the Jacobi~identity if the multiplication of~$A$ is associative, and is then a Lie~bracket.
	But the converse does not hold true:
	it may happen that~$[\ph, \ph]$ is a Lie~bracket even though~$A$ is not associative.
	
	One important example of this are \defemph{pre-Lie~algebras}\index{pre-Lie algebra}:
	We say that~$A$ is a pre-Lie~algebra if its multiplication satisfies the condition
	\begin{equation}
		\label{abstract equation for pre-lie algebra}
		[l_a, l_b]
		=
		l_{[a,b]}
		\qquad
		\text{for all~$a, b \in A$,}
	\end{equation}
	where the left hand side is the endomorphism commutator~$[l_a, l_b] = l_a l_b - l_b l_a$, and where we denote for every element~$a$ of~$A$ by~$l_a$ the left multiplication with~$a$, i.e. the map
	\[
		l_a
		\colon
		A
		\to
		A \,,
		\quad
		x
		\mapsto
		ax \,.
	\]
	Writing out the condition~\eqref{abstract equation for pre-lie algebra} yields the equivalent condition
	\begin{alignat}{2}
		\label{pre lie algebra condition written out}
		a(bc) - b(ac)
		&=
		(ab-ba)c
		&
		\qquad
		&\text{for all~$a, b, c \in A$,}
	\intertext{or equivalently the condition}
		a(bc) - (ab)c
		&=
		b(ac) - (ba)c
		&
		\qquad
		&\text{for all~$a, b, c \in A$.}
		\notag
	\end{alignat}
	If~$A$ is a pre-Lie~algebra, then the resulting commutator bracket~$[\ph, \ph]$ on~$A$ is still a Lie~bracket, even if~$A$ itself is not associative.
	Indeed, the bracket~$[\ph, \ph]$ is alternating and it follows from the characterization~\eqref{pre lie algebra condition written out} of a pre-Lie~algebra that it also satisfies the Jacobi~identity, because
	\begin{align*}
		{}&
		[a, [b,c] ] + [b, [c, a]] + [c, [a, b]]
		\\
		={}&
		a (bc - cb) - (bc - cb) a
		+ b (ca - ac) - (ca - ac) b
		+ c (ab - ba) - (ab - ba) c
		\\
		={}&
		a (bc) - a (cb) - (bc - cb) a
		+ b (ca) - b (ac) - (ca - ac) b
		+ c (ab) - c (ba) - (ab - ba) c
		\\
		={}&
		\underbracket{a (bc)}_{1}
		- \underbracket{a (cb)}_{2}
		- \underbracket{b (ca)}_{3}
		- \underbracket{c (ba)}_{4}
		+ \underbracket{b (ca)}_{3}
		- \underbracket{b (ac)}_{5}
		- \underbracket{c (ab)}_{6}
		- \underbracket{a (cb)}_{2}
		+ \underbracket{c (ab)}_{6}
		- \underbracket{c (ba)}_{4}
		- \underbracket{a (bc)}_{1}
		- \underbracket{b (ac)}_{5}
		\\
		={}&
		0
	\end{align*}
	for all~$a, b, c \in A$.

	Every associative \enquote{algebra} is in particular a pre-Lie~algebra, and thus we see that the Lie~algebra structure on an associative \enquote{algebra} actually comes from its pre-Lie~algebra structure.
	The situation is hence as follows:
	\[
		\text{associative \enquote{algebra}}
		\to
		\text{pre-Lie~algebra}
		\to
		\text{Lie~algebra}
	\]
 Pre-Lie~algebras were first introduced by Gerstenhaber%
 \footnote{
	 Murray Gerstenhaber\index{Gerstenhaber, Murray}\index{Murray Gerstenhaber} (b. 1927).
 }
 and we refer to~\cite{gerstenhaber_cohomology_of_associative_ring} to see this concept in action.
\end{remark}


\subsection{Lie~subalgebras, Lie~ideals and Commutator Spaces}


\begin{definition}
	Let~$\glie$ be a~{\liealgebra{$\kf$}}.
	\begin{enumerate}
		\item
			A \defemph{Lie~subalgebra}\index{Lie subalgebra}\index{subalgebra} of~$\glie$ is a~{\linear{$\kf$}} subspace~$\hlie$ of~$\glie$ such that
			\begin{alignat*}{2}
				[x,y] &\in \hlie
				&\qquad
				&\text{for all~$x, y \in \hlie$.}
		\intertext{
		\item
			A \defemph{Lie~ideal}\index{Lie ideal} of~$\glie$, or simply~\defemph{ideal}\index{ideal} of~$\glie$ is a~{\linear{$\kf$}} subspace~$I$ of~$\glie$ such that
			}
				[x,y] &\in I
				&\qquad
				&\text{for all~$x \in \glie$,~$y \in I$.}
			\end{alignat*}
	\end{enumerate}
\end{definition}


\begin{remark}
	\label{on the notion of ideals}
	Let~$\glie$ be a Lie~algebra.
	\begin{enumerate}
		\item
			It is not necessary to distinguish between left ideals, right ideals and two-sided ideals of~$\glie$ (as one might be used to from ring theory) because the Lie~bracket of~$\glie$ is antisymmetric.
		\item
			Some people use the notation~$I \subideal \glie$ to express that~$I$ is an ideal of~$\glie$.
			We will refrain from doing so, but still want the reader to be aware of this notation.
		\item
			Every ideal of~$\glie$ is in particular a Lie~subalgebra of~$\glie$.
			This is different to the setting of rings%
			\footnote{
				We consider only unital rings, unless otherwise specified.
			}, where a proper ideal is never a subring.
			Lie~algebras do instead behave more like groups, where a normal subgroup is in particular a subgroup.
	\end{enumerate}
\end{remark}


\begin{remark}
	Let~$\glie$ be a Lie~algebra.
	Every Lie~subalgebra~$\hlie$ of~$\glie$ becomes a Lie~algebra in its own right by restricting the Lie~bracket of~$\glie$ to~$\hlie$.
	It follows in particular that every ideal of~$\glie$ is again a Lie~algebra in its own right.
	(This is different to the situation in ring theory, where the only ideal that is also a subring is the ring itself.)
\end{remark}


\begin{definition}
	A~\liealgebra{$\kf$}~$\glie$ is~\defemph{linear}\index{linear Lie algebra} if it is a Lie~subalgebra of~$\gllie(V)$ for some finite-dimensional~\vectorspace{$\kf$}~$V$, or a Lie~subalgebra of~$\gllie(n, \kf)$ for some natural number~$n$.
\end{definition}


\begin{recall}
	For calculations in~$\gllie(n, \kf)$ it is often useful to remember the identity
	\begin{equation}
		\label{product of basis matrices}
		E_{ij} E_{kl}
		=
		\begin{cases*}
			E_{il}  & if~$j = k$, \\
			0       & otherwise,
		\end{cases*}
	\end{equation}
	where the matrices~$E_{ij}$\glsadd{standard basis matrix} with~$i,j = 1, \dotsc, n$ are the standard basis matrices\index{standard basis matrices} of~$\gllie(n, \kf)$.
	One may think about the matrix~$E_{ij}$ as \enquote{going from~$j$ to~$i$}.
	The composition~$E_{ij} E_{kl}$ does then \enquote{go from~$l$ to~$i$} if the positions~$j$ and~$k$ match, and if they don’t fit, then this composition vanishes.
	
	This intuition can be formalized by observing that
	\[
		E_{ij} e_k
		=
		\begin{cases*}
			e_i & if~$j = k$, \\
			0   & otherwise,
		\end{cases*}
	\]
	where~$e_1, \dotsc, e_n$\glsadd{standard basis vector} denotes the standard basis vectors\index{standard basis vectors} of~$\kf^n$.
	The above formula tells us that the matrix~$E_{ij}$ maps one of the standard basis vectors (namely~$e_j$) to another standard basis vector (namely~$e_i$), but filters out all other standard basis vectors.
	Composing two standard basis matrices therefore gives the desired result.

	It follows from the identity~\eqref{product of basis matrices} that in particular
	\[
		[ E_{ij}, E_{kl} ]
		=
		E_{ij} E_{kl} - E_{kl} E_{ij}
		=
		\delta_{jk} E_{il} - \delta_{il} E_{kj}
	\]
	for all~$i, j, k, l = 1, \dotsc, n$.
\end{recall}


\begin{examples}[Linear Lie~algebras]
	\label{examples for linear lie algebras}
	\leavevmode
	\begin{enumerate}
		\item
			The two primordial examples for a linear~\liealgebra{$\kf$} are the general linear Lie~algebras~$\gllie(V)$ for some finite-dimensional~\vectorspace{$\kf$}~$V$ and~$\gllie(n, \kf)$ for some natural number~$n$.
		\item
			The linear subspace
			\[
				\sllie(n, \kf)
				\defined
				\{
					A \in \gllie(n, \kf)
				\suchthat
					\tr(A) = 0
				\}
				\glsadd{special linear lie algebra matrices}
			\]
			of~$\gllie(n, \kf)$ is actually an ideal of~$\gllie(n, \kf)$, as we will see in \cref{examples of commutator ideals}.
			The Lie~algebra~$\sllie(n, \kf)$ is the \defemph{special linear Lie~algebra}\index{special linear Lie algebra}.
		\item
			Let~$V$ be a finite-dimensional vector space.
			The linear subspace
			\[
				\sllie(V)
				\defined
				\{
					f \in \gllie(V)
				\suchthat
					\tr(f) = 0
				\}
				\glsadd{special linear lie algebra endomorphism}
			\]
			is an ideal of~$\gllie(V)$.
			This Lie~algebra is the \defemph{special linear Lie~algebra}\index{special linear Lie algebra} of~$V$.
		\item
			The set of upper triangular matrices\index{upper triangular matrices}, given by
			\[
				\trianglie(n, \kf)
				\defined
				\left\{
					\begin{pmatrix}
							a_{11}
						& \cdots
						& \cdots
						& a_{1n}
						\\
							{}
						& \ddots
						& {}
						& \vdots
						\\
							{}
						& {}
						& \ddots
						& \vdots
						\\
							{}
						& {}
						& {}
						& a_{nn}
					\end{pmatrix}
				\suchthat*
					\text{$a_{ij} \in \kf$ for all~$1 \leq i \leq j \leq n$}
				\right\} \,,
				\glsadd{upper triangular lie algebra}
			\]
			is a Lie~subalgebra of~$\gllie(n, \kf)$.
			This holds because the set~$\trianglie(n, \kf)$ is a~{\subalgebra{$\kf$}} of~$\Mat(n, \kf)$, and hence closed under the commutator bracket~$[A,B] = AB - BA$.
			A basis of~$\trianglie(n, \kf)$ is given by the matrices~$E_{ij}$ with~$i \leq j$.

		\item
			The set of strictly upper triangular matrices\index{strictly upper triangular matrices}
			\[
				\upperlie(n, \kf)
				\defined
				\left\{
					\begin{pmatrix}
							0
						& a_{12}
						& \cdots
						& a_{1n}
						\\
							{}
						& \ddots
						& \ddots
						& \vdots
						\\
							{}
						& {}
						& \ddots
						& a_{n-1,n}
						\\
							{}
						& {}
						& {}
						& 0
					\end{pmatrix}
				\suchthat*
					\text{$a_{ij} \in \kf$ for all~$1 \leq i < j \leq n$}
				\right\}
				\glsadd{strictly upper triangular lie algebra}
			\]
			is an ideal of~$\trianglie(n, \kf)$, as we will see in \cref{examples of commutator ideals}.
			A basis of~$\upperlie(n, \kf)$ is given by the matrices~$E_{ij}$ with~$i < j$.
		\item
			The set of diagonal matrices\index{diagonal matrices}
			\[
				\diaglie(n, \kf)
				=
				\left\{
					\begin{pmatrix}
							d_1
						& {}
						& {}
						\\
							{}
						& \ddots
						& {}
						\\
							{}
						& {}
						& d_n
					\end{pmatrix}
				\suchthat*
					d_1, \dotsc, d_n \in \kf
				\right\}
				\glsadd{diagonal lie algebra}
			\]
			is an~{\dimensional{$n$}} Lie~subalgebra of~$\gllie(n, \kf)$.
			A basis of~$\diaglie(n, \kf)$ is given by the matrices~$E_{ii}$ with~$i = 1, \dotsc, n$.
		\item
			The linear subspace
			\[
				\afflie(n, \kf)
				\defined
				\begin{pmatrix}
					\gllie(n, \kf)  & \kf^n \\
					0               & 0
				\end{pmatrix}
				=
				\left\{
					\begin{pmatrix}
						A & a \\
						0 & 0
					\end{pmatrix}
				\suchthat*
				\begin{array}{@{}c@{}}
						A \in \gllie(n, \kf), \\
						a \in \kf^n
					\end{array}
				\right\}
				\glsadd{affine transformation lie algebra}
			\]
			of~$\gllie(n+1, \kf)$ is a Lie~subalgebra of~$\gllie(n+1, \kf)$.
			Indeed, we have
			\[
				\begin{pmatrix}
					A & a \\
					0 & 0
				\end{pmatrix}
				\begin{pmatrix}
					B & b \\
					0 & 0
				\end{pmatrix}
				=
				\begin{pmatrix}
					A B & A b \\
					0   & 0
				\end{pmatrix}
			\]
			for all~$A, B \in \gllie(n, \kf)$ and~$a, b \in \kf$, and thus
			\[
				\Biggl[
					\begin{pmatrix}
						A & a \\
						0 & 0
					\end{pmatrix}
					,
					\begin{pmatrix}
						B & b \\
						0 & 0
					\end{pmatrix}
				\Biggr]
				=
				\begin{pmatrix}
					[A, B]  & A b - B a \\
					0       & 0
				\end{pmatrix} \,.
			\]
			This commutator is again contained in~$\afflie(n, \kf)$.
			This Lie~algebra~$\afflie(n, \kf)$ is the \defemph{Lie~algebra of affine transformations of~$\kf^n$}\index{affine transformations}.
	\end{enumerate}
\end{examples}


% TODO: Remark about the associated groups.


\begin{definition}
	Let~$\glie$ be a~\liealgebra{$\kf$} and let~$X$ and~$Y$ be two subsets of~$\glie$.
	The linear subspace of~$\glie$ given by
	\[
		[X,Y]
		\defined
		\gen{
			[x,y]
		\suchthat
			x \in X,
			y \in Y
		}_{\kf}
		\glsadd{commutator space}
	\]
	is the \defemph{commutator space}\index{commutator space} of~$X$ and~$Y$.
\end{definition}


\begin{remark}
	Let~$\glie$ be a Lie~algebra.
	\begin{enumerate}
		\item
			For any two subsets~$X$ and~$Y$ of~$\glie$ we find that
			\[
				[X,Y] = -[Y,X] = [Y,X]
			\]
			because the Lie~bracket of~$\glie$ is anti-symmetric.
		\item
			For any two subsets~$X$ and~$Y$ of~$\glie$ we have
			\[
				[X, Y]
				=
				[ \gen{X}_{\kf}, \gen{Y}_{\kf} ] \,.
			\]
			To understand the commutator space~$[X, Y]$ we can therefore often assume that~$X$ and~$Y$ are linear subspace of~$\glie$.
		\item
			For every collection~$X_\lambda$ with~$\lambda \in \Lambda$ of subsets of~$\glie$ and every subset~$Y$ of~$\glie$ we have
			\[
				\left[ \sum_{\lambda \in \Lambda} X_\lambda, Y \right]
				=
				\sum_{\lambda \in \Lambda} [ X_\lambda, Y ]
				\qquad\text{and}\qquad
				\left[ \bigcap_{\lambda \in \Lambda} X_\lambda, Y \right]
				\subseteq
				\bigcap_{\lambda \in \Lambda} [ X_\lambda, Y ] \,.
			\]
		\item
			For any three subsets~$X$,~$Y$, and~$Z$ of~$\glie$ it follows from the Jacobi~identity\index{Jacobi identity!for commutator spaces} that
			\begin{align*}
				[X, [Y, Z]]
				&\subseteq
				[[X, Y], Z] + [Y, [X, Z]]
			\shortintertext{as well as}
				[[X, Y], Z]
				&\subseteq
				[[X, Z], Y] + [X, [Y, Z]] \,.
			\end{align*}
	\end{enumerate}
	We will sometimes use these identities to simplify some calculations.
\end{remark}


\begin{proposition}[Lie~subalgebras and ideals via commutator spaces]
	Let~$\glie$ be a Lie~algebra.
	\begin{enumerate}
		\item
			A linear subspace~$\hlie$ of~$\glie$ is a Lie~subalgebra of~$\glie$ if and only if the commutator subspace~$[\hlie, \hlie]$ is again contained in~$\hlie$.
		\item
			A linear subspace~$I$ of~$\glie$ is an ideal of~$\glie$ if and only if the commutator subspace~$[\glie, I]$ is again contained in~$I$.
		\qed
	\end{enumerate}
\end{proposition}


\begin{proposition}[New Lie~subalgebras from old ones]
	Let~$\glie$ be a Lie~algebra.
	\begin{enumerate}
		\item
			Let~$\hlie_\lambda$ with~$\lambda \in \Lambda$ be a collection of Lie~subalgebras of~$\glie$.
			The intersection~$\bigcap_{\lambda \in \Lambda} \hlie_\lambda$\index{intersection!of Lie subalgebras} is again a Lie~subalgebra of~$\glie$.
		\item
			Let~$\hlie$ be a Lie~subalgebra of~$\glie$ and let~$I$ be an ideal of~$\glie$.
			The sum~$\hlie + I$\index{sum!of Lie subalgebra and ideal} is again an ideal of~$\glie$.
	\end{enumerate}
\end{proposition}


\begin{proof}
	\leavevmode
	\begin{enumerate}
		\item
			We have
			\[
				\left[
					\bigcap_{\lambda \in \Lambda} \glie_\lambda,
					\bigcap_{\lambda \in \Lambda} \glie_\lambda
				\right]
				\subseteq
				\bigcap_{\lambda, \mu \in \Lambda}
				[\glie_\lambda, \glie_\mu]
				\subseteq
				\bigcap_{\substack{\lambda, \mu \in \Lambda \\ \lambda = \mu}}
				[\glie_\lambda, \glie_\mu]
				=
				\bigcap_{\lambda \in \Lambda}
				[\glie_\lambda, \glie_\lambda]
				\subseteq
				\bigcap_{\lambda \in \Lambda}
				\glie_\lambda \,,
			\]
			which proves the assertion.
		\item
			We have
			\[
				[\hlie + I, \hlie + I]
				\subseteq
				[\hlie, \hlie] + [\hlie, I] + [I, \hlie] + [I, I]
				\subseteq
				\hlie + I + I + \hlie
				=
				\hlie + I \,,
			\]
			which proves the assertion.
		\qedhere
	\end{enumerate}
\end{proof}


\begin{warning}
	Let~$\glie$ be a Lie~algebra.
	\begin{enumerate}
		\item
			Given a Lie~subalgebra~$\hlie$ of~$\glie$ and an ideal~$I$ of~$\glie$, their commutator space~$[\hlie, I]$\index{commutator space!of Lie subalgebra and ideal} is not necessarily again a Lie~subalgebra of~$\glie$.

			Let, for example,~$\glie$ be the general linear Lie~algebra~$\gllie(n, \kf)$ for some~$n \geq 2$, let~$\hlie$ be the Lie~subalgebra of~$\glie$ of diagonal matrices~$\diaglie(n, \kf)$, and let~$I$ be~$\glie$ itself.
			Then
			\[
				[\hlie, I]
				=
				\left\{
				  \begin{pmatrix}
						    &         & a_1 \\
						    & \iddots &     \\
						a_n &         &
				  \end{pmatrix}
				\suchthat*
				  a_1, \dotsc, a_n \in \kf
				\right\} \,.
			\]
			(This can be seen for cheap from the upcoming \cref{background on diagonal matrices}.)
			We find in particular that the matrices~$E_{1n}$ and~$E_{n1}$ are contained in~$[\hlie, I]$, but that their commutator~$[E_{1n}, E_{n1}] = E_{11} - E_{nn}$ is not.
		\item
			Given two Lie~subalgebras~$\hlie$ and~$\klie$ of~$\glie$, their sum~$\hlie + \klie$\index{sum!of Lie subalgebras} is not necessarily a Lie~subalgebra of~$\glie$ again.

			Indeed, let us consider thie Lie~algebra~$\glie = \gllie(n, \kf)$ for some~$n \geq 2$.
			Let~$\hlie$ be the Lie~subalgebra of strictly upper triangular matrices -- i.e.~$\upperlie(n, \kf)$, and let~$\klie$ be the Lie~subalgebra of strictly lower triangular matrices -- i.e.~$\upperlie(n, \kf)^\trans$.
			The sum~$\hlie + \klie$ consistst of all those matrices in~$\glie$ whose diagonal entries vanish.
			It is in particular the cases that both~$E_{1n}$ and~$E_{n1}$ are contained in~$\hlie + \klie$ because~$n \geq 2$.
			But their commutator is given by
			\[
				[E_{1n}, E_{n1}]
				=
				E_{1n} E_{n1} - E_{n1} E_{1n}
				=
				E_{11} - E_{nn} \,,
			\]
			which is a nonzero diagonal matrix because~$n \geq 2$.
			We find that~$[E_{1n}, E_{n1}]$ is not again contained in~$\hlie + \klie$, whence~$\hlie + \klie$ is not again a Lie~subalgebra of~$\glie$.
	\end{enumerate}
\end{warning}


\begin{proposition}[New ideals from old ones]
	\label{construction of new ideals}
	Let~$\glie$ be a Lie~algebra.
	\begin{enumerate}
		\item
		Let~$I_\lambda$ with~$\lambda \in \Lambda$ be a collection of ideals of~$\glie$.
		Both the intersection~$\bigcap_{\lambda \in \Lambda} I_\lambda$\index{intersection!of ideals} and the sum~$\sum_{\lambda \in \Lambda} I_\lambda$\index{sum!of ideals} are again ideals of~$\glie$.
		\item
		Let~$I$ and~$J$ be two ideals of~$\glie$.
		Their commutator space~$[I,J]$\index{commutator space!of ideals} is again an ideal of~$\glie$.
	\end{enumerate}
\end{proposition}


\begin{proof}
	\leavevmode
	\begin{enumerate}
		\item
			We have~%
			$
				[ \glie, \sum_{\lambda \in \Lambda} I_\lambda ]
				=
				\sum_{\lambda \in \Lambda} [ \glie, I_\lambda ]
				\subseteq
				\sum_{\lambda \in \Lambda} I_\lambda
			$
			and~%
			$
				[ \glie, \bigcap_{\lambda \in \Lambda} I_\lambda ]
				\subseteq
				\bigcap_{\lambda \in \Lambda} [ \glie, I_\lambda ]
				\subseteq
				\bigcap_{\lambda \in \Lambda} I_\lambda
			$.
		\item
			We have
			$
				[ \glie, [I, J] ]
				\subseteq
				[ [\glie, I], J] + [ I, [\glie, J]]
				\subseteq
				[I, J] + [I, J]
				=
				[I, J]
			$
			by the Jacobi~identity.
	 \qedhere
 \end{enumerate}
\end{proof}


\begin{example}
	Any Lie~algebra~$\glie$ is an ideal of itself.
	It thus follows from \cref{construction of new ideals} that the commutator space
	\[
		[\glie, \glie]
		=
		\gen{ [x,y] \suchthat x, y \in \glie }_{\kf}
	\]
	is again an ideal of~$\glie$.
\end{example}


\begin{definition}
	Let~$\glie$ be a Lie~algebra.
	The ideal~$[ \glie, \glie ]$ of~$\glie$ is the \defemph{commutator ideal}\index{commutator ideal} of~$\glie$, or the \defemph{derived Lie~algebra}\index{derived Lie algebra} of~$\glie$.
\end{definition}


\begin{example}
	\label{examples of commutator ideals}
	\leavevmode
	\begin{enumerate}
		\item
			Let~$\heisenberglie$ be the Heisenberg Lie~algebra from \cref{examples for lie algebras}.
			The commutator ideal of~$\heisenberglie$ is one-dimensional and spanned by the basis element~$c$.
		\item
			The commutator ideal of the general linear Lie~algebra~$\gllie(n, \kf)$ is the special linear Lie~algebra~$\sllie(n, \kf)$\index{special linear Lie algebra}.
			Indeed, we have for any two matrices~$A$ and~$B$ in~$\gllie(n, \kf)$ that
			\[
				\tr(AB) = \tr(BA)
			\]
			and therefore
			\[
					\tr( [A,B] )
				= \tr(AB-BA)
				= \tr(AB) - \tr(BA)
				= \tr(AB) - \tr(AB)
				= 0  \,.
			\]
			This shows that the commutator ideal of~$\gllie(n, \kf)$ is contained~$\sllie(n, \kf)$.
			We observe on the other hand that~$\sllie(n, \kf)$ has a basis given by the matrices~$E_{ij}$ for~$i,j = 1, \dotsc, n$ and~$i \neq j$, together with the matrices~$E_{ii} - E_{i+1,i+1}$ for~$i = 2, \dotsc, n$.
			Each of these matrices is a commutator, namely
			\[
				[E_{ij}, E_{jj}]
				=
				E_{ij} E_{jj} - \underbrace{ E_{jj} E_{ij} }_{=0}
				=
				E_{ij}
			\]
			for all~$i, j = 1, \dotsc, n$ with~$i \neq j$, and
			\[
				[E_{i,i+1}, E_{i+1,i}]
				=
				E_{i,i+1} E_{i+1,i} - E_{i+1,i} E_{i,i+1}
				=
				E_{ii} - E_{i+1,i+1}
			\]
			for all~$i = 2, \dotsc, n$.
			This shows that~$\sllie(n, \kf)$ is contained in the commutator ideal of~$\gllie(n, \kf)$.

			We have now shown that~$\sllie(n, \kf)$ is indeed the commutator ideal of~$\gllie(n, \kf)$.
			This entails that~$\sllie(n, \kf)$ is an ideal of~$\gllie(n, \kf)$, as claimed in \cref{examples for linear lie algebras}.
		\item
			Let~$V$ be a finite-dimensional vector space.
			The commutator ideal of~$\gllie(V)$ is~$\sllie(V)$.
			% TODO: What happens if V is infinite-dimensional?
			% TODO: Reference to [sln, sln] = sln under suitable conditions.
		\item
			The commutator ideal of~$\trianglie(n, \kf)$\index{upper triangular matrices} is~$\upperlie(n, \kf)$\index{strictly upper triangular matrices}.
		
			Indeed, for any two upper triangular matrices~$A$ and~$B$ their two products~$AB$ and~$BA$ are again upper triangular, and both products have the same diagonal entries.
			The commutator~$[A,B] = AB - BA$ is therefore a strictly upper triangular matrix.
			This shows that
			\[
				[\trianglie(n, \kf), \trianglie(n, \kf)]
				\subseteq
				\upperlie(n, \kf) \,.
			\]
			We know on the other hand that~$\upperlie(n, \kf)$ has as a basis the matrices~$E_{ij}$ with~$1 \leq i < j \leq n$.
			Each of those matrices can be written as a commutator, namely as
			\[
				[E_{ii}, E_{ij}]
				=
				E_{ii} E_{ij} - \underbrace{ E_{ij} E_{ii} }_{= 0}
				=
				E_{ij} \,,
			\]
			with~$E_{ii}$ contained in~$\trianglie(n, \kf)$ and~$E_{ij}$ contained in~$\upperlie(n, \kf)$.
			This shows that
			\[
				\upperlie(n, \kf)
				\subseteq
				[\trianglie(n, \kf), \upperlie(n, \kf)] \,.
			\]
			It follows that
			\[
				[ \trianglie(n, \kf), \trianglie(n, \kf) ]
				\subseteq
				\upperlie(n, \kf)
				\subseteq
				[ \trianglie(n, \kf), \upperlie(n, \kf) ]
				\subseteq
				[ \trianglie(n, \kf), \trianglie(n, \kf) ] \,,
			\]
			and thus~$[ \trianglie(n, \kf), \trianglie(n, \kf) ] = \upperlie(n, \kf)$ as claimed.

			That~$\upperlie(n, \kf)$ is the commutator ideal of~$\trianglie(n, \kf)$ entails that~$\upperlie(n, \kf)$ is indeed an ideal in~$\trianglie(n, \kf)$, as claimed in \cref{examples for linear lie algebras}.
		\item
			The commutator ideal of~$\afflie(n, \kf)$\index{affine transformations} is given by
			\[
				\begin{pmatrix}
					\sllie(n, \kf)  & \kf^n \\
					0               & 0
				\end{pmatrix}
				=
				\Biggl\{
					\begin{pmatrix}
						A & a \\
						0 & 0
					\end{pmatrix}
				\suchthat[\Bigg]
					\begin{array}{@{}c@{}}
						A \in \sllie(n, \kf), \\
						a \in \kf^n
					\end{array}
				\Biggr\}
			\]
			To see this let us denote this linear subspace of~$\afflie(n, \kf)$ by~$C$.
			The Lie~bracket on~$\afflie(n, \kf)$ is given by
			\[
				\Biggl[
					\begin{pmatrix}
						A & a \\
						0 & 0
					\end{pmatrix}
					,
					\begin{pmatrix}
						B & b \\
						0 & 0
					\end{pmatrix}
				\Biggr]
				=
				\begin{pmatrix}
					[A, B]  & A b - B a \\
					0       & 0
				\end{pmatrix} \,.
			\]
			for all~$A, B \in \gllie(n, \kf)$ and~$a, b \in \kf^n$.
			We see from this that the term~$[A, B]$ is contained in~$\sllie(n, \kf)$.
			The commutator ideal of~$\afflie(n, \kf)$ is therefore contained in the subspace~$C$.

			We observe on the other hand that
			\begin{align*}
				[ \afflie(n, \kf), \afflie(n, \kf) ]
				&=
				\Biggl[
					\begin{pmatrix}
						\gllie(n, \kf)  & \kf^n \\
						0               & 0
					\end{pmatrix}
					,
					\begin{pmatrix}
						\gllie(n, \kf)  & \kf^n \\
						0               & 0
					\end{pmatrix}
				\Biggr]
				\\
				&\supseteq
				\Biggl[
					\begin{pmatrix}
						\gllie(n, \kf)  & 0 \\
						0               & 0
					\end{pmatrix}
					,
					\begin{pmatrix}
						\gllie(n, \kf)  & 0 \\
						0               & 0
					\end{pmatrix}
				\Biggr]
				\\
				&=
				\begin{pmatrix}
					[ \gllie(n, \kf), \gllie(n, \kf) ]  & 0  \\
					0                                   & 0
				\end{pmatrix}
				\\
				&=
				\begin{pmatrix}
					\sllie(n, \kf)  & 0 \\
					0               & 0
				\end{pmatrix} \,,
			\end{align*}
			as well as
			\[
				[ \afflie(n, \kf), \afflie(n, \kf) ]
				\supseteq
				\Biggl[
					\begin{pmatrix}
						\Id & 0 \\
						0   & 0
					\end{pmatrix}
					,
					\begin{pmatrix}
						0 & \kf^n \\
						0 & 0
					\end{pmatrix}
				\Biggr]
				=
				\begin{pmatrix}
					0 & \Id \cdot \kf^n \\
					0 & 0
				\end{pmatrix}
				=
				\begin{pmatrix}
					0 & \kf^n \\
					0 & 0
				\end{pmatrix} \,,
			\]
			and thus together
			\[
				[ \afflie(n, \kf), \afflie(n, \kf) ]
				\supseteq
				\begin{pmatrix}
					\sllie(n, \kf)  & 0 \\
					0               & 0
				\end{pmatrix}
				+
				\begin{pmatrix}
					0 & \kf^n \\
					0 & 0
				\end{pmatrix}
				=
				\begin{pmatrix}
					\sllie(n, \kf)  & \kf^n \\
					0               & 0
				\end{pmatrix}
				=
				C \,.
			\]
			This shows altogether the desired equality~$[ \afflie(n, \kf), \afflie(n, \kf) ] = C$.
	\end{enumerate}
\end{example}


\begin{definition}
	A Lie~algebra~$\glie$ is \defemph{perfect}\index{perfect Lie algebra} if it equals its commutator ideal, i.e. if~$\glie = [\glie, \glie]$.
\end{definition}


\begin{example}
	Let~$V$ be an infinite-dimensional vector space.
	Then general linear Lie~algebra~$\gllie(V)$ is perfect.
	In fact, every element of~$\gllie(V)$ is already a commutator itself.

	To prove this we note that the vector space~$V$ is isomorphic to the direct sum~$V^{\oplus \Natural_{\geq 1}}$.
	We may therefore assume that~$V = W^{\oplus \Natural_{\geq 1}}$ for some vector space~$W$.
	We can thus represent every endomorphism~$f$ of~$V$ as a matrix
	\[
		f
		\equiv
		\begingroup
		\renewcommand{\arraystretch}{1.3}
		\begin{pmatrix}
			f_{11}  & f_{12}  & f_{13}  & f_{14}  & \cdots  \\
			f_{21}  & f_{22}  & f_{23}  & f_{24}  & \cdots  \\
			f_{31}  & f_{32}  & f_{33}  & f_{34}  & \cdots  \\
			f_{41}  & f_{42}  & f_{43}  & f_{44}  & \cdots  \\
			\vdots  & \vdots  & \vdots  & \vdots  & \ddots
		\end{pmatrix} \,.
		\endgroup
	\]
	Each matrix entry~$f_{ij}$ is an endomorphism of~$W$, namely the composite~$\pi_i \circ f \circ \iota_j$, where~$\iota_j$ the inclusion from~$W$ into the~\howmanyth{$j$} direct summand of~$V$, and~$\pi_i$ the projection from~$V$ onto its~\howmanyth{$i$} direct summand.
	This matrix is pointwise column-finite, in the sense that for every element~$w$ of~$W$ and every column index~$j$ the images~$f_{ij}(w)$ vanish for all but finitely many row indices~$i$.
	Suppose conversely that we have given a family of endomorphismss~$g_{ij}$ of~$W$ with~$i, j \geq 1$ such that the resulting matrix is pointwise column-finite.
	Then this matrix describes an endomorphism~$g$ of~$V$.

	Let~$s$ be the shift endomorphism of~$V$ given by
	\[
		s( (w_1, w_2, w_3, \dotsc) )
		=
		( w_2, w_3, w_4, \dotsc )
	\]
	for all~$(w_1, w_2, w_3, \dotsc) \in V$.
	As a matrix, this endomorphism is given by
	\[
		s
		\equiv
		\begin{pmatrix}
			0 & 1 &   &   &         \\
				& 0 & 1 &   &         \\
				&   & 0 & 1 &         \\
				&   &   & 0 & \ddots  \\
				&   &   &   & \ddots
		\end{pmatrix}
	\]
	We therefore have
	\begin{align*}
		[s, f]
		&=
		s f - f s
		\\
		&\equiv
		\begin{pmatrix}
			f_{21}  & f_{22}  & f_{23}  & f_{24}  & \cdots  \\
			f_{31}  & f_{32}  & f_{33}  & f_{34}  & \cdots  \\
			f_{41}  & f_{42}  & f_{43}  & f_{44}  & \cdots  \\
			f_{51}  & f_{52}  & f_{53}  & f_{54}  & \cdots  \\
			\vdots  & \vdots  & \vdots  & \vdots  & \ddots
		\end{pmatrix}
		-
		\begin{pmatrix}
			0       & f_{11}  & f_{12}  & f_{13}  & \cdots  \\
			0       & f_{21}  & f_{22}  & f_{23}  & \cdots  \\
			0	      & f_{31}  & f_{32}  & f_{33}  & \cdots  \\
			0       & f_{41}  & f_{42}  & f_{43}  & \cdots  \\
			\vdots  & \vdots  & \vdots  & \vdots  & \ddots
		\end{pmatrix}
		\\
		&=
		\begingroup
		\renewcommand{\arraystretch}{1.5}
		\arraycolsep=8pt
		\begin{pmatrix}
			f_{21}  & f_{22} - f_{11} & f_{23} - f_{12} & f_{24} - f_{13} & \cdots  \\
			f_{31}  & f_{32} - f_{21} & f_{33} - f_{22} & f_{34} - f_{23} & \cdots  \\
			f_{41}  & f_{42} - f_{31} & f_{43} - f_{32} & f_{44} - f_{33} & \cdots  \\
			f_{51}  & f_{52} - f_{41} & f_{53} - f_{42} & f_{54} - f_{43} & \cdots  \\
			\vdots  & \vdots          & \vdots          & \vdots          & \ddots
		\end{pmatrix} \,.
		\endgroup
	\end{align*}
	Let now~$g$ be an endomorphism of~$V$.
	We can use the above explicit calculation of the commutator~$[s, f]$ to construct an endomorphism~$f$ with~$[s, f] = g$.

	Indeed:
	Starting with the first column we choose the entry~$f_{11}$ arbitrary and~$f_{i1}$ as~$g_{i-1,1}$ for every~$i \geq 2$.
	Once the entries~$f_{ij}$ are constucted for all~$i \geq 1$ and~$j = 1, \dotsc, k$, we choose the entries~$f_{1,k+1}$ arbitrary and the entry~$f_{i,k+1}$ as~$g_{i-1, j+1} + f_{i-1, j}$ for every~$i \geq 2$.
	The matrix described by these entries~$f_{ij}$ is pointwise column-finite because the matrix associated to~$g$ is pointwise column-finite.
	It follows that the entries~$f_{ij}$ describe an endomorphism~$f$ of~$V$.
	By construction, this endomorphism satisfies~$[s, f] = g$.

	We have thus shown that every endomorphism of~$V$ is a commutator (namely a commutator of the form~$[s, f]$ for some endomorphism~$f$ of~$V$).
\end{example}


\begin{question}
	In the above discussion, can we construct the inverse of~$[s, \ph]$ is a nicer way?
\end{question}




\subsection{Centralizers and the Center of a Lie~algebra}


\begin{definition}
	Let~$\glie$ be a Lie~algebra.
	\begin{enumerate}
		\item
			For every subset~$X$ of~$\glie$ its \defemph{centralizer}\index{centralizer} is the set
			\[
				\centerlie_{\glie}(X)
				\defined
				\{
					z \in \glie
				\suchthat
					\text{$[z,x] = 0$ for every~$x \in X$}
				\} \,.
				\glsadd{centralizer of subset}
			\]
		\item
			For any element~$x$ of~$\glie$ its \defemph{centralizer}\index{centralizer} is the set
			\[
				\centerlie_{\glie}(x)
				\defined
				\centerlie_{\glie}(\{x\})
				=
				\{
					z \in \glie
				\suchthat{} % don’t want \suchthat to interpret the following bracket as an optional argument
					[z,x] = 0
				\} \,.
				\glsadd{centralizer of element}
			\]
		\item
			The \defemph{center}\index{center} of~$\glie$ is the set
			\[
				\centerlie(\glie)
				\defined
				\centerlie_{\glie}(\glie)
				=
				\{
					z \in \glie
				\suchthat
					\text{$[z,x] = 0$ for every~$x \in \glie$}
				\} \,.
				\glsadd{center}
			\]
	\end{enumerate}
\end{definition}


\begin{proposition}
	\label{structure of centralizers}
	Let~$\glie$ be a Lie~algebra.
	\begin{enumerate}
		\item
			For every subset~$X$ of~$\glie$ its centralizer~$\centerlie_{\glie}(X)$ is a Lie~subalgebra of~$\glie$.
		\item
			\label{centralizer of an ideal is again an ideal}
			For every ideal~$I$ of~$\glie$ its centralizer~$\centerlie_{\glie}(I)$ is again an ideal of~$\glie$.
	\end{enumerate}
\end{proposition}


\begin{proof}
	\leavevmode
	\begin{enumerate}
		\item
			We have
			\begin{align*}
				\SwapAboveDisplaySkip
				[ [ \centerlie_{\glie}(X), \centerlie_{\glie}(X) ], X ]
				&\subseteq
				[ [ \centerlie_{\glie}(X), X ], \centerlie_{\glie}(X) ]
				+ [ \centerlie_{\glie}(X), [ \centerlie_{\glie}(X), X ] ]
				\\
				&=
				[ 0, \centerlie_{\glie}(X) ]
				+ [ \centerlie_{\glie}(X), 0 ]
				\\
				&=
				0 \,,
			\end{align*}
			which shows that the commutator subspace~$[ \centerlie_{\glie}(X), \centerlie_{\glie}(X) ]$ is again contained in~$\centerlie_{\glie}(X)$.
		\item
			We have
			\begin{align*}
				\SwapAboveDisplaySkip
				[ [\glie, \centerlie_{\glie}(I)], I ]
				&\subseteq
				[ [\glie, I], \centerlie_{\glie}(I) ]
				+ [ \glie, [ \centerlie_{\glie}(I), I] ]
				\\
				&\subseteq
				[ I, \centerlie_{\glie}(I) ]
				+ [ \glie, 0 ]
				\\
				&=
				0 + 0
				\\
				&=
				0 \,,
			\end{align*}
			which shows that the commutator space~$[\glie, \centerlie_{\glie}(I)]$ is again contained in~$\centerlie_{\glie}(I)$.
		\qedhere
	\end{enumerate}
\end{proof}
% TODO: Give alternate proofs one representations have been introduced.


\begin{corollary}
	Let~$\glie$ be a Lie~algebra.
	Its center~$\centerlie(\glie)$ is an ideal in~$\glie$.
\end{corollary}


\begin{proof}
	We apply part~\ref{centralizer of an ideal is again an ideal} of~\cref{structure of centralizers} to the special case~$I = \glie$.
\end{proof}


\begin{fluff}
	We will in the following compute some centralizers and centers.
	For linear Lie~algebras this can sometimes be done nicely with the help of diagonal matrices.
\end{fluff}


\begin{recall}
	\label{background on diagonal matrices}
	Let~$D$ be a diagonal matrix in~$\gllie(n, \kf)$ with diagonal entries~$\lambda_1, \dotsc, \lambda_n$.
	For any other matrix~$A$ in~$\gllie(n, \kf)$ the product~$DA$ results from~$A$ by multiplying for every~$i = 1, \dotsc, n$ the~\howmanyth{$i$} row of~$A$ by the scalar~$\lambda_i$.
	Similarly, the product~$AD$ results from~$A$ by multiplying for every~$j = 1, \dotsc, n$ the~\howmanyth{$j$} column of~$A$ by the scalar~$\lambda_j$.
	This means in formulae that
	\[
		(DA)_{ij}
		=
		\lambda_i A_{ij}
		\quad\text{and}\quad
		(AD)_{ij}
		=
		\lambda_j A_{ij}
	\]
	for all~$i, j = 1, \dotsc, n$.
	It follows that
	\[
		[D, A]_{ij}
		=
		(DA - AD)_{ij}
		=
		(DA)_{ij} - (AD)_{ij}
		=
		\lambda_i A_{ij} - \lambda_j A_{ij}
		=
		(\lambda_i - \lambda_j) A_{ij}
	\]
	for all~$i, j = 1, \dotsc, n$.
	We find in particular the following:
	\begin{enumerate}
		\item
			The matrices~$E_{ij}$ are eigenvector of~$\ad_{\gllie(n, \kf)}(D)$ with corresponding eigenvalues~$\lambda_i - \lambda_j$ for all~$i, j = 1, \dotsc, n$.
		\item
			The matrix~$A$ commutes with the diagonal matrix~$D$ if and only if its entry~$A_{ij}$ vanishes for all those indices~$i, j = 1, \dotsc, n$ with~$\lambda_i \neq \lambda_j$.

			Suppose that the diagonal entries of~$D$ are arranged in such a way that
			\[
				D
				=
				\diag
				(
					\underbrace{ \mu_1, \dotsc, \mu_1 }_{n_1},
					\dotsc,
					\underbrace{\mu_k, \dotsc, \mu_k}_{n_k}
				)
			\]
			where the diagonal matrices~$\mu_1, \dotsc, \mu_k$ are pairwise distinct.
			Then we can express the above condition on the commutativity with~$D$ as
			\begin{align*}
				\centerlie_{\gllie(n, \kf)}(D)
				&=
				\left\{
					\begin{pmatrix}
						A_1 &         &     \\
								& \ddots  &     \\
								&         & A_k
					\end{pmatrix}
				\suchthat*
					\text{$A_i \in \gllie(n_i, \kf)$ for all~$i = 1, \dotsc, k$}
				\right\}
				\\
				&=
				\begin{pmatrix}
					\gllie(n_1, \kf) &        &                   \\
					                 & \ddots &                   \\
					                 &        & \gllie(n_k, \kf)
				\end{pmatrix} \,.
			\end{align*}
			We want to emphasize a special case of this general calculation:
			If the diagonal entries of~$D$ are pairwise different, then it follows that every matrix that commutes with~$D$ is already diagonal itself.
	\end{enumerate}
\end{recall}


\begin{lemma}
	\label{center consists of diagonal matrices}
	Let~$\glie$ be a Lie~subalgebra of~$\gllie(n, \kf)$.
	\begin{enumerate}
		\item
			Suppose that the Lie~algebra~$\glie$ contains for any two indices~$i$,~$j$ with~$1 \leq i < j \leq n$ a diagonal matrix~$D$ with~$D_{ii} \neq D_{jj}$.
			Then the center of~$\glie$ consists of diagonal matrices.
		\item
			Suppose furthermore that the Lie~algebra~$\glie$ contains for any two indices~$i$,~$j$ with~$1 \leq i < j \leq n$ at least one of the two matrices~$E_{ij}$ or~$E_{ji}$.
			Then the center of~$\glie$ consists of scalar multiples of the identity matrix.
	\end{enumerate}
\end{lemma}


\begin{proof}
	\leavevmode
	\begin{enumerate}
		\item
			Let~$A$ be a matrix contained in the center of~$\glie$.
			There exists by assumption for any two indices~$i$,~$j$ with~$1 \leq i < j \leq n$ a diagonal matrix~$D$ in~$\glie$ with~$D_{ii} \neq D_{jj}$.
			The matrices~$A$ and~$D$ commute, whence it follows from \cref{background on diagonal matrices} that~$A_{ij} = 0$.
			This shows that~$A$ is a diagonal matrix.
		\item
			Suppose that the matrix~$E_{ij}$ is contained in~$\glie$ for some two indices~$i$,~$j$ with~$1 \leq i < j \leq n$.
			It then further follows from \cref{background on diagonal matrices} that
			\[
				0
				=
				[A, E_{ij}]
				=
				(A_{ii} - A_{jj}) E_{ij} \,,
			\]
			and thus~$A_{ii} = A_{jj}$.
			If instead~$E_{ji}$ is contained in~$\glie$ then we also find that~$A_{ii} = A_{jj}$.
			It follows overall that all diagonal entries of~$A$ are equal.
			The diagonal matrix~$A$ is hence a scalar multiple of the identity matrix.
		\qedhere
	\end{enumerate}
\end{proof}


\begin{example}
	\label{examples of centers}
	\leavevmode
	\begin{enumerate}
		\item
			It follows from \cref{center consists of diagonal matrices} that the center of~$\gllie(n, \kf)$ is spanned by the identity matrix for all~$n \geq 2$.
			This also holds for~$n = 1$ (and~$n = 0$).
		\item
			It also follows from \cref{center consists of diagonal matrices} that the center of~$\trianglie(n, \kf)$ is spanned by the identity matrix for all~$n \geq 1$.
			This assertion also holds for~$n = 1$ (and~$n = 0$).
		\item
			We will now determine the center of~$\upperlie(n, \kf)$ for all~$n \geq 0$.
			For~$n = 0$ and~$n = 1$ we have~$\upperlie(n, \kf) = 0$ and thus~$\centerlie( \upperlie(n, \kf) ) = 0$.

			We will now show that for~$n \geq 2$ the center of~$\upperlie(n, \kf)$ is spanned by the single matrix~$E_{1n}$.
			Indeed, the Lie~algebra~$\upperlie(n, \kf)$ has the matrices~$E_{ij}$ with~$1 \leq i < j \leq n$ as a basis.
			A matrix~$A$ in~$\upperlie(n, \kf)$ is therefore contained in the center of~$\upperlie(n, \kf)$ if and only if it satisfies
			\[
				[A, E_{ij}] = 0
				\qquad
				\text{for all~$1 \leq i < j \leq n$.}
			\]

			For the matrix~$E_{1n}$ we have~$E_{ij} E_{1n} = 0$ because~$j > 1$ and thus$~j \neq 1$, as well as~$E_{1n} E_{ij} = 0$ because~$i < n$ and thus~$i \neq n$.
			We therefore have
			\[
				[E_{1n}, E_{ij}]
				=
				E_{1n} E_{ij} - E_{ij} E_{1n}
				=
				0 - 0
				=
				0
			\]
			for all~$1 \leq i < j \leq n$.
			This shows that~$E_{1n}$ is indeed central in~$\upperlie(n, \kf)$.

			Suppose now on the other hand that the matrix~$A$ is central in~$\upperlie(n, \kf)$.
			We may write the matrix~$A$ as a linear combination
			\[
				A
				=
				\sum_{1 \leq i < j \leq n}
				a_{ij} E_{ij} \,.
			\]
			It follows that
			\begin{align*}
				\SwapAboveDisplaySkip
				0
				&=
				[A, E_{1k}]
				\\
				&=
				\sum_{1 \leq i < j \leq n} 
				a_{ij}
				[ E_{ij}, E_{1k} ]
				\\
				&=
				\sum_{1 \leq i < j \leq n} 
				a_{ij}
				( E_{ij} E_{1k} - E_{1k} E_{ij} )
				\\
				&=
				\sum_{1 \leq i < j \leq n} 
				a_{ij}
				( \underbrace{\delta_{j1}}_{=0} E_{ik} - \delta_{ki} E_{1j} )
				\\
				&=
				\sum_{1 \leq i < j \leq n}
				(-a_{ij}) \delta_{ki} E_{1j}
				\\
				&=
				\sum_{j = k+1}^n
				(-a_{kj}) E_{1j}
			\end{align*}
			for all~$k = 2, \dotsc, n$.
			This tells us that all coefficients~$a_{ij}$ with~$j = 2, \dotsc, n$ vanish.
			We find similarly that
			\begin{align*}
				0
				&=
				[A, E_{kn}]
				\\
				&=
				\sum_{1 \leq i < j \leq n}
				a_{ij}
				[E_{ij}, E_{kn}]
				\\
				&=
				\sum_{1 \leq i < j \leq n}
				a_{ij}
				( E_{ij} E_{kn} - E_{kn} E_{ij} )
				\\
				&=
				\sum_{1 \leq i < j \leq n}
				a_{ij}
				( \delta_{jk} E_{in} - \underbrace{\delta_{ni}}_{=0} E_{kj} )
				\\
				&=
				\sum_{1 \leq i < j \leq n}
				a_{ij} \delta_{jk} E_{in}
				\\
				&=
				\sum_{i=1}^{k-1}
				a_{ik} E_{in}
			\end{align*}
			for all~$k = 1, \dotsc, n-1$.
			This tells us that all coefficients~$a_{ij}$ with~$j = 1, \dotsc, n-1$ vanish.
			It shows altogether that~$A = a_{1n} E_{1n}$.
		\item
			We can also compute the center of~$\afflie(n, \kf)$.
			An element
			\[
				\begin{pmatrix}
					A & a \\
					0 & 0
				\end{pmatrix}
			\]
			with~$A \in \gllie(n, \kf)$ and~$a \in \kf^n$ is central in~$\afflie(n, \kf)$ if and only if
			\[
				0
				=
				\Biggl[
					\begin{pmatrix}
						A & a \\
						0 & 0
					\end{pmatrix}
					,
					\begin{pmatrix}
						B & b \\
						0 & 0
					\end{pmatrix}
				\Biggr]
				=
				\begin{pmatrix}
					[A, B]  & A b - B a \\
					0       & 0
				\end{pmatrix}
			\]
			for all~$B \in \gllie(n, \kf)$ and~$b \in \kf^n$.
			It sufficies to consider the special cases~$B = 0$ and~$b = 0$ by the bilinearity of the Lie~bracket of~$\afflie(n, \kf)$. 
			In the special case~$B = 0$ we arrive at the condition
			\[
				A b = 0
				\qquad
				\text{for all~$b \in \kf^n$,}
			\]
			and in the special case~$b = 0$ we arrive at the two additional conditions
			\[
				[A, B] = 0 \,,
				\quad
				B a = 0
				\qquad
				\text{for all~$B \in \gllie(n, \kf)$}.
			\]
			The first condition tells us that~$A = 0$, and the third condition tells us that~$a = 0$.
			We have thus shown that the center of~$\afflie(n, \kf)$ is trivial.
	\end{enumerate}
\end{example}


\begin{question}
	Is there a nice trick to compute the center of~$\upperlie(n, \kf)$?
\end{question}


\begin{definition}
	A Lie~algebra~$\glie$ is \defemph{abelian}\index{abelian} if any two elements of~$\glie$ commute, i.e. if~$[x,y] = 0$ for all~$x, y \in \glie$.
\end{definition}

\begin{proposition}

	Let~$\glie$ be a Lie~algebra.
	The following three conditions on~$\glie$ are equivalent.
	\begin{equivalenceslist}
		\item
			$\glie$ is abelian.
		\item
			$\centerlie(\glie) = \glie$.
		\item
			$[\glie, \glie] = 0$.
		\qed
	\end{equivalenceslist}
\end{proposition}


\begin{examples}
	\leavevmode
	\begin{enumerate}
		\item
			A~{\algebra{$\kf$}}~$A$ is commutative if and only if it is abelian as a Lie~algebra.
		\item
			In any Lie~algebra~$\glie$ every element~$x$ of~$\glie$ spans a {\onedimensional} abelian Lie~subalgebra of~$\glie$, given by~$\gen{x}_{\kf} = \{ \lambda x \suchthat \lambda \in \kf \}$.
		\item
			Every vector space~$\glie$ can be made into an abelian Lie~algebra is precisely one way, namely by setting~$[x, y] \defined 0$ for all~$x, y \in \glie$.
			In this sense, an abelian Lie~algebras is \enquote{the same} as a vector space.
	\end{enumerate}
\end{examples}


\begin{lemma}
	\label{center has codimension at least two for non-abelian}
	Let~$\glie$ be a non-abelian Lie~algebra.
	The codimension of~$\centerlie(\glie)$ in~$\glie$ it at least~$2$.
\end{lemma}


\begin{proof}
	Suppose otherwise that the codimension of~$\centerlie(\glie)$ in~$\glie$ is at most~$1$.
	We know that~$\centerlie(\glie)$ is a proper ideal of~$\glie$ becaus~$\glie$ is non-abelian.
	We thus find that the codimension of~$\centerlie(\glie)$ in~$\glie$ is precisely~$1$.

	Let~$x$ be some non-central element of~$\glie$.
	It follows from the above observation that
	\[
		\glie
		=
		\centerlie(\glie) \oplus \gen{x}_{\kf}
	\]
	as vector spaces.
	It follows that
	\begin{align*}
		[\glie, \glie]
		&=
		[ \centerlie(\glie) + \gen{x}_{\kf}, \centerlie(\glie) + \gen{x}_{\kf} ]
		\\
		&=
		[ \centerlie(\glie), \centerlie(\glie) ]
		+ [ \centerlie(\glie), \gen{x}_{\kf} ]
		+ [ \gen{x}_{\kf}, \centerlie(\glie) ]
		+ [ \gen{x}_{\kf}, \gen{x}_{\kf} ]
		\\
		&=
		0 + 0 + 0 + 0
		\\
		&=
		0 \,.
	\end{align*}
	But this shown that~$\glie$ is abelian -- a contradiction!
\end{proof}


\begin{remark}
	One might compare \cref{center has codimension at least two for non-abelian} and its proof to a proposition from group theory and its proof:
	If a group~$G$ is nonabelian, then the quotient~$G / {\centergroup(G)}$ is not cyclic.
\end{remark}


\begin{warning}
	Let~$\glie$ be a Lie~algebra.
	The reader who is already familiar with quotient Lie~algebras -- which we will introduce in \cref{definition of quotient representation} -- may wonder about a possible generalization of \cref{center has codimension at least two for non-abelian}:
	if the quotient~$\glie / {\centerlie(\glie)}$ is abelian, then does it follow that~$\glie$ is abelian?

	The answer to this question is no.
	Indeed, one might consider for~$\glie$ the Lie~algebra~$\upperlie(3, \kf)$.
	We have seen in \cref{examples of centers} that the center of~$\glie$ is one-dimensional and spanned by the matrix~$E_{13}$.
	The quotient~$\glie / {\centerlie(\glie)}$ is thus spanned by the two residue classes~$\class{ E_{12} }$ and~$\class{ E_{23} }$.
	Their commutator is
	\[
		\Bigl[ \class{ E_{12} }, \class{ E_{23} } \Bigr]
		=
		\class{ [ E_{12}, E_{23} ] }
		=
		\class{ E_{13} }
		=
		0 \,,
	\]
	which shows that~$\glie / {\centerlie(\glie)}$ is abelian.
	But~$\glie$ is not abelian because the matrices~$E_{12}$ and~$E_{23}$ do not commute in~$\glie$.
\end{warning}


\begin{fluff}
	The Lie~algebra~$\sllie(2,\kf)$ will play a crucial role in the second part of these notes.
	We have already observed in the above discussion that~$\sllie(2,\kf)$ has a basis given by the three matrices
	\[
		e
		\defined
		\begin{pmatrix}
			0 & 1 \\
			0 & 0
		\end{pmatrix} \,,
		\qquad
		h
		\defined
		\begin{pmatrix*}[r]
			1 &  0  \\
			0 & -1
		\end{pmatrix*}  \,,
		\qquad
		f
		\defined
		\begin{pmatrix}
			0 & 0 \\
			1 & 0
		\end{pmatrix} \,.
	\]
	The Lie~bracket~$[\ph, \ph]$ of~$\sllie(2, \kf)$ is on these basis elements given by
	\[
		[h, e]
		=
		2e  \,,
		\qquad
		[h, f]
		=
		-2 f \,,
		\qquad
		[e,f]
		=
		h \,.
	\]
	We will see these relations quite a lot later on.

	The above basis of~$\sllie(2, \kf)$ is so important that we give it a special name.
\end{fluff}


\begin{definition}
 Let~$\kf$ be any field.
 The basis
 \[
		e
		=
		\begin{pmatrix}
			0 & 1 \\
			0 & 0
		\end{pmatrix} \,,
		\qquad
		h
		=
		\begin{pmatrix*}[r]
			1 &  0  \\
			0 & -1
		\end{pmatrix*}  \,,
		\qquad
		f
		=
		\begin{pmatrix}
			0 & 0 \\
			1 & 0
		\end{pmatrix} \,.
		\glsadd{standard basis of sl2}
	\]
	of the Lie~algebra~$\sllie(2, \kf)$ is its \defemph{standard basis}\index{standard basis}.
\end{definition}


\begin{remark}
	Some authors prefer the letters~$x$,~$h$,~$y$ over~$e$,~$h$,~$f$.
\end{remark}


\begin{example}
	We now determine the center of~$\sllie(n, \kf)$ for any field~$\kf$ and every natural number~$n$.

	In the cases~$n = 0$ and~$n = 1$ we have~$\sllie(n, \kf) = 0$ and therefore also~$\centerlie( \sllie(n, \kf) ) = 0$.
	We consider from now on the case~$n \geq 2$.

	Suppose first that the characteristic of~$\kf$ is distinct from~$2$.
	The Lie~algebra~$\sllie(n, \kf)$ does contain for any two indices~$i$,~$j$ with~$1 \leq i < j \leq n$ the diagonal matrix~$D$ with diagonal entries
	\[
		D_{kk}
		\defined
		\begin{cases*}
			\phantom{-}1  & if~$k = i$, \\
								-1  & if~$k = j$, \\
			\phantom{-}0  & otherwise.
		\end{cases*}
	\]
	The diagonal entries~$1$ and~$-1$ are distinct by assumption, whence it follows from \cref{center consists of diagonal matrices} that the center of~$\sllie(n, \kf)$ consists of scalar multiples of the identity matrix.

	Suppose now that the characteristic of~$\kf$ is~$2$ and that~$n \geq 3$.
	For any two indices~$i$,~$j$ with~$1 \leq i < j \leq n$ there exists then a third index~$k$ with~$k \neq i, j$.
	It follows that~$\sllie(2, \kf)$ contains the diagonal matrix~$D$ given by
	\[
		D_{ll}
		=
		\begin{cases*}
			1 & if~$l = i$ or~$l = k$, \\
			0 & if~$l = j$,  \\
			0 & otherwise.
		\end{cases*}
	\]
	The matrix~$D$ is built so that its two diagonal entries~$D_{ii}$ and~$D_{jj}$ are distinct.
	It follows from \cref{center consists of diagonal matrices} that the center of~$\sllie(n, \kf)$ consists of scalar multiples of the identity matrix.

	Supose now that the characteristic of~$\kf$ is~$2$ and that~$n = 2$.
	For the standard basis~$e$,~$h$,~$f$ of~$\sllie(2, \kf)$ we have
	\[
		[h, e] = 0 \,,
		\quad
		[h, f] = 0 \,,
		\quad
		[e, f] = h \,.
	\]
	We find that~$\sllie(2, \kf)$ is non-abelian and that~$h$ is central in~$\sllie(2, \kf)$.
	It follows from \cref{center has codimension at least two for non-abelian} that the center of~$\sllie(2, \kf)$ is spanned by~$h$, which is the identity matrix (because~$1 = -1$).

	We have now seen that for~$n \geq 2$ the center of~$\sllie(n, \kf)$ consists of scalar multiples of the identity matrix.
	But the identity matrix is contained in~$\sllie(n, \kf)$ if and only if the characteristic of~$\kf$ divides~$n$.
	We have thus shown that
	\[
		\centerlie( \sllie(n, \kf) )
		=
		\begin{cases*}
			\gen{ \Id }_{\kf} & if~$\ringchar(\kf)$ divides~$n$, \\
			0                 & otherwise,
		\end{cases*}
	\]
	for every~$n \geq 2$.
	This description also holds for the special~$n = 0$ and~$n = 1$.
	However, the span~$\gen{ \Id }_{\kf}$ is only one-dimensional for~$n \geq 1$.
\end{example}


\subsection{Normalizers}


\begin{definition}
	Let~$\glie$ be a Lie~algebra and let~$U$ be a linear subspace of~$\glie$.
	The set
	\[
		\normallie_{\glie}(U)
		\defined
		\{
			x \in \glie
		\suchthat
			\text{$[x,y] \in U$ for every~$y \in U$}
		\}
		\glsadd{normalizer}
	\]
	is the \defemph{normalizer}\index{normalizer} of~$U$ in~$\glie$.
\end{definition}


\begin{proposition}
	Let~$\glie$ be a Lie~algebra and let~$U$ be a linear subspace of~$\glie$.
	\begin{enumerate}
		\item
			The normalizer~$\normallie_{\glie}(U)$ is a Lie~subalgebras of~$\glie$.
		\item
			The linear subspace~$U$ is a Lie~subalgebra of~$\glie$ if and only if~$U$ is contained in~$\normallie_{\glie}(U)$.
		\item
			The linear subspace~$U$ is an ideal of~$\glie$ if and only if its normalizer~$\normallie_{\glie}(U)$ is all of~$\glie$.
		\item
			The centralizer~$\centerlie_{\glie}(U)$ is an ideal of the normalizer~$\normallie_{\glie}(U)$.
	\end{enumerate}
\end{proposition}


\begin{proof}
	\leavevmode
	\begin{enumerate}
		\item
			We have
			\begin{align*}
				\SwapAboveDisplaySkip
				[ [ \normallie_{\glie}(U), \normallie_{\glie}(U) ], U ]
				&\subseteq
				[ [ \normallie_{\glie}(U), U ], \normallie_{\glie}(U) ]
				+ [ \normallie_{\glie}(U), [ \normallie_{\glie}(U), U ] ]
				\\
				&\subseteq
				[ U, \normallie_{\glie}(U) ]
				+ [ \normallie_{\glie}(U), U ]
				\\
				&\subseteq
				U + U
				\\
				&=
				U \,,
			\end{align*}
			which shows that~$[ \normallie_{\glie}(U), \normallie_{\glie}(U) ]$ is again contained in~$\normallie_{\glie}(U)$.
		\item
			The linear subspace~$U$ is a Lie~subalgebra of~$\glie$ if and only if the commutator space~$[ U, U ]$ is again contained in~$U$, which is the case if and only if~$U$ is contained in~$\normallie_{\glie}(U)$.
		\item
			The linear subspace~$U$ is an ideal of~$\glie$ if and only if the commutator space~$[\glie, U]$ is again contained in~$U$, which means precisely that~$\glie$ is contained in the normalizer~$\normallie_{\glie}(U)$.
			But~$\normallie_{\glie}(U)$ is aways contained in~$\glie$, whence this inclusion is then already an equality.
		\item
			It follows from the inclusion
			\[
				[\centerlie_{\glie}(U), U]
				=
				0
				\subseteq
				U
			\]
			that the centralizer~$\centerlie_{\glie}(U)$ is contained in the normalizer~$\normallie_{\glie}(U)$.
			We have
			\begin{align*}
				[ [ \normallie_{\glie}(U), \centerlie_{\glie}(U) ], U ]
				&\subseteq
				[ [\normallie_{\glie}(U), U], \centerlie_{\glie}(U) ]
				+ [ \normallie_{\glie}(U), [\centerlie_{\glie}(U),  U] ]
				\\
				&\subseteq
				[ U, \centerlie_{\glie}(U) ]
				+ [ \normallie_{\glie}(U), 0 ]
				\\
				&=
				0 + 0
				\\
				&=
				0
			\end{align*}
			by the Jacobi~identity.
			This shows that the commutator space~$[ \normallie_{\glie}(U), \centerlie_{\glie}(U) ]$ is again contained in the centralizer~$\centerlie_{\glie}(U)$, which shows that~$\centerlie_{\glie}(U)$ is indeed an ideal of~$\normallie_{\glie}(U)$.
		\qedhere
	\end{enumerate}
\end{proof}





\section{New Lie~Algebras From Old Ones}


\subsection{Products of Lie~Algebras}


\begin{proposition}
	\label{construction of product lie algebra}
	Let~$\glie_{\lambda}$ with~$\lambda$ in~$\Lambda$ be a family of Lie~algebras.
	Then the bracket
	\[
		\bigl[ (x_\lambda)_\lambda, (y_\lambda)_\lambda \bigr]
		\defined
		( [x_\lambda, y_\lambda] )_\lambda
		\qquad
		\text{for all~$(x_\lambda)_\lambda, (y_\lambda)_\lambda \in \prod_{\lambda \in \Lambda} \glie_\lambda$}
	\]
	is a Lie~bracket on the vector space~$\prod_{\lambda \in \Lambda} \glie_\lambda$.
	\qed
\end{proposition}


\begin{definition}
	In the situation of \cref{construction of product lie algebra} the resulting Lie~algebra~$\prod_{\lambda \in \Lambda} \glie_\lambda$\glsadd{product of lie algebras} is the \defemph{product}\index{product of Lie algebras} of the Lie~algebras~$\glie_\lambda$.
\end{definition}


\subsection{External Direct Sums of Lie~Algebras}


\begin{proposition}
	\label{construction of direct sum of lie algebras}
	Let~$\glie_\lambda$ with~$\lambda$ in~$\Lambda$ be a family of Lie~algebras.
	Then the direct sum~$\bigoplus_{\lambda \in \Lambda} \glie_\lambda$ is a Lie~subalgebra of the product~$\prod_{\lambda \in \Lambda} \glie_\lambda$.
\end{proposition}


\begin{proof}
	Let~$(x_\lambda)_\lambda$ and~$(y_\lambda)_\lambda$ be two elements of~$\bigoplus_{\lambda \in \Lambda} \glie_\lambda$.
	Then there exist only finitely many indices~$\lambda \in \Lambda$ for which one of the vectors~$x_\lambda$ or~$y_\lambda$ does not vanish.
	There hence exist only finitely many indices~$\lambda \in \Lambda$ for which~$[x_\lambda, y_\lambda]$ does not vanish.
	This shows that~$[ (x_\lambda)_\lambda, (y_\lambda)_\lambda ]$ is again contained in~$\bigoplus_{\lambda \in \Lambda} \glie_\lambda$.
\end{proof}


\begin{definition}
	In the situation of \cref{construction of direct sum of lie algebras}, the resulting Lie~algebra~$\bigoplus_{\lambda \in \Lambda} \glie_\lambda$\glsadd{external direct sum of lie algebras}\index{external direct sum of Lie algebras}\index{direct sum of Lie algebras!external} is the \defemph{external direct sum} of the Lie~algebras~$\glie_\lambda$.
\end{definition}


\subsection{Quotients of Lie~Algebras}


\begin{proposition}
	\label{construction of quotient lie algebra}
	Let~$\glie$ be a Lie~algebra and let~$I$ an ideal of~$\glie$.
	The quotient vector space~$\glie/I$ inherits from~$\glie$ the structure of a Lie~algebra via the bracket
	\[
		[\class{x}, \class{y}]
		\defined
		\class{ [x,y] }
		\qquad
		\text{for all~$x, y \in \glie$.}
	\]
\end{proposition}


\begin{proof}
	The bilinear map~$[\ph, \ph]$ on~$\glie/I$ is well-defined:
	Suppose that~$x$,~$y$ and~$x'$,~$y'$ are elements of~$\glie$ such that both~$x$ and~$x'$, as well as~$y$ and~$y'$ represent the same element of~$\glie / I$.
	Then both differences~$x - x'$ and~$y - y'$ are contained in~$I$.
	It follows that the difference
	\begin{align*}
		[x,y] - [x', y']
		&=
		[x' + (x-x'), y' + (y-y')] - [x', y']
		\\
		&=
			\underbrace{[x', y-y']}_{\in I}
		+ \underbrace{[x-x', y']}_{\in I}
		+ \underbrace{[x-x', y-y']}_{\in I}
	\end{align*}
	is again contained in~$I$.

	This means that~$[x, y]$ and~$[x', y']$ represent the same element of~$\glie / I$.
	We have thus shown that the bracket on~$\glie/I$ is well-defined.
	
	It remains to show that the bracket~$[\ph, \ph]$ on~$\glie / I$ is bilinear and alternating, and that it satisfies the Jacobi~identity.
	But these properties are inherited from the bracket of~$\glie$, as they can be checked on representatives for the residue classes in~$\glie / I$.
\end{proof}


\begin{definition}
	\label{definition of quotient representation}
	The Lie~algebra~$\glie / I$\glsadd{quotient of lie algebra} from \cref{construction of quotient lie algebra} is the \defemph{quotient}\index{quotient of Lie algebras} of~$\glie$ by~$I$.
\end{definition}


\subsection{Abelianization of Lie~Algebras}


\begin{proposition}
	\label{quotient is abelian iff moded out the commutator ideal}
	Let~$\glie$ be a Lie~algebra and let~$I$ be an ideal of~$\glie$.
	The quotient Lie~algebra~$\glie / I$ is abelian if and only if the ideal~$I$ contains the commutator ideal of~$\glie$.
\end{proposition}


\begin{proof}
	We have the chain of equivalences
	\begin{align*}
		{}&
		\text{$\glie / I$ is abelian}
		\\
		\iff{}&
		\text{$[ \class{x}, \class{y}] = 0$ for all~$x, y \in \glie$}
		\\
		\iff{}&
		\text{$\class{[x,y]} = 0$ for all~$x, y \in \glie$}
		\\
		\iff{}&
		\text{$[x,y] \in I$ for all~$x, y \in \glie$}
		\\
		\iff{}&
		[\glie, \glie] \subseteq I \,,
	\end{align*}
	which proves the assertion.
\end{proof}


\begin{fluff}
	It follows from \cref{quotient is abelian iff moded out the commutator ideal} that~$\glie / [\glie, \glie]$ is the largest abelian quotient Lie~algebra of~$\glie$.
	This Lie~algebra has a special name:
\end{fluff}


\begin{definition}
	Let~$\glie$ be a Lie~algebra.
	The quotient Lie~algebra~$\glie / [\glie, \glie]$ is the \defemph{abelianization}\index{abelianization} of~$\glie$.
	It is denoted by~$\glie^{\ab}$\glsadd{abelianization of lie algebra}.
\end{definition}


\subsection{Extension of Scalars for Lie~Algebras}


\begin{proposition}
	\label{quasi extension of scalars for lie algebras}
	
	Let~$\glie$ be a Lie~algebra over a field~$\kf$ and let~$A$ be a commutative~{\algebra{$\kf$}}.
	\begin{enumerate}
		\item
			The tensor product~$A \tensor_{\kf} \glie$ becomes an~\liealgebra{$A$} via the bracket
			\begin{alignat*}{2}
				[a \tensor x, b \tensor y]
				&\defined
				(ab) \tensor [x,y]
				&\qquad
				&\text{for all~$a, b \in A$ and~$x, y \in \glie$}.
		\intertext{
		\item
			The tensor product~$\glie \tensor_{\kf} A$ becomes an~\liealgebra{$A$} via the bracket
		}
				[x \tensor a, y \tensor b]
				&\defined
				[x,y] \tensor (ab)
				&\qquad
				&\text{for all~$a, b \in A$ and~$x, y \in \glie$}.
			\end{alignat*}
	\end{enumerate}
\end{proposition}


\begin{proof}
	We prove only the first assertion, as the second one can be shown in the same way.

	The Lie~bracket of~$\glie$ is~\bilinear{$\kf$} and can therefore be regarded as a~\linear{$\kf$} map
	\[
		l \colon \glie \tensor_{\kf} \glie \to \glie \,.
	\]
	By the functoriality of the extension of scalars we now get an induced~\linear{$A$} map
	\[
		\id_A \tensor l
		\colon
		A \tensor_{\kf} \glie \tensor_{\kf} \glie
		\to
		A \tensor_{\kf} \glie \,,
	\]
	which maps any simple tensor~$a \tensor x \tensor y$ onto the simple tensor~$a \tensor [x,y]$.
	We now recall that there exists a unique isomorphism of~\modules{$A$}
	\[
		A \tensor_{\kf} \glie \tensor_{\kf} \glie
		\cong
		( A \tensor_{\kf} \glie ) \tensor_A ( A \tensor_{\kf} \glie )
	\]
	under which a simple tensor~$a \tensor x \tensor b \tensor y$ of the right hand side corresponds to the simple tensor~$(ab) \tensor x \tensor y$ of the left hand side.
	By considering the composite
	\[
		(A \tensor_{\kf} \glie) \tensor_A (A \tensor_{\kf} \glie)
		\to
		A \tensor_{\kf} \glie \tensor_{\kf} \glie
		\xto{\id_A \tensor l}
		A \tensor_{\kf} \glie
	\]
	we get altogether an~{\linear{$A$}} map
	\[
		(A \tensor_{\kf} \glie) \tensor_A (A \tensor_{\kf} \glie)
		\to
		A \tensor_{\kf} \glie
	\]
	which maps any simple tensor~$a \tensor x \tensor b \tensor y$ onto the the simple tensor~$(ab) \tensor [x,y]$.
	We may reinterpret this~\linear{$A$} map as an~\bilinear{$A$} map
	\[
		[\ph, \ph]
		\colon
		(A \tensor_{\kf} \glie) \times (A \tensor_{\kf} \glie)
		\to
		A \tensor_{\kf} \glie
	\]
	that is given on (pairs of) simple tensors by
	\[
		[a \tensor x, b \tensor y]
		=
		(ab) \tensor [x,y] \,.
	\]
	This~\bilinear{$A$} map is precisely the desired bracket.

	It remains to show this bracket~$[\ph, \ph]$ on~$A \tensor_{\kf} \glie$ is already a Lie~bracket.
	For this we need to show that it is alternating and that it satisfies the Jacobi~identity.

	To see that it is alternating let~$t$ be an elements of~$A \tensor_{\kf} \glie$.
	We may write this element as sums of simple tensors, say~$t = \sum_{i=1}^n a_i \tensor x_i$.
	We can then compute the commutator~$[t, t]$ as
	\[
		[t, t]
		=
		\Biggl[
			\sum_{i=1}^n a_i \tensor x_i,
			\sum_{j=1}^n a_j \tensor x_j
		\Biggr]
		=
		\sum_{i, j = 1}^n
		[ a_i \tensor x_i, a_j \tensor x_j ]
		=
		\sum_{i, j = 1}^n
		( a_i a_j ) \tensor [ x_i, x_j ] \,.
	\]
	The summands for~$i = j$ vanish since in this case~$[x_i, x_j] = [x_i, x_i] = 0$.
	For~$i \neq j$ the two occuring summands~$(a_i a_j) \tensor [x_i, x_j]$ and~$(a_j a_i) \tensor [x_j, x_i]$ cancel each other because~$a_i a_j = a_j a_i$ while~$[x_i, x_j] = -[x_j, x_i]$.
	Thus overall~$[t, t] = 0$.
	This shows that the bracket~$[\ph, \ph]$ on~$A \tensor_{\kf} \glie$ is alternating.

	It remains to show that the bracket on~$A \tensor_{\kf} \glie$ satisfies the Jacobi~identity.
	We hence want to show that the map
	\begin{gather*}
		J
		\colon
		(A \tensor_{\kf} \glie) \times (A \tensor_{\kf} \glie) \times (A \tensor_{\kf} \glie)
		\to
		(A \tensor_{\kf} \glie)
	\shortintertext{given by}
		(t, u, v)
		\mapsto
		[t, [u, v]] + [u, [v, t]] + [v, [t, u]]
	\end{gather*}
	is the zero map.
	The map~$J$ is~\trilinear{$A$} by the~\bilinearity{$A$} of the bracket~$[\ph, \ph]$ on~$A \tensor_{\kf} \glie$.
	It hence sufficies to show that the map~$J$ is zero on an~\linear{$A$} generating set of~$A \tensor_{\kf} \glie$.
	Such a generating set is given by the simple tensors~$1 \tensor x$ with~$x \in \glie$.
	We find for these generators that
	\begin{align*}
		\SwapAboveDisplaySkip
		{}&
		J(1 \tensor x, 1 \tensor y, 1 \tensor z)
		\\
		={}&
			[1 \tensor x, [1 \tensor y, 1 \tensor z]]
		+ [1 \tensor y, [1 \tensor z, 1 \tensor x]]
		+ [1 \tensor z, [1 \tensor x, 1 \tensor y]]
		\\
		={}&
		1 \tensor \bigl( [x, [y, z]] + [y, [z, x]] + [z, [x, y]] \bigr)
		\\
		={}&
		1 \tensor 0
		\\
		={}&
		0
	\end{align*}
	for all~$x, y, z \in \glie$ by the Jacobi~identity for~$\glie$.
	It follows that~$J = 0$, as desired.
\end{proof}


\begin{definition}
	The Lie~algebras~$A \tensor_{\kf} \glie$\glsadd{extension of scalars of lie algebra} and~$\glie \tensor_{\kf} A$\glsadd{extension of scalars of lie algebra} from \cref{quasi extension of scalars for lie algebras} are the \defemph{extension of scalars}\index{extension of scalars} of~$\glie$ from~$\kf$ to~$A$.
\end{definition}


\begin{example}
	Let~$\Kf/\kf$ be a field extension and let~$\glie$ be a Lie~algebra over~$\kf$.
	Then the tensor product~$\Kf \tensor_{\kf} \glie$ is a~\liealgebra{$\Kf$} via the Lie~bracket given by
	\[
		[\lambda \tensor x, \mu \tensor y]
		= 
		(\lambda \mu) \tensor [x,y]
		\qquad
		\text{for all simple tensor~$\lambda, \mu \in \Kf$ and~$x, y \in \glie$.}
	\]
	We can moreover regard~$\glie$ as an~\liesubalgebra{$\kf$} of~$\Kf \tensor_{\kf} \glie$ via the inclusion map
	\[
		\glie
		\to
		\Kf \tensor_{\kf} \glie \,,
		\quad
		x
		\mapsto
		1 \tensor x \,.
	\]
\end{example}


\begin{example}
	Let~$\glie$ be a Lie~algebra and let~$\kf[t, t^{-1}]$ be the~\algebra{$\kf$} of Laurent~polynomials over~$\kf$.
	Then
	\[
		\looplie(\glie)
		\defined
		\glie \tensor_{\kf} \kf[t, t^{-1}]
		\glsadd{loop lie algebra}
	\]
	with the Lie~bracket as in~\cref{quasi extension of scalars for lie algebras} is the \defemph{loop Lie~algebra} of~$\glie$.
\end{example}


% \begin{example}
%   Another example for constructing new Lie~algebras out of old ones are \defemph{central extensions}:
%   Let~$\glie$ be any~$\kf$-Lie~algebra.
%   Then let
%   \[
%     \widetilde{\glie}
%     \defined
%     \glie \oplus \kf
%     =
%     \{
%       x + \lambda c
%     \suchthat
%       x \in \glie,
%       \lambda \in \kf
%     \},
%   \]
%   where we understand~$c$ as a formal variable.
%   Suppose that~$\kappa \colon \glie \times \glie \to \kf$ is a~{\bilinear{$\kf$}} map satisfying the following properties:
%   \begin{enumerate}
%   \item
%     $\kappa$ is antisymmetric, i.e.~$\kappa(x,y) = -\kappa(y,x)$ for all~$x,y \in \glie$.
%   \item
%     $\kappa$ satisfies the \defemph{$2$-cocycle condition}
%     \[
%       \kappa([x,y],z) + \kappa([y,z],x) + \kappa([z,x],y) = 0
%     \]
%     for all~$x, y, z \in \glie$.
%   \end{enumerate}
%   Then~$\widetilde{\glie}$ becomes a Lie~algebra via
%   \[
%     [x + \lambda c, y + \mu c]
%     \defined
%     [x,y] + \kappa(x,y) c
%   \]
%   for all~$x, y \in \glie$ and~$\lambda, \mu \in \kf$.
%   Note that the element~$c$ is central in~$\widetilde{\glie}$ in the sense that~$[x,c] = 0$ for all~$x \in \glie$.
%   
%   Take for example~$\glie \defined \gllie(n, \kf)$.
%   We can then define a symmetric bilinear form~$(-,-)_{\tr}$ on~$\glie$ via
%   \[
%     (A,B)_{\tr}
%     \defined
%     \tr(AB)
%   \]
%   for all~$A, B \in \glie$.
%   We can use~$(-,-)_{\tr}$ to define on the Loop~algebra~$\looplie(\glie)$ a~{\bilinear{$\kf[t,t^{-1}]$}} form~$(-,-)$ via
%   \[
%     \looplie(\glie) \times \looplie(\glie)
%     \to
%     \kf[t,t^{-1}] \,,
%     \quad
%     (x \tensor p, y \tensor q)
%     \mapsto
%     (x,y)_{\tr} \, pq \,.
%   \]
%   We get from this a bilinear form a~{\twococycle}~$\kappa \colon \looplie(\glie) \times \looplie(\glie) \to \kf$ via
%   \[
%     \kappa(a,b)
%     \defined
%     \Res\left( \frac{\partial a}{\partial t}, b \right) \,.
%   \]
%   The bilinear form~$\kappa$ is also antisymmetric:
%   Let~$a = x \tensor t^i$ and~$b = y \tensor t^{j}$ with~$x,y \in \glie$ and~$i,j \in \Integer$.
%   Then
%   \begin{align*}
%     \kappa(x \tensor t^i, y \tensor t^{j})
%     &=
%     \Res(i x \tensor t^{i-1}, y \tensor t^{j})
%     \\
%     &= 
%     \Res(i t^{i+j-1} (x,y)_{\tr})
%     \\
%     &=
%     \begin{cases}
%       i (x,y)_{\tr} & \text{if~$i+j = 0$} \,,\\
%                   0 & \text{otherwise}  \,.
%     \end{cases}
%   \end{align*}
%   In the same way we find that
%   \[
%     \kappa(y \tensor t^{j}, x \tensor t^i)
%     =
%     \begin{cases}
%        j (x,y)_{\tr} & \text{if~$i+j = 0$} \,, \\
%                    0 & \text{otherwise}  \,.
%     \end{cases}
%   \]
%   Since~$(\cdot,\cdot)_{\tr}$ is symmetric we find that
%   \begin{align*}
%     \kappa(x \tensor t^i, y \tensor t^{j})
%     &=
%     \begin{cases}
%     i (x,y)_{\tr} & \text{if~$i+j = 0$} \,, \\
%                 0 & \text{otherwise}  \,,
%     \end{cases} \\
%     &=
%     \begin{cases}
%     -j (x,y)_{\tr} & \text{if~$i+j = 0$}  \,, \\
%                   0 & \text{otherwise}  \,,
%     \end{cases} \\
%     &=
%     -\kappa(y \tensor t^{j}, x \tensor t^i) \,.
%   \end{align*}
% \end{example}
% 
% 
% \begin{remark}
%   During the rest of these notes we will never see the Loop algebra again.
% \end{remark}


\subsection{The Opposite Lie~Algebra}


\begin{recall}
	If~$A$ is a~\enquote{\algebra{$\kf$}}, then we can form its \defemph{opposite \enquote{algebra}}~$A^{\op}$\glsadd{opposite algebra}\index{opposite algebra@opposite \enquote{algebra}}.

	The \enquote{algebras}~$A$ and~$A^{\op}$ have the same underlying~\vectorspace{$\kf$}.
	If we want to regard an element~$a$ of~$A$ as an element of~$A^{\op}$ then we write~$a^{\op}$\glsadd{opposite element} instead.
	(So~$a = a^{\op}$ but~$a$ lives in~$A$ while~$a^{\op}$ lives in~$A^{\op}$.)
	The multplication on~$A^{\op}$ is given by
	\[
		a^{\op} \cdot b^{\op}
		\defined
		(b \cdot a)^{\op}
		\qquad
		\text{for all~$a, b \in A$.}
	\]
	It holds that~$(A^{\op})^{\op} = A$, and~$(a^{\op})^{\op} = a$ for every element~$a$ of~$A$.

	The \enquote{algebra}~$A$ is associative if and only if its opposite \enquote{algebra}~$A^{\op}$ is associative, and an element~$1$ of~$A$ is a multiplicative neutral element of~$A$ if and only if~$1^{\op}$ is a multiplicative neutral element of~$A^{\op}$.
	It follows that~$A$ is a~{\algebra{$\kf$}} if and only if~$A^{\op}$ is a~\algebra{$\kf$}.
\end{recall}


\begin{proposition}
	Let be a~\liealgebra{$\kf$} with Lie~bracket~$[\ph, \ph]$.
	The opposite \enquote{algebra}~$\glie^{\op}$, whose bracket is given by
	\[
		[x^\op, y^\op]
		=
		[y,x]^{\op}
		=
		-[x,y]^{\op}
		\qquad
		\text{for all~$x, y \in \glie$,}
	\]
	is again a Lie~algebra.
	\qed
\end{proposition}


\begin{definition}
	Let~$\glie$ be a Lie~algebra.
	The Lie~algebra~$\glie^{\op}$\glsadd{opposite lie algebra} is the \defemph{opposite Lie~algebra}\index{opposite Lie algebra} of~$\glie$.
\end{definition}





\section{Homomorphisms of Lie~Algebras}



\subsection{Definition and Basic Examples}


\begin{definition}
	Let~$\glie$ and~$\hlie$ be two~\liealgebras{$\kf$}.
	A~\linear{$\kf$} map~$\varphi$ from~$\glie$ to~$\hlie$ is a \defemph{homomorphism of Lie~algebras}\index{homomorphism!of Lie algebras} if it satisfies the condition
 \[
	 \varphi([x,y])
	 =
	 [\varphi(x), \varphi(y)]
	 \qquad
	 \text{for all~$x, y \in \glie$.}
 \]
\end{definition}


\begin{proposition}
	Let~$\glie$ and~$\hlie$ be two Lie~algebras and let~$\varphi$ be a homomorphism of Lie~algebras from~$\glie$ to~$\hlie$.
	Then
	\[
		[ \varphi(X), \varphi(Y) ]
		=
		\varphi( [X, Y] )
	\]
	for any two subsets~$X$ and~$Y$ of~$\glie$.
	\qed
\end{proposition}


\begin{proposition}
	Let~$\glie$ and~$\hlie$ be two Lie~algebras and let~$\varphi$ be a homomorphism of Lie~algebras from~$\glie$ to~$\hlie$.
	\begin{enumerate}
		\item
			The image\index{image} of~$\varphi$ is a Lie~subalgebra of~$\hlie$.
		\item
			The kernel\index{kernel} of~$\varphi$ is an ideal of~$\glie$.
	\end{enumerate}
\end{proposition}


\begin{proof}
	\leavevmode
	\begin{enumerate}
		\item
			The image of~$\varphi$ is a linear subspace of~$\hlie$ because~$\varphi$ is linear.
			We have
			\[
				[ \im(\varphi), \im(\varphi) ]
				=
				[ \varphi(\glie), \varphi(\glie) ]
				=
				\varphi( [\glie, \glie] )
				\subseteq
				\varphi(\glie)
				=
				\im(\varphi) \,,
			\]
			which shows that~$\im(\varphi)$ is indeed a Lie~subalgebra of~$\hlie$.
		\item
			The kernel of~$\varphi$ is a linear subspace of~$\glie$ because~$\varphi$ is linear.
			We have
			\[
				\varphi( [\glie, \ker(\varphi)] )
				=
				[ \varphi(\glie), \varphi(\ker(\varphi)) ]
				=
				[ \varphi(\glie), 0 ]
				=
				0 \,,
			\]
			which shows that the commutator space~$[\glie, \ker(\varphi)]$ is again contained in~$\ker(\varphi)$.
			This means that~$\ker(\varphi)$ is indeed an ideal in~$\glie$.
		\qedhere
	\end{enumerate}
\end{proof}


\begin{examples}
	\label{homomorphisms of lie algebras}
	Let~$\glie$,~$\hlie$, and~$\klie$ be Lie~algebras.
	\begin{enumerate}
		\item
			\label{identity is a homomorphism of lie algebras}
			The identity map of~$\glie$ is a homomorphism of Lie~algebras from~$\glie$ to~$\glie$.
		\item
			\label{composite of homomorphisms of lie algebras}
			Let~$\varphi$ be a homomorphism of Lie~algebras from~$\glie$ to~$\hlie$ and let~$\psi$ be a homomorphism of Lie~algebras from~$\hlie$ to~$\klie$.
			The composite~$\psi \circ \varphi$ is a homomorphism of Lie~algebras from~$\glie$ to~$\klie$.
		\item
			Let~$\hlie$ be a Lie~subalgebra of~$\glie$.
			The inclusion map from~$\hlie$ to~$\glie$ is a homomorphism of Lie~algebras.
		\item
			Suppose that the Lie~algebras~$\glie$ and~$\hlie$ are both abelian.
			Then any~\linear{$\kf$} map from~$\glie$ to~$\hlie$ is already a homomorphism of Lie~algebras.
		\item
			For every element~$x$ of~$\glie$ let~$\ad(x)$ be the linear map
			\[
				\ad(x)
				\colon
				\glie
				\to
				\glie \,,
				\qquad
				y
				\mapsto
				[x,y] \,.
				\index{adjoint representation}
			\]
			It follows from the bilinearity of the Lie~bracket of~$\glie$ that this describes a~\linear{$\kf$} map
			\[
				\ad
				\glsadd{adjoint map}
				\colon
				\glie
				\to
				\gllie(\glie) \,.
			\]
			It follows from the Jacobi~identity that the map~$\ad$ is already a homomorphism of Lie~algebras.
			Indeed, we have for all element~$x$,~$y$,~$z$ of~$\glie$ that
			\begin{align*}
					\ad([x,y])(z)
					&=
					[[x,y], z]
					\\
					&=
					[ [x,z], y ] + [ x, [y,z] ]
					\\
					&=
					[x,[y,z]] - [y,[x,z]]
					\\
					&=
					\ad(x)(\ad(y)(z)) - \ad(y)(\ad(x)(z))
					\\
					&=
					( \ad(x) \ad(y) - \ad(y) \ad(x) )(z)
					\\
					&=
					[\ad(x), \ad(y)](z) \,,
			\end{align*}
			and therefore~$\ad([x,y]) = [ \ad(x), \ad(y) ]$.
		\item
			\label{algebra homomorphisms are lie algebra homomorphisms}
			Let~$A$ and~$B$ be two associative~{\algebras{$\kf$}}.
			Every homomorphism of~{\algebras{$\kf$}}~$\Phi$ from~$A$ to~$B$ is also a homomorphism of Lie~algebras.
			Indeed, we have for all elements~$a$,~$b$ of~$A$ that
			\[
				\Phi([a,b])
				=
				\Phi(ab - ba)
				=
				\Phi(a) \Phi(b) - \Phi(b) \Phi(a)
				=
				[\Phi(a), \Phi(b)] \,.
			\]
		\item
			Let~$\glie$ be a Lie~algebra over an arbitary field~$\kf$.
			If~$\varphi$ is a homomorphism of Lie~algebras from~$\sllie(2, \kf)$ to~$\glie$, then the images
			\[
				E \defined \varphi(e)  \,,
				\qquad
				H \defined \varphi(h)  \,,
				\qquad
				F \defined \varphi(f)
			\]
			satisfy the commutator relations
			\begin{equation}
				\label{relations for sl2 tripel}
				[H, E] = 2E  \,,
				\qquad
				[H, F] = -2F  \,,
				\qquad
				[E, F] = H \,.
			\end{equation}
			Conversely, every such triple~$(E', H', F')$ of elements of~$\glie$ satisfying the above commutator relations (with~$X$ replaced by~$X'$ for~$X = E, H, F$) gives rise to a unique homomorphism of Lie~algebras~$\varphi'$ from~$\sllie(2, \kf)$ to~$\glie$ that is given by
			\[
				\varphi'(e) = E' \,,
				\qquad
				\varphi'(h) = H' \,,
				\qquad
				\varphi'(f) = F' \,.
			\] 
			These two constructions are mutually inverse.
			We have thus constructed a bijection
			\begin{align*}
				\left\{
					\begin{tabular}{c}
						homomorphisms of \\
						Lie~algebras~$\varphi \colon \sllie(2, \kf) \to \glie$
					\end{tabular}
				\right\}
				&\to
				\left\{
					\begin{tabular}{c}
						triples $(E, H, F)$ of elements of~$\glie$ \\
						that satisfy the relations~\eqref{relations for sl2 tripel}
					\end{tabular}
				\right\} \,,
				\\
				\varphi
				&\mapsto
				\bigl( \varphi(e), \varphi(h), \varphi(f) \bigr) \,.
			\end{align*}
	%     Such triples will play an important role later on.
	\end{enumerate}
\end{examples}


\begin{remark}
	It follows from part~\ref{identity is a homomorphism of lie algebras} and part~\ref{composite of homomorphisms of lie algebras} of \cref{homomorphisms of lie algebras} that the~\liealgebras{$\kf$} form a category\index{category!of Lie algebras}.
	We will denote this category by
	\[
		\cLie{\kf} \,.
		\glsadd{category lie algebras}
	\]
	The class of objects of~$\cLie{\kf}$ is the class of~\liealgebras{$\kf$}.
	For any two Lie~algebras~$\glie$ and~$\hlie$ over~$\kf$ we have
	\[
		\Hom_{\cLie{\kf}}(\glie, \hlie)
		=
		\{
			\text{homomorphisms of Lie~algebras~$\textstyle \glie \to \hlie$} 
		\} \,.
	\]
	The composition of morphisms in~$\cLie{\kf}$ is the usual composition of functions.
	The identity morphism of an object of~$\cLie{\kf}$ is the usual identity function.

	We have a forgetful functor
	\[
		\cLie{\kf}
		\to
		\cVect{\kf}
	\]
	that assigns to every~\liealgebra{$\kf$} its underlying~\vectorspace{$\kf$}.
	It follows from part~\ref{algebra homomorphisms are lie algebra homomorphisms} of \cref{homomorphisms of lie algebras} that we also have a forgetful functor
	\[
		\cAlg{\kf}
		\to
		\cLie{\kf} \,,
	\]
	where~$\cAlg{\kf}$\glsadd{category algebras} denotes the category of~\algebras{$\kf$}\index{category!of algebras}.
	The forgetful functor from~$\cAlg{\kf}$ to~$\cVect{\kf}$ is the composite of the forgetful functor from~$\cAlg{\kf}$ to~$\cLie{\kf}$ and the forgetful functor from~$\cLie{\kf}$ to~$\cVect{\kf}$.
\end{remark}


\begin{proposition}
	\label{inverse of homomorphism of lie algebras is again a homomorphism of lie algebras}
	Let~$\glie$ and~$\hlie$ be two Lie~algebras and let~$\varphi$ be a bijective homomorphism of Lie~algebras from~$\glie$ to~$\hlie$.
	The set-theoretic inverse map of~$\varphi$ is a homomorphism of Lie~algebras from~$\hlie$ to~$\glie$.
\end{proposition}


\begin{proof}
	The inverse~$\varphi^{-1}$ is~\linear{$\kf$} because the original map~$\varphi$ is~\linear{$\kf$}.
	We also have
	\[
		\varphi^{-1}( [x,y] )
		=
		\varphi^{-1}( [ \varphi(\varphi^{-1}(x)), \varphi(\varphi^{-1}(y)) ] )
		=
		\varphi^{-1}( \varphi( [ \varphi^{-1}(x), \varphi^{-1}(y) ] ) )
		=
		[ \varphi^{-1}(x), \varphi^{-1}(y) ]
	\]
	for any two elements~$x$,~$y$ of~$\hlie$.
	This shows that~$\varphi^{-1}$ is a homomorphism of Lie~algebras.
\end{proof}


\begin{remark}
	We have the notion of an \defemph{isomorphism of~\liealgebras{$\kf$}}\index{isomorphism!of Lie algebras} because \liealgebras{$\kf$} form a category.
	More explicitely, a homomorphism of Lie~algebras~$\varphi$ from a Lie~algebra~$\glie$ to a Lie~algebra~$\hlie$ is an isomorphism (of Lie~algebras) if and only if there exists a homomorphism of Lie~algebras~$\psi$ from~$\hlie$ to~$\glie$ such that both~$\psi \circ \varphi = \id_{\glie}$ and~$\varphi \circ \psi = \id_{\hlie}$.

	We can now give a reinterpretation of \cref{inverse of homomorphism of lie algebras is again a homomorphism of lie algebras}:
	a homomorphism of Lie~algebras is an isomorphism of Lie~algebras if and only if it is bijective.
\end{remark}


\begin{example}[Classification of abelian Lie~algebras]
	\index{classification!of abelian Lie algebras}
	Let~$\kf$ be any field.

	Two abelian~{\liealgebras{$\kf$}} are isomorphic (as Lie~algebras) if and only if they are isomorphic as~{\vectorspaces{$\kf$}}, because every vector space isomorphism between them is already an isomorphism of Lie~algebras.
	It follows that there exists precisely one abelian~{\liealgebra{$\kf$}} of each dimension up to isomorphism.
\end{example}


\begin{example}[Classification of {\onedimensional} Lie~algebras]
	\index{classification!of one-dimensional Lie algebras}
	\index{one-dimensional Lie algebras}
	Let~$\kf$ be any field and let~$\glie$ be a~{\onedimensional}~\liealgebra{$\kf$}.
	The Lie~bracket of~$\glie$ is zero since it is an alternating bilinear map on a one-dimensional vector space.
	The Lie~algebra~$\glie$ is therefore abelian.
	It follows that there exists precisely one {\onedimensional}~\liealgebra{$\kf$} up to isomorphism, namely the abelian one.
\end{example}


\begin{example}[Classification of {\twodimensional} Lie~algebras]
	\index{classification!of two-dimensional Lie algebras}
	\index{two-dimensional Lie algebras}
	There exists precisely one {\twodimensional}, abelian~\liealgebra{$\kf$} up to isomorphism.

	Let now~$\glie$ be a {\twodimensional}, non-abelian~\liealgebra{$\kf$}.
	Let~$x'$,~$y'$ be any basis of~$\glie$.
	The commutator space~$[\glie, \glie]$ is nonzero because~$\glie$ is non-abelian, and~$[\glie, \glie]$ is spanned by the single commutator~$[x',y']$ because the Lie~bracket is alternating.
	We thus have~$[\glie, \glie] = \gen{ [x', y'] }_{\kf}$ with~$[x', y']$ being nonzero.

	Let now~$x \defined [x',y']$ and let~$y$ be some element of~$\glie$ that is linearly independent to~$x$.
	Then~$x$,~$y$ is a basis of~$\glie$, and we have seen above that the commutator~$[x,y]$.
	This commutator is also contained in the commutator space~$[\glie, \glie]$, which is spanned by~$x$.
	The element~$[x,y]$ is thus a nonzero scalar multiple of~$x$.
	By rescaling the basis vector~$y$ we may therefore assume that~$[x,y]$ equals~$x$.

	We have thus shown that any two-dimensional, non-abelian Lie~algebra admits a basis~$x$,~$y$ on that its Lie~bracket has a specific form, namely
	\[
		[x,y] = x \,.
	\]
	This shows that there exists at most one {\twodimensional}, non-abelian~\liealgebra{$\kf$} up to isomorphism.

	To show the existence of such a two-dimensional, non-abelian~\liealgebra{$\kf$} we consider the two matrices
	\[
		x
		\defined
		\begin{pmatrix}
			0 & 1 \\
			0 & 0
		\end{pmatrix}
		=
		E_{12}  \,,
		\qquad
		y
		\defined
		\begin{pmatrix}
			0 & 0 \\
			0 & 1
		\end{pmatrix}
		=
		E_{22}  \,.
	\]
	We have
	\[
		[x,y]
		=
		[E_{12}, E_{22}]
		=
		E_{12} E_{22} - E_{22} E_{12}
		=
		E_{12} - 0
		=
		E_{12}
		=
		x \,.
	\]
	The linear subspace of~$\gllie(2, \kf)$ which is spanned by the two matrices~$x$ and~$y$ is therefore a Lie~subalgebra of~$\gllie(2, \kf)$.
	The matrices~$x$ and~$y$ are linearly independent, whence this Lie~subalgebra is {\twodimensional}.
	It is also non-abelian because the matrices~$x$ and~$y$ do not commute.

	We have altogether shown that there exists precisely two {\twodimensional}~\liealgebras{$\kf$} up to isomorphism.
	One of them is abelian, and the other one is non-abelian and admits a basis~$x$,~$y$ with~$[x,y] = x$.
\end{example}

\begin{example}[Three-dimensional Lie~algebras]
	\label{infinitely many three-dimensional lie algebras}
	\index{three-dimensional Lie algebras}
	The number of isomorphism classes of {\threedimensional} Lie~algebras over a field~$\kf$ depends on the cardinality of~$\kf$.

	If the field~$\kf$ is finite, then there exist only finitely many {\threedimensional} Lie~algebras up to isomorphism.
	Indeed, every such Lie~algebra is isomorphic to the vector space~$\kf^3$ together with a suitable Lie~bracket~$[\ph, \ph]$ on~$\kf^3$.
	But there exist only finitely many Lie~brackets on~$\kf^3$ because~$\kf^3$ is finite.

	If the field~$\kf$ is infinite then there exist infinitely many {\threedimensional}~\liealgebras{$\kf$} up to isomorphism.
	We show this by constructing a family of Lie~algebras~$\glie_\tau$ where~$\tau$ ranges through~$\kf$, such that~$\glie_\tau$ and~$\glie_\upsilon$ are isomorphic if and only if~$\tau = \upsilon$ or~$\tau \upsilon = 1$.

	The Lie~algebra~$\glie_\tau$ is given by a the vector space with basis~$t$,~$x$,~$y$ together with the Lie~bracket given by
	\[
		[t, x] = x \,,
		\quad
		[t, y] = \tau y \,,
		\quad
		[x, y] = 0 \,.
	\]
	Such a Lie~algebra exists since it can be realized as the Lie~subalgebra of~$\gllie(3, \kf)$ that is spanned by the three matrices
	\[
		t
		=
		\begin{pmatrix}
			0 &   &       \\
				& 1 &       \\
				&   & \tau
		\end{pmatrix} \,,
		\qquad
		x
		=
		E_{21} 
		=
		\begin{pmatrix}
			0 & 0 & 0 \\
			1 & 0 & 0 \\
			0 & 0 & 0
		\end{pmatrix} \,,
		\qquad
		y
		=
		E_{31}
		=
		\begin{pmatrix}
			0 & 0 & 0 \\
			0 & 0 & 0 \\
			1 & 0 & 0
		\end{pmatrix} \,.
	\]

	We first observe that for~$\tau \neq 0$ we can replace the basis~$t$,~$x$,~$y$ of~$\glie_\tau$ by the slighty rescaled basis~$t'$,~$x'$,~$y'$ given by
	\[
		t' \defined \frac{t}{\tau} \,,
		\quad
		x' \defined x \,,
		\quad
		y' \defined y \,.
	\]
	The Lie~bracket of~$\glie_\tau$ is on this rescaled basis given by the relations
	\[
		[t', x'] = \frac{1}{\tau} x' \,,
		\quad
		[t', y'] = y' \,,
		\quad
		[y', x'] = 0 \,.
	\]
	We find from these relations that the unique linear map~$\varphi \colon \glie_{\tau} \to \glie_{1/\tau}$ given by
	\[
		\varphi(t') = t \,,
		\quad
		\varphi(x') = y \,,
		\quad
		\varphi(y') = x
	\]
	is an isomorphism of Lie~algebras.
	This shows that~$\glie_{\tau}$ is isomorphic to~$\glie_{\upsilon}$ if~$\tau \neq 0$ and~$\upsilon = 1/\tau$, i.e. if~$\tau \upsilon = 1$.
	
	Let now~$\glie$ be~$\glie_\tau$ for some scalar~$\tau$ in~$\kf$.
	The commutator space~$[\glie, \glie]$ is spanned by~$x$ and~$y$ if~$\tau$ is nonzero, and otherwise spanned by~$x$.
	We can hence distinguish the Lie~algebra~$\glie_0$ from the Lie~algebras~$\glie_\upsilon$ for~$\upsilon \neq 0$ by considering the dimension of~$[\glie, \glie]$.

	To further distinguish between the Lie~algebras~$\glie_\upsilon$ with~$\upsilon \neq 0$ let~$t'$ be some element of~$\glie$ that does not belong to the commutator space~$[\glie, \glie]$.
	We find from the equality~$[\glie, \glie] = \gen{x,y}_{\kf}$ that the element~$t'$ is of the form
	\[
		t'
		=
		\alpha t + \beta x + \gamma y
	\]
	for some coefficients~$\alpha$,~$\beta$,~$\gamma$ in~$\kf$ with~$\alpha \neq 0$.
	We consider the endomorphism
	\[
		\ad(t')
		=
		[t', \ph]
		\colon
		\glie
		\to
		\glie \,.
	\]
	With respect to the basis~$t$,~$x$,~$y$ of~$\glie$ we have
	\[
		\ad(t)
		\equiv
		\begin{pmatrix}
			0 & 0 & 0     \\
			0 & 1 & 0     \\
			0 & 0 & \tau
		\end{pmatrix} \,,
		\quad
		\ad(x)
		\equiv
		\begin{pmatrix*}[r]
			 0  & 0 & 0 \\
			-1  & 0 & 0 \\
			 0  & 0 & 0
		\end{pmatrix*} \,,
		\quad
		\ad(y)
		\equiv
		\begin{pmatrix*}[r]
			0     & 0 & 0 \\
			0     & 0 & 0 \\
			-\tau & 0 & 0
		\end{pmatrix*}
	\]
	and therefore
	\begin{align*}
		\ad(t')
		&=
		\ad(\alpha t + \beta x + \gamma y)
		\\
		&=
		\alpha \ad(t) + \beta \ad(x) + \gamma \ad(y)
		\\
		&\equiv
		\alpha
		\begin{pmatrix}
			0 & 0 & 0     \\
			0 & 1 & 0     \\
			0 & 0 & \tau
		\end{pmatrix}
		+
		\beta
		\begin{pmatrix*}[r]
			 0  & 0 & 0 \\
			-1  & 0 & 0 \\
			 0  & 0 & 0
		\end{pmatrix*}
		+
		\gamma
		\begin{pmatrix*}[r]
			0     & 0 & 0 \\
			0     & 0 & 0 \\
			-\tau & 0 & 0
		\end{pmatrix*}
		\\
		&=
		\begin{pmatrix}
			 0          & 0       & 0           \\
			-\beta      & \alpha  & 0           \\
			-\gamma\tau & 0       & \alpha \tau
		\end{pmatrix} \,.
	\end{align*}
	The eigenvalues of~$\ad(t')$ are thus given by~$0$,~$\alpha$, and~$\alpha \tau$.
	We find from this that the two quotients of the two non-zero eigenvalues of~$\ad(t')$ are given by~$\tau$ and~$1 / \tau$.

	The above calculations shows how the set~$\{ \tau, 1 / \tau \}$ can be reconstructed from the Lie~algebra~$\glie = \glie_\tau$:
	the values~$\tau$ and~$1/\tau$ are precisely the quotients of the nonzero eigenvalues of~$\ad(t')$ where~$t'$ is any element of~$\glie$ not contained in the commutator space~$[\glie, \glie]$.
	It follows that for~$\glie_\tau$ and~$\glie_\upsilon$ to be isomorphic we need the equality~$\{ \tau , 1/\tau \} = \{ \upsilon, 1/\upsilon \}$.
	This means that~$\tau = \upsilon$ or~$\tau = 1 / \upsilon$, i.e.~$\tau \upsilon = 1$.
\end{example}


\subsection{Universal Property of the Product}


\begin{proposition}[Universal property of the product]
	\label{products of lie algebras}
	\index{universal property!of product of Lie algebras}
	Let~$\glie_\lambda$ with~$\lambda$ in~$\Lambda$ be a family of~\liealgebras{$\kf$}.
	\begin{enumerate}
		\item
			The canonical projection
			\[
			 \pi_\mu
			 \colon
			 \prod_{\lambda \in \Lambda} \glie_\lambda
			 \to
			 \glie_\mu \,,
			 \quad
			 ( x_\lambda )_\lambda
			 \mapsto
			 x_\mu
			\]
			is for every index~$\mu$ in~$\Lambda$ a homomorphism of Lie~algebras.
		\item
			Let~$\hlie$ be a~\liealgebra{$\kf$}.
			A map~$\varphi$ from~$\hlie$ to~$\prod_{\lambda \in \Lambda} \glie$ is a homomorphism of Lie~algebras if and only if it is a homomorphisms of Lie~algebras in each coordinate, i.e.\ if and only if for every index~$\mu$ in~$\Lambda$ the composite~$\pi_\mu \circ \varphi$ is a homomorphism of Lie~algebras from~$\hlie$ to~$\glie_\mu$.
		\qed
	\end{enumerate}
\end{proposition}


\begin{proof}
	\leavevmode
	\begin{enumerate}
		\item
			This holds because the Lie~algebra structure on~$\prod_{\lambda \in \Lambda} \glie_{\lambda}$ is defined componentwise.
		\item
			If~$\varphi$ is a homomorphism of Lie~algebras from~$\hlie$ to~$\prod_{\lambda \in \Lambda} \glie_\lambda$, then the composite~$\pi_\mu \circ \varphi$ is for every index~$\mu$ in~$\Lambda$ a composite of homomorphism of Lie~algebras, and therefore again a homomorphism of Lie~algebras.

			Suppose on the other hand that each composite~$\pi_\lambda \circ \varphi$ is a homomorphism of Lie~algebras.
			The map~$\varphi$ is then linear in each coordinate, and thus linear.
			We also have for every two elements~$x$,~$y$ of~$\hlie$ and for every index~$\mu$ in~$\Lambda$ the equalities
			\begin{align*}
				\pi_\mu\bigl( \varphi( [ x, y ] ) \bigr)
				&=
				(\pi_\mu \circ \varphi)( [x, y] )
				\\
				&=
				[ (\pi_\mu \circ \varphi)(x), (\pi_\mu \circ \varphi)(y) ]
				\\
				&=
				[ \pi_\mu( \varphi(x) ), \pi_\mu( \varphi(y) ) ]
				\\
				&=
				\pi_\mu\bigl( [\varphi(x), \varphi(y)] \bigr) \,,
			\end{align*}
			and thus altogether the equality
			\[
				\varphi( [x,y] ) = [ \varphi(x), \varphi(y) ] \,.
			\]
			This shows that the linear map~$\varphi$ is a homomorphism of Lie~algebras.
		\qedhere
	\end{enumerate}
\end{proof}


\begin{remark}
	\Cref{products of lie algebras} shows that the category~$\cLie{\kf}$ has all small products.

	Given three~\liealgebras{$\kf$}~$\glie$,~$\hlie_1$,~$\hlie_2$ and two homomorphisms of Lie~algebras
	\[
		\varphi_1 \colon \glie \to \hlie_1 \,,
		\quad
		\varphi_2 \colon \glie \to \hlie_2 \,,
	\]
	the set
	\[
		\{
			x \in \glie
		\suchthat
			\varphi_1(x) = \varphi_2(x)
		\}
	\]
	is a Lie~subalgebra of~$\glie$.
	This then shows that the category~$\cLie{\kf}$ has binary equalizers.

	Together, this shows that the category~$\cLie{\kf}$ has all small limits, i.e. it is complete.
	We will see in \cref{existence of small colimits} that the category~$\cLie{\kf}$ also has all small colimits, i.e. that it is cocomplete.
\end{remark}


\subsection{Universal Property of the External Direct Sum}


\begin{example}[Universal property of the external direct sum]
	\label{homomorphism out of direct sum}
	\index{universal property!of direct sum of Lie algebras}
	Let~$\glie_\lambda$ with~$\lambda$ in~$\Lambda$ be a family of~\liealgebras{$\kf$}.
	For every index~$\mu$ in~$\Lambda$ we have a~\linear{$\kf$}, injective inclusion map
	\[
		\iota_\mu
		\colon
		\glie_\mu
		\to
		\bigoplus_{\lambda \in \Lambda} \glie_\lambda
	\]
	that is given by
	\[
		\iota_\mu(x)
		=
		(x_\lambda)_\lambda
		\quad\text{with}\quad
		x_\lambda
		=
		\begin{cases*}
			x & if~$\lambda = \mu$, \\
			0 & otherwise,
		\end{cases*}
		\qquad
		\text{for all~$\lambda \in \Lambda$.}
	\]
	These inclusion maps are homomorphisms of Lie~algebras because the Lie~bracket on~$\bigoplus_{\lambda \in \Lambda} \glie_\lambda$ is defined componentwise.
	We can therefore regard every Lie~algebra~$\glie_\mu$ as a Lie~subalgebra of the direct sum~$\bigoplus_{\lambda \in \Lambda} \glie_\lambda$ via the inclusion map~$\iota_\mu$.

	Let~$\hlie$ be another~\liealgebra{$\kf$}.
	We have a {\onetoonetext} correspondence
	\begin{align}
		\left\{
			\begin{tabular}{c}
				\linear{$\kf$} maps \\
				$\varphi \colon \bigoplus_{\lambda \in \Lambda} \glie_\lambda \to \hlie$
			\end{tabular}
		\right\}
		&\onetoone
		\left\{
			\begin{tabular}{c}
				$(\varphi_\lambda)_\lambda$
			\end{tabular}
		\suchthat*
			\begin{tabular}{c}
				\linear{$\kf$} maps\\
				$\varphi_\lambda \colon \glie_\lambda \to \hlie$
			\end{tabular}
		\right\}
		\label{universal property of vector space direct sum}
	\intertext{that is given by}
		\SwapAboveDisplaySkip
		\varphi
		&\mapsto
		(\varphi \circ \iota_\lambda)_\lambda \,,
		\notag
		\\
		\biggl(
			(x_\lambda)_\lambda
			\mapsto
			\sum_{\lambda \in \Lambda}
			\varphi_\lambda(x_\lambda)
		\biggr)
		&\mapsfrom
		(\varphi_\lambda)_\lambda \,.
		\notag
	\end{align}
	We may think about the composite~$\varphi \circ \iota_\lambda$ as the restriction of~$\varphi$ to~$\glie_\lambda$, when~$\glie_\lambda$ is regarded as a Lie~subalgebra of~$\glie$ via the inclusion~$\iota_\lambda$.

	If a~\linear{$\kf$} map~$\varphi$ from~$\bigoplus_{\lambda \in \Lambda} \glie_\lambda$ to~$\hlie$ is a homomorphism of Lie~algebras, then each composite~$\varphi \circ \iota_\mu$ is a homomorphism of Lie~algebras from~$\glie_\mu$ to~$\hlie$, because it is a composite of two homomorphisms of Lie~algebras.
	We note that the Lie~algebras~$\glie_\mu$ commute with each other in~$\bigoplus_{\lambda \in \Lambda} \glie_\lambda$, in the sense that
	\[
		[ \iota_\mu(\glie_\mu), \iota_\kappa(\glie_\kappa) ] = 0
		\qquad
		\text{for any two distinct indices~$\mu$ and~$\kappa$}.
	\]
	It follows that the images of the composites~$\varphi \circ \iota_\lambda$ commute with each other in~$\hlie$, because
	\[
		[
			(\varphi \circ \iota_\mu)(\glie_\mu),
			(\varphi \circ \iota_\kappa)(\glie_\kappa)
		]
		=
		\varphi( [\iota_\mu(\glie_\mu), \iota_\kappa(\glie_\kappa)] )
		=
		\varphi(0)
		=
		0
	\]
	for any two distinct indices~$\mu$ and~$\kappa$.

	Suppose on the other hand that~$\varphi_\lambda \colon \glie_\lambda \to \hlie$ with~$\lambda$ in~$\Lambda$ is a family of homomorphisms of Lie~algebras whose images commute with each other.
	Let~$\varphi$ be the~\linear{$\kf$} from~$\bigoplus_{\lambda \in \Lambda} \glie_\lambda$ to~$\hlie$ corresponding to the maps~$\varphi_\lambda$.
	More explicitely, we have
	\[
		\varphi( (x_\lambda)_\lambda )
		=
		\sum_{\lambda \in \Lambda}
		\varphi_\lambda(x_\lambda)
		\qquad
		\text{for every~$(x_\lambda)_\lambda \in \bigoplus_{\lambda \in \Lambda} \glie_\lambda$.}
	\]
	Then the map~$\varphi$ is again a homomorphism of Lie~algebras.
	Indeed, let~$(x_\lambda)_\lambda$ and~$(y_\lambda)_\lambda$ be two elements of~$\bigoplus_{\lambda \in \Lambda} \glie_\lambda$.
	We have
	\begin{align*}
		[
			\varphi( (x_\lambda)_\lambda ),
			\varphi( (y_\lambda)_\lambda )
		]
		&=
		\Biggl[
			\sum_{\lambda \in \Lambda}
			\varphi_\lambda( x_\lambda ) ,
			\sum_{\mu \in \Lambda}
			\varphi_\mu( y_\mu )
		\Biggr]
		\\
		&=
		\sum_{\lambda, \mu \in \Lambda}
		\underbrace{
			[ \varphi_\lambda( x_\lambda ) , \varphi_\mu( y_\mu ) ]
		}_{
			\text{$= 0$ for~$\lambda \neq \mu$}
		}
		\\
		&=
		\sum_{\lambda \in \Lambda} [ \varphi_\lambda( x_\lambda ), \varphi_\lambda( y_\lambda ) ]
		\\
		&=
		\sum_{\lambda \in \Lambda} \varphi_\lambda( [ x_\lambda , y_\lambda ] )
		\\
		&=
		\varphi( ([x_\lambda, y_\lambda])_\lambda )
		\\
		&=
		\varphi( [ (x_\lambda)_\lambda, (y_\lambda)_\lambda ] ) \,.
	\end{align*}
	This shows that~$\varphi$ is indeed a homomorphism of Lie~algebras.

	It follows from the above assertions that the {\onetoonetext} correspondence~\eqref{universal property of vector space direct sum} restricts to a {\onetoonetext} correspondence
	\begin{align*}
		\left\{
			\begin{tabular}{c}
				Lie~algebra \\
				homomorphisms \\
				$\varphi \colon \bigoplus_{\lambda \in \Lambda} \glie_\lambda \to \hlie$
			\end{tabular}
		\right\}
		&\onetoone
		\left\{
			\begin{tabular}{c}
				$(\varphi_\lambda)_\lambda$
			\end{tabular}
		\suchthat*
			\begin{tabular}{c}
				Lie~algebra homomorphisms \\
				$\varphi_\lambda \colon \glie_\lambda \to \hlie$ whose images \\
				commute with each other
			\end{tabular}
		\right\} \,.
	\end{align*}
\end{example}


\subsection{Internal Direct Sums}


\begin{example}
	\label{direct sum of ideals}
%  If~$I$ and~$J$ are two Lie~algebra over the same field~$\kf$ then their product~$I \times J$ contains the linear subspaces~$I' \defined I \times 0$ and~$J' \defined 0 \times J$ as ideals.
%  These ideals are isomorphic to~$I$ and~$J$ as Lie~algebras via the isomorphisms
%  \begin{alignat*}{2}
%    I
%    &\to
%    I'  \,,
%    &
%    \quad
%    x
%    &\mapsto
%    (x,0) \,,
%    \\
%    J
%    &\to
%    J'  \,,
%    &
%    \quad
%    y
%    &\mapsto
%    (0,y) \,.
%  \end{alignat*}
	Let~$\glie$ be a Lie~algebra and let~$I_\lambda$ with~$\lambda$ in~$\Lambda$ be a family of ideals of~$\glie$ such that~$I = \bigoplus_{\lambda \in \Lambda} I_\lambda$ as vector spaces.
	In other words, the underlying vector space of~$\glie$ is the internal direct sum of the underlying vector spaces of the ideals~$I_\lambda$.
	Let~$\glie$ be a~{\liealgebra{$\kf$}} and let~$I_\lambda$ with~$\lambda$ in~$\Lambda$ be a family of ideals of~$\glie$ such that
	\[
		\glie
		=
		\bigoplus_{\lambda \in \Lambda}
		I_\lambda
	\]
	as vector spaces.
	It then follows for any two distinct indices~$\mu$ and~$\kappa$ that the ideals~$I_\mu$ and~$I_\kappa$ commute with each other in~$\glie$.
	Indeed, the commutator subspace~$[I_\mu, I_\kappa]$ is contained in~$I_\mu$ because~$I_\mu$ is an ideal in~$\glie$.
	This commutator subspace is for the same reason also contained in~$I_\kappa$.
	It follows that~$[I_\mu, I_\kappa]$ is contained in~$I_\mu \cap I_\kappa = 0$, which means that~$[I_\mu, I_\kappa]$ vanishes.

	It follows that the isomorphism of vector spaces
	\[
		\bigoplus_{\lambda \in \Lambda}
		I_\lambda
		\to
		\glie \,,
		\quad
		(x_\lambda)_\lambda
		\mapsto
		\sum_{\lambda \in \Lambda} x_\lambda
	\]
	is an isomorphism of Lie~algebras.

	Let~$\hlie$ be another~\liealgebra{$\kf$}.
	It now follows from \cref{homomorphism out of direct sum} that a homomorphism of Lie~algebras~$\varphi$ from~$\glie$ to~$\hlie$ is \enquote{the same} as a collection of Lie~algebra homomorphisms~$\varphi_\lambda$ from~$I_\lambda$ to~$\hlie$ where~$\lambda$ ranges through~$\Lambda$ and such that the images of~$\varphi_\mu$ and~$\varphi_\kappa$ commute in~$\hlie$ for any two distinct indices~$\mu$ and~$\kappa$.
\end{example}


\begin{definition}
	In the situation of \cref{direct sum of ideals} the Lie~algebra~$\glie$ is the \defemph{internal direct sum}\index{internal direct sum of lie algebras}\index{direct sum of Lie algebras!internal} the ideals~$I_\lambda$.
\end{definition}


\subsection{Universal Property of the Quotient}


\begin{theorem}[Homomorphism theorem]
	\label{homomorphism theorem}
	Let~$\glie$ be a Lie~algebra and let~$I$ be an ideal of~$\glie$.
	\begin{enumerate}
		\item
			The canonical projection map
			\[
				\pi
				\colon
				\glie
				\to
				\glie/I \,,
				\quad
				x
				\mapsto
				\class{x}
			\]
			is a homomorphism of Lie~algebras.
	\end{enumerate}
	Let~$\hlie$ be another Lie~algebra.
	\begin{enumerate}[resume*]
		\item
			Let~$\psi$ be a homomorphism of Lie~algebras from~$\glie/I$ to~$\hlie$.
			The composite~$\psi \circ \pi$ is a homomorphism of Lie~algebras from~$\glie$ to~$\hlie$ whose kernel contains~$I$.
		\item
			Let conversely~$\varphi$ be a homomorphism of Lie~algebras from~$\glie$ to~$\hlie$.
			The homomorphism~$\varphi$ factors through a homomorphism of Lie~algebras~$\psi$ from~$\glie/I$ to~$\hlie$ that makes the diagram
			\[
				\begin{tikzcd}
					\glie
					\arrow{r}[above]{\varphi}
					\arrow{d}[left]{\pi}
					&
					\hlie
					\\
					\glie/I
					\arrow[dashed]{ur}[below right]{\psi}
					&
					{}
				\end{tikzcd}
			\]
			commute if and only if the ideal~$I$ is contained in the kernel of~$\ker(\varphi)$.
			The homomorphism~$\psi$ is unique and given by
			\[
				\psi( \class{x} )
				=
				\varphi(x)
				\qquad
				\text{for every~$x \in \glie$.}
			\]
			The image and kernel of~$\psi$ are given by~$\im(\psi) = \im(\varphi)$ and~$\ker(\psi) = \ker(\varphi)/I$.
		\qed
	\end{enumerate}
\end{theorem}


%TODO: Add a proof.


\begin{remark}
	The homomorphism theorem is also known as the \defemph{universal property of the quotient}\index{universal property!of quotient Lie algebra}.
\end{remark}


\begin{corollary}[Isomorphism theorems]
	\label{isomorphism theorems}
	Let~$\glie$ be a Lie~algebra.
	\begin{enumerate}
		\item
			\label{first isomorphism theorem}
			Let~$\hlie$ be another Lie~algebra and let~$\varphi$ be a homomorphism of Lie~algebras from~$\glie$ to~$\hlie$.
			The homomorphism~$\varphi$ induces a well-defined isomorphism of Lie~algebras
			\[
				\glie / {\ker(\varphi)}
				\to
				\im(\varphi)  \,,
				\quad
				\class{x}
				\mapsto
				\class{\varphi(x)} \,.
			\]
		\item
			Let~$I$ and~$J$ be two ideals of~$\glie$ such that~$I$ is contained in~$J$.
			The quotient~$J/I$ is an ideal of the Lie~algebra~$\glie/I$ and the natural isomorphism of vector spaces
			\[
				(\glie/I) / (J/I)
				\to
				\glie/I \,,
				\quad
				\class{ \class{x} }
				\mapsto
				\class{x}
			\]
			is already a natural isomorphism of Lie~algebras.
		\item
			Let~$\hlie$ is a Lie~subalgebra of~$\glie$ and let~$I$ is an ideal of~$\glie$.
			Then the sum~$\hlie + I$ is a Lie~subalgebra of~$\glie$ that contains the ideal~$I$, and the intersection~$\hlie \cap I$ is an ideal of~$\hlie$.
			The natural isomorphism of vector spaces
			\begin{gather*}
				\hlie/(\hlie \cap I)
				\to
				(\hlie + I)/I \,,
				\quad
				\class{x}
				\mapsto
				\class{x}
			\end{gather*}
			is already a natural isomorphism of Lie~algebras.
		\qed
	\end{enumerate}
\end{corollary}


%\begin{lemma}
%  \label{homomorphisms respect commutators of sets}
%  If~$\varphi \colon \glie \to \hlie$ is a homomorphism of Lie~algebras then
%  \[
%    \varphi([X,Y])
%    =
%    [\varphi(X), \varphi(Y)]
%  \]
%  for any two subsets~$X$,~$Y$ of~$\glie$.
%  \qed
%\end{lemma}


\begin{proposition}
	Let~$\glie$ and~$\hlie$ be two Lie~algebras and let~$\varphi$ be a homomorphism of Lie~algebras from~$\glie$ to~$\hlie$.
	\begin{enumerate}
		\item
			For every Lie~subalgebra~$\klie$ of~$\hlie$ its preimage~$\varphi^{-1}(\klie)$ is a Lie~subalgebra of~$\glie$.
		\item
			For every Lie~subalgebra~$\klie$ of~$\glie$ its image~$\varphi(\klie)$ is a Lie~subalgebra of~$\hlie$.
		\item
			For every ideal~$I$ of~$\hlie$ its preimage~$\varphi^{-1}(I)$ is an ideal of~$\glie$.
		\item
			Suppose the homomorphism~$\varphi$ is surjective.
			Then for every ideal of~$I$ of~$\glie$ its image~$\varphi(I)$ is an ideal of~$\hlie$.
		\qed
	\end{enumerate}
\end{proposition}


\begin{warning}
	Let~$\glie$ and~$\hlie$ be two Lie~algebras and let~$\varphi$ be a homomorphism of Lie~algebras from~$\glie$ to~$\hlie$.
	For an ideal~$I$ in~$\glie$ is it in general not true that the image~$\varphi(I)$ is an ideal of~$\hlie$.

	Indeed, let~$\hlie$ be some Lie~algebra and let~$\glie$ be a Lie~subalgebra of~$\hlie$ that is not an ideal of~$\hlie$.
	Then~$I \defined \glie$ is an ideal of~$\glie$ and the inclusion map~$\iota$ from~$\glie$ to~$\hlie$ is a homomorphism of Lie~algebras.
	But the image~$\iota(I) = \hlie$ is by construction not an ideal of~$\hlie$.
\end{warning}


\begin{proposition}[Correspondence theorem]
	\label{correspondence theorem}
	Let~$I$ be an ideal of a Lie~algebra~$\glie$ and let
	\[
		\pi
		\colon
		\glie
		\to
		\glie / I
	\]
	denote the canonical quotient map.
	\begin{enumerate}
		\item
			Let~$\hlie$ be a Lie~subalgebra of~$\glie$ that contains the ideal~$I$.
			The quotient~$\hlie/I$ is a Lie~subalgebra of of~$\glie/I$, and this construction induces a {\onetoonetext} correspondence
			\begin{align*}
				\left\{
					\begin{tabular}{@{}c@{}}
						Lie~subalgebras $\hlie$ of~$\glie$ \\
						containing~$I$
					\end{tabular}
				\right\}
				&\longleftrightarrow
				\{ \text{Lie~subalgebras~$\klie$ of~$\glie/I$} \} \,,
				\\
				\hlie
				&\mapsto
				\hlie/I \,,
				\\
				\pi^{-1}(\klie)
				&\mapsfrom
				\klie \,.
		\intertext{
		\item
			This correspondence restricts to a {\onetoonetext} correspondence
		}
				\left\{
					\begin{tabular}{@{}c@{}}
						Lie~ideals~$J$ in~$\glie$ \\
						containing~$I$
					\end{tabular}
				\right\}
				&\longleftrightarrow
				\{ \text{Lie~ideals~$K$ in~$\glie/I$} \} \,,
				\\
				J
				&\mapsto
				J/I \,,
				\\
				\pi^{-1}(K)
				&\mapsfrom
				K \,.
			\end{align*}
		\item
			Let~$J$ be an ideal of~$\glie$ containing~$I$.
			For the corresponding ideal~$J/I$ of~$\glie/I$ the resulting quotient Lie~algebras~$\glie/J$ and~$(\glie/I)/(J/I)$ are isomorphic via the third isomorphism theorem.
		\qed
	\end{enumerate}
\end{proposition}


\subsection{Universal Property of the Abelianization}


\begin{example}[Universal property of abelianization]
	\index{universal property!of abelianization}
	\label{universal property of abelianization}
	Let~$\glie$ be a~\liealgebra{$\kf$} and let~$\hlie$ be an abelian~\liealgebra{$\kf$}.
	If~$\varphi$ is any homomorphism of Lie~algebras from~$\glie$ to~$\hlie$ then the image of~$\varphi$ is a Lie~subalgebra of~$\glie$, which is then again abelian.
	It follows from the isomorphism between~$\im(\varphi)$ and~$\glie / {\ker(\varphi)}$ that the quotiont Lie~algebra~$\glie / {\ker(\varphi)}$ is abelian.
	The ideal~$\ker(\varphi)$ must therefore contain the commutator ideal~$[\glie, \glie]$, as seen in \cref{quotient is abelian iff moded out the commutator ideal}.
	The homomorphism~$\varphi$ does therefore factor through a homomorphism from~$\glie^{\ab}$ to~$\hlie$.
	This construction gives a {\onetoonetext} correspondence
	\[
		\left\{
			\begin{tabular}{c}
				homomorphisms of \\
				Lie~algebras~$\glie \to \hlie$
			\end{tabular}
		\right\}
		\onetoone
		\left\{
			\begin{tabular}{c}
				homomorphisms of \\
				Lie~algebras $\glie^{\ab} \to \hlie$
			\end{tabular}
		\right\}
		=
		\{
			\textstyle
			\text{linear maps~$\glie^{\ab} \to \hlie$}
		\} \,.
	\]
\end{example}


\begin{proposition}
	\label{functoriality of abelianization}
	Let~$\glie$ and~$\hlie$ be two~\liealgebras{$\kf$} and let~$\varphi$ be a homomorphism of Lie~algebras from~$\glie$ to~$\hlie$.
	The homomorphism~$\varphi$ induces a homomorphism of Lie~algebras
	\[
		\varphi^{\ab}
		\colon
		\glie^{\ab}
		\to
		\hlie^{\ab} \,,
		\quad
		\class{x}
		\mapsto
		\class{\varphi(x)} \,.
	\]
\end{proposition}


\begin{proof}
	The homomorphism~$\varphi$ maps the commutator ideal~$[\glie, \glie]$ into the commutator ideal~$[\hlie, \hlie]$.
	It thus induces a homomorphism from~$\glie / [\glie, \glie]$ to~$\hlie / [\hlie, \hlie]$ as desired.
\end{proof}


\begin{remark}
	Let~$\cLieab{\kf}$\glsadd{category abelian lie algebras} denote the full subcategory of~$\cLie{\kf}$ whose class of objects consists of those~\liealgebras{$\kf$} which are abelian.
	Let~$U$ be the forgetful functor from~$\cLieab{\kf}$ to~$\cLie{\kf}$ (i.e. the inclusion functor).

	We also have a functor~$(-)^{\ab}$ from~$\cLie{\kf}$ to~$\cLieab{\kf}$.
	This functor assigns to each~\liealgebra{$\kf$}~$\glie$ its abelianization~$\glie^{\ab}$ and to each homomorphism of Lie~algebras~$\varphi$ from~$\glie$ to~$\hlie$ the induced homomorphism of Lie~algebras~$\varphi^{\ab}$ from~$\glie^{\ab}$ to~$\hlie^{\ab}$ as introduced in~\cref{functoriality of abelianization}.

	The discussion in \cref{universal property of abelianization} tells us that the abelianization functor~$(\ph)^{\ab}$ is left adjoint to the forgetful functor~$U$.
\end{remark}


\subsection{Universal Property of Extension of Scalars}


\begin{proposition}[Universal property of extension of scalars]
	\index{universal property!of extension of scalars}
	Let~$\glie$ be a~\liealgebra{$\kf$}, let~$A$ be a commutative~\algebra{$\kf$} and let~$\hlie$ be an~\liealgebra{$A$}.
	Every homomorphism of~\liealgebras{$\kf$}~$\varphi$ from~$\glie$ to~$\hlie$ extends uniquely to a homomorphism of~\liealgebras{$A$}~$\psi$ from~$A \tensor_{\kf} \glie$ to~$\hlie$.
\end{proposition}


\begin{proof}
	We know from linear algebra that the homomorphism~$\varphi$ extends uniquely to an~\linear{$A$} map~$\psi$ from~$A \tensor_{\kf} \glie$ to~$\hlie$.
	The compatibility of~$\psi$ with the Lie~brackets of~$A \tensor_{\kf} \glie$ and~$\hlie$ can be checked on an~\generating{$A$} set of~$A \tensor_{\kf} \glie$.
	Such a generating set is given by~$\glie$, on which~$\psi$ agrees with~$\varphi$, and where it is therefore compatible with the Lie~brackets by assumption.
\end{proof}


\subsection{Anti-homomorphisms}


\begin{recall}
	\index{anti-homomorphism!of algebras@of \enquote{algebras}}
	\label{anti-homomorphisms for general algebras}
	Let~$A$ and~$B$ be two~\enquote{\algebras{$\kf$}}.
	A map~$\Phi$ from~$A$ ot~$B$ is an \defemph{anti-homomorphism} if it is~{\linear{$\kf$}} and satisfies the condition
	\[
		\Phi(ab)
		=
		\Phi(b) \Phi(a)
		\qquad
		\text{for all~$a, b \in A$.}
	\]
	For a map~$\Phi$ from~$A$ to~$B$ the following conditions are equivalent.
	\begin{equivalenceslist*}
		\item
			$\Phi$ is an anti-homomorphism from~$A$ to~$B$.
		\item
			$\Phi$ is a homomorphism from~$A^{\op}$ to~$B$.
		\item
			$\Phi$ is a homomorphism from~$A$ to~$B^{\op}$.
		\item
			$\Phi$ is an anti-homomorphism from~$A^{\op}$ to~$B^{\op}$.
	\end{equivalenceslist*}

	An anti-homomorphism~$\Phi$ from~$A$ to~$B$ is an \defemph{anti-isomorphism}\index{anti-isomorphism!of algebras@of \enquote{algebras}} if there exists another anti-homomorphism~$\Psi$ from~$B$ to~$A$ with both~$\Psi \circ \Phi = \id_A$ and~$\Phi \circ \Psi = \id_B$.
	For a map~$\Phi$ from~$A$ to~$B$ the following conditions are equivalent.
	\begin{equivalenceslist*}
		\item
			$\Phi$ is an anti-isomorphism from~$A$ to~$B$.
		\item
			$\Phi$ is an isomorphism from~$A^{\op}$ to~$B$.
		\item
			$\Phi$ is an isomorphism from~$A$ to~$B^{\op}$.
		\item
			$\Phi$ is an anti-isomorphism from~$A^{\op}$ to~$B^{\op}$.
	\end{equivalenceslist*}

	It follows in particular that an anti-homomorphism of~\enquote{\algebras{$\kf$}} is an anti-isomorphism if and only if it is bijective.
\end{recall}


\begin{fluff}
	The general definitions of anti-homomorphisms and anti-isomorphisms for \enquote{algebras} from \cref{anti-homomorphisms for general algebras} can in particular be applied to Lie~algebras.
	We will make this explicit now:
\end{fluff}


\begin{definition}
	Let~$\glie$ and~$\hlie$ be two~\liealgebras{$\kf$}.
	\begin{enumerate}
		\item
			A map~$\varphi$ from~$\glie$ and~$\hlie$ is an \defemph{anti-homomorphism}\index{anti-homomorphism!of Lie algebras} of Lie~algebras if it is~\linear{$\kf$} and satisfies the condition
			\[
				\varphi([x,y]) = [\varphi(y), \varphi(x)]
				\qquad
				\text{for all~$x, y \in \glie$.}
			\]
		\item
			An anti-homomorphism of Lie~algebras~$\varphi$ from~$\glie$ to~$\hlie$ is an \defemph{anti-isomorphism}\index{anti-isomorphism!of Lie algebras} if there exists an anti-homomorphism of Lie~algebras~$\psi$ from~$\hlie$ to~$\glie$ such that both~$\varphi \circ \psi = \id_{\hlie}$ and~$\psi \circ \varphi = \id_{\glie}$.
	\end{enumerate}
\end{definition}


\begin{remark}
	\label{characterizations of anti-homomorphisms for lie algebras}
	The characterizations of anti-homomorphisms and anti-isomorphisms of \enquote{algebras} from \cref{anti-homomorphisms for general algebras} apply in particular to anti-homomorphisms and anti-isomorphisms of Lie~algebras.
	We will therefore not spill out these equivalences a second time.
	Instead, we advise the reader to take the equivalences in \cref{anti-homomorphisms for general algebras} and replace~$A$ by~$\glie$ and~$B$ by~$\hlie$.
\end{remark}


\begin{proposition}
	\label{lie algebra isomorphic to its opposite}
	Every Lie~algebra~$\glie$ is isomorphic to its opposite Lie~algebra~$\glie^{\op}$ via the map
	\[
		\glie
		\to
		\glie^{\op}\,,
		\quad
		x
		\mapsto
		-x^{\op}  \,.
	\]
\end{proposition}


\begin{proof}
	The map~$\varphi$ from~$\glie$ to~$\glie^{\op}$ given by~$x \mapsto -x^{\op}$ for every~$x \in \glie$ is linear, and it is an anti-homomorphism of Lie~algebras because
	\[
		\varphi([x, y])
		=
		-[x,y]^{\op}
		=
		-[ y^{\op}, x^{\op} ]
		=
		[ x^{\op}, y^{\op} ]
		=
		[ -x^{\op}, -y^{\op} ]
		=
		[ \varphi(x), \varphi(y) ]
	\]
	for all~$x, y \in \glie$.
	It is also bijective, and thus an isomorphism of Lie~algebras.
\end{proof}


\begin{corollary}
	We have for any two~\liealgebras{$\kf$}~$\glie$ and~$\hlie$ a {\onetoonetext} correspondence given by
	\begin{align*}
		\SwapAboveDisplaySkip
		\left\{
			\begin{tabular}{c}
				anti-homomorphisms \\
				of Lie~algebras~$\glie \to \hlie$
			\end{tabular} 
		\right\}
		&\onetoone
		\left\{
			\begin{tabular}{c}
				homomorphisms \\
				of Lie~algebras~$\glie \to \hlie$
			\end{tabular}
		\right\} \,,
		\\
		\varphi
		&\mapsto
		-\varphi \,,
		\\
		-\varphi
		&\mapsfrom
		\varphi \,.
	\end{align*}
\end{corollary}


\begin{proof}
	This is a combination of \cref{anti-homomorphisms for general algebras}, respectively \cref{characterizations of anti-homomorphisms for lie algebras}, and \cref{lie algebra isomorphic to its opposite}.
\end{proof}





\section{Simple Lie~Algebras}
\label{simple lie algebras}


\begin{definition}
	A Lie~algebra~$\glie$ is \defemph{simple}\index{simple Lie algebra} if it is non-abelian and the only ideals of~$\glie$ are~$0$ and~$\glie$.
\end{definition}


\begin{remark}
	\leavevmode
	\begin{enumerate}
		\item
			Any simple Lie~algebra is in particular nonzero.
		\item
			A Lie~algebra is simple if and only if it is non-abelian and contains precisely two ideals.
	\end{enumerate}
\end{remark}


\begin{examples}
	\label{examples for simple lie algebras}
	\leavevmode
	\begin{enumerate}
		\item
			The Lie~algebra~$\gllie(n, \kf)$ isn’t simple.
			For~$n = 0$ it is zero, for~$n = 1$ it is abelian, and for~$n \geq 1$ it contains~$\sllie(n,\kf)$ as a nonzero, proper ideal.
		\item
			The Lie~algebra~$\sllie(2, \kf)$ is simple if and only if the field~$\kf$ does not have characteristic~$2$.
			To prove this we consider the standard basis
			\[
				e
				=
				\begin{pmatrix}
					0 & 1 \\
					0 & 0
				\end{pmatrix} \,,
				\qquad
				h
				=
				\begin{pmatrix*}[r]
					1 &  0  \\
					0 & -1
				\end{pmatrix*} \,,
				\qquad
				f
				=
				\begin{pmatrix}
					0 & 0 \\
					1 & 0
				\end{pmatrix}
			\]
			of~$\sllie(2, \kf)$, on which the Lie~bracket of~$\sllie(2, \kf)$ is given by the relations
			\[
				[h,e] = 2e  \,,
				\qquad
				[h,f] = -2 f \,,
				\qquad
				[e,f] = h \,.
			\]
			
			If the field~$\kf$ is of characteristic~$2$ then the element~$h$ spans a {\onedimensional} ideal, which then shows that~$\sllie(2, \kf)$ is not simple.
			
			Let us consider in the following the case that the field~$\kf$ is not of characteristic~$2$.
			Let~$I$ be a nonzero ideal of~$\sllie(2, \kf)$ and let~$x$ be some nonzero element of~$I$.
			We may write the element~$x$ as a linear combination
			\[
				x = \alpha e + \beta h + \gamma f
			\]
			for some scalar~$\alpha$,~$\beta$,~$\gamma$ in~$\kf$.
			It follows that
			\[
				[e,x]
				=
				-2 \beta e + \gamma h \,,
				\qquad \text{and thus}\qquad
				[e,[e,x]]
				=
				-2 \gamma e \,.
			\]
			The elements~$[e,x]$ and~$[e,[e,x]]$ are both again contained in~$I$ because~$I$ is an ideal of~$\sllie(2, \kf)$.

			It now follows that the ideal~$I$ contains the basis vector~$e$.
			If the scalar~$\gamma$ is nonzero, then it follows from the equality~$[e,[e,x]] = -2 \gamma e$ that
			\[
				e
				=
				- \frac{ [e,[e,x]] }{ 2\gamma } \,.
			\]
			If~$\gamma$ vanishes but the scalar~$\beta$ is nonzero then it follows from the equality$[e,x] = -2 \beta e$ that
			\[
				e
				=
				-\frac{ [e,x] }{ 2\beta } \,.
			\]
			If both~$\beta$ and~$\gamma$ vanish then it follows that~$\alpha$ must be nonzero because~$x$ is nonzero, and it then follows from the equality~$x = \alpha e$ that
			\[
				e = \frac{x}{\alpha} \,.
			\]
			We find in each case that the basis vector~$e$ is contained in the ideal~$I$, because the elements~$x$,~$[e,x]$ and~$[e,[e,x]]$ are contained in~$I$.
			
			It further follows that the basis elements~$h$ and~$f$ are also contained in~$I$ because~$h = [e,f]$ and~$f = -[h,f]/2$.
			We have thus altogether found that the ideals~$I$ contains all three standard basis vectors of~$\sllie(2 \kf)$, and must therefore equal~$\sllie(2, \kf)$.
	\end{enumerate}
\end{examples}


\begin{proposition}
	\label{commutator and center of simple}
	Let~$\glie$ be a simple Lie~algebra.
	Then~$\glie$ has trivial center and is perfect.
\end{proposition}


\begin{proof}
	The Lie~algebra~$\glie$ is nonabelian because it is simple.
	We therefore find that the commutator ideal~$[\glie, \glie]$ is a nonzero ideal of~$\glie$, and we also find that the center~$\centerlie(\glie)$ is a proper ideal of~$\glie$.
	But~$\glie$ admits only two ideals because it is simple, namely the zero ideal and~$\glie$ itself.
	It therefore follows that~$[\glie, \glie] = \glie$ and~$\centerlie(\glie) = 0$.
\end{proof}


\begin{corollary}
	\label{ad is injective for simple}
	Let~$\glie$ be a simple Lie~algebra.
	The homomorphism of Lie~algebras~$\ad$ from~$\glie$ to~$\gllie(\glie)$ is injective.
\end{corollary}


\begin{proof}
	The kernel of~$\ad$ is the center of~$\glie$, which vanishes by \cref{commutator and center of simple}.
\end{proof}


\begin{corollary}
	Every finite-dimensional, simple Lie~algebra is isomorphic to a linear Lie~algebra.
	\qed
\end{corollary}


\begin{fluff}
	A famous theorem due to Ado -- that we will not attempt to prove in this lecture -- states that this conclusion actually holds for every finite-dimensional Lie~algebra.
\end{fluff}


\begin{theorem}[Ado, first version]
	\label{Ado’s theorem}
	Every finite-dimensional Lie~algebra is isomorphic to a linear Lie~algebra.
\end{theorem}


\begin{fluff}
	We finish this \lcnamecref{simple lie algebras} by proving the general simplicity of~$\sllie(n, \kf)$.
\end{fluff}


\begin{theorem}[Simplicity of~$\sllie(n, \kf)$]
	\label{sln is simple}
	Let~$\kf$ be any field.
	The Lie~algebra~$\sllie(n, \kf)$ is simple if and only if~$n \geq 2$ and the characteristic of~$\kf$ does not divide~$n$.
\end{theorem}


\begin{proof}
	The assertion holds for~$n = 0$ and~$n = 1$ because~$\sllie(2, \kf)$ is then zero, and therefore not simple.
	We have also proven the assertion for~$n = 2$ in \cref{examples for simple lie algebras}.
	We will therefore assume in the following that~$n \geq 3$.

	Suppose first that the characteristic of~$\kf$ divides~$n$.
	The identity matrix is then contained in~$\sllie(n, \kf)$, which shows that the center of~$\sllie(n, \kf)$ is nonzero.
	It follows from \cref{commutator and center of simple} that~$\sllie(n, \kf)$ is not simple.

	Suppose in the following that the characteristic of~$\kf$ does not divide~$n$.
	We abbrevite~$\sllie(n, \kf)$ as~$\glie$, and denote by~$\hlie$ its Lie~subalgebra of traceless diagonal matrices.
	We consider the decomposition
	\begin{equation}
		\label{decomposition of sln for simplicity}
		\glie
		=
		\hlie \oplus \bigoplus_{i \neq j} \gen{ E_{ij} }_{\kf} \,.
	\end{equation}
	Let~$I$ be a nonzero ideal of~$\glie$.
	We show in the following that~$I$ already equals~$\glie$.
	To do this let~$A$ be a nonzero matrix contained in~$I$.
	With respect to the decomposition~\eqref{decomposition of sln for simplicity} we can write the matrix~$A$ as
	\[
		A = A' + \sum_{i \neq j} \alpha_{ij} E_{ij}
	\]
	for some coefficients~$\alpha_{ij}$ in~$\kf$.

	Let us first show that the ideal~$I$ contains some nonzero diagonal matrix.
	If all coefficients~$\alpha_{ij}$ vanish, then~$A = A'$ is this desired matrix.
	Suppose otherwise that the coefficient~$\alpha_{ij}$ does not vanish for some indices~$i$ and~$j$.
	For every~$k = 1, \dotsc, n$ let~$D_k$ be the diagonal matrix whose entries are~$1/n$, except for the~\howmanyth{$k$} one, which is~$1/n - 1$.
	The matrix~$D_k$ has trace zero and is thus contained in~$\glie$.
	It follows from \cref{background on diagonal matrices} that the commutator~$[D_i, A]$ arises from~$A$ by
	\begin{itemize}
		\item
			deleting all diagonal entries of~$A$,
		\item
			multiplying the~\howmanyth{$i$} column with~$1$, and the~\howmanyth{$i$} row with~$-1$ (except for the deleted diagonal entry~$A_{ii}$), and
		\item
		  removing all other entries of~$A$.
	\end{itemize}
	It follows that the matrix~$[D_i, [D_j, A]]$ is again contained in~$I$ and that it is given by
	\[
		\widetilde{A}
		\defined
		- \alpha_{ij} E_{ij} - \alpha_{ji} E_{ji} \,.
	\]
	It follows that the matrix
	\[
		\Bigl[ E_{ji}, - \widetilde{A} \Bigr]
		=
		\alpha_{ij} ( E_{jj} - E_{ii} )
	\]
	is contained in~$I$.
	This is the desired nonzero diagonal matrix in~$I$.

	Let us now show that the ideal~$I$ contains some matrix~$E_{ij}$.
	We consider for this a nonzero diagonal matrix~$D$ contained in~$I$.
	The matrix~$D$ cannot be a scalar multiple of the identity matrix because the characteristic of~$\kf$ does not divide the size~$n$.
	It follows that there exist two indices~$i$ and~$j$ such that the diagonal entries~$D_{ii}$ and~$D_{jj}$ are distinct.
	It follows that the matrix
	\[
		\frac{1}{D_{ii} - D_{jj}} [D, E_{ij}]
		=
		E_{ij}
	\]
	is again contained in the ideal~$I$.

	We now show that the ideal~$I$ contains every matrix~$E_{kl}$ where~$k$ and~$l$ are distinct.
	We have already shown that the ideal~$I$ contains some matrix~$E_{ij}$.
	We distinguish now between the following cases:
	\begin{itemize}
		\item
			If~$(i,j) = (k,l)$ then~$E_{kl} = E_{ij}$ is contained in~$I$.
		\item
			If~$i = k$ but~$j \neq l$ then the matrix~$E_{jl}$ is contained in~$\glie$, and it follows that
			\[
				[ E_{ij}, E_{jl} ]
				=
				[ E_{kj}, E_{jl} ]
				=
				E_{kl}
			\]
			is indeed contained in~$I$.
		\item
			Similarly, if~$i \neq k$ but~$j = l$ then the matrix~$E_{ki}$ is contained in~$\glie$, and it follows that
			\[
				[ E_{ki}, E_{ij} ]
				=
				[ E_{ki}, E_{il} ]
				=
				E_{kl}
			\]
			is indeed contained in~$I$.
		\item
			Suppose that~$i \neq j$ and~$j \neq i$.
			There exists an index~$k$ that is distinct from both~$i$ and~$j$ because~$n \geq 3$.
			It follows that the matrix~$E_{ki}$ is contained in~$\glie$, and hence that the matrix
			\[
				[E_{ki}, E_{ij}]
				=
				E_{kj}
			\]
			is again contained in~$I$.
			It follows from the previous case that~$E_{kl}$ is contained in~$I$.
	\end{itemize}
	It now follows that the Lie subalgebra~$\hlie$ of~$\glie$ is contained in~$I$.
	Indeed, a vector space generating set of~$\hlie$ is given by the matrices~$E_{ii} - E_{jj}$ with~$i \neq j$.
	We have already seen that the matrices~$E_{ij}$ and~$E_{ji}$ are contained in~$I$, whence it follows that
	\[
		[E_{ij}, E_{ji}]
		=
		E_{ii} - E_{jj}
	\]
	is contained in~$I$.

	We have altogether shown that the ideal~$I$ contains both the Lie~subalgebra~$\hlie$ of~$\glie$ and all matrices~$E_{ij}$ with~$i \neq j$.
	It follows from the decomposition~\eqref{decomposition of sln for simplicity} that~$I$ equals~$\glie$.
\end{proof}


\begin{remark}
	It follows from \cref{sln is simple} and \cref{commutator and center of simple} that
	\[
		[\sllie(n, \kf), \sllie(n, \kf)]
		=
		\sllie(n, \kf) \,.
	\]
	In other words, every matrix of trace zero is a linear combination of commutators.
	It was proven in \cite{albert_muckenhoupt_matrices_trace_zero} that every matrix of trace zero is already a commutator itself
\end{remark}





\section{Derivations and Inner Automorphisms}


\subsection{Derivations}


\begin{definition}
	\label{definition of derivations}
	\index{derivation!of an algebra@of an~\enquote{algebras}}
	Let~$A$ be a~\enquote{\algebra{$\kf$}}.
	A \defemph{derivation} of~$A$ is a~{\linear{$\kf$}} map~$\delta$ from~$A$ to~$A$ such that
	\[
		\delta(ab)
		=
		\delta(a) b + a \delta(b)
		\qquad
		\text{for all~$a, b \in A$.}
	\]
	The set of derivations of~$A$ is denoted by
	\[
		\Der(A)
		\defined
		\{
			\delta
			\colon
			A
			\textstyle\to
			A
		\suchthat
			\text{$\delta$ is a derivation of~$A$}
		\}  \,.
		\glsadd{derivations}
	\]
\end{definition}


\begin{proposition}
	Let~$A$ be a~\enquote{\algebra{$\kf$}}.
	The set~$\Der(A)$ is a Lie~subalgebra of~$\gllie(A)$.
\end{proposition}


\begin{proof}
	For any two element~$a$,~$b$ of~$A$, the auxiliary map
	\[
		h_{ab}
		\colon
		\gllie(A)
		\to
		A \,,
		\quad
		\delta
		\mapsto
		\delta(ab) - \delta(a)b - a \delta(b)
	\]
	is linear.
	It follows that
	\[
		\Der(A)
		=
		\bigcap_{a, b \in A}
		\ker( h_{ab} )
	\]
	is a linear subspace of~$\gllie(A)$.
	If~$\delta_1$ and~$\delta_2$ are any two derivations of~$A$ then
	\[
		\delta_1( \delta_2(ab) )
		=
		\delta_1( \delta_2(a) b + a \delta_2(b) )
		=
		\delta_1(\delta_2(a)) + \delta_2(a) \delta_1(b)
		+ \delta_1(a) \delta_2(b) + a \delta_1( \delta_2(b) )
	\]
	for all~$a, b \in A$, and therefore
	\begin{align*}
		[\delta_1, \delta_2](ab)
		&=
		(\delta_1 \delta_2 - \delta_2 \delta_1)(ab)
		\\
		&=
		\delta_1( \delta_2(ab) ) - \delta_2( \delta_1(ab) )
		\\
		&=
		\delta_1(\delta_2(a)) b + a \delta_1(\delta_2(b))
		- \delta_2(\delta_1(a)) b - a \delta_2(\delta_1(b))
		\\
		&=
		(\delta_1 \delta_2 - \delta_2 \delta_1)(a) b
		+ a (\delta_1 \delta_2 - \delta_2 \delta_1)(b)
		\\
		&=
		[\delta_1, \delta_2](a) b + a [\delta_1, \delta_2](b) \,.
	\end{align*}
	This shows that the commutator~$[\delta_1, \delta_2]$ of any two derivations~$\delta_1$ and~$\delta_2$ of~$A$ is again such a derivation.
	This means that the linear subspace~$\Der(A)$ of~$\gllie(A)$ is indeed a Lie~subalgebra.
\end{proof}


\begin{remark}
	\label{derivations made explicit}
	Let us unravel the definition of a derivation in some special cases.
	\begin{enumerate}
		\item
			Let~$\glie$ be a Lie~algebra.
			A derivation of~$\glie$\index{derivation!of Lie algebra} is a vector space endomorphism~$\delta$ of~$\glie$ such that
			\[
				\delta([x,y])
				=
				[\delta(x), y] + [x, \delta(y)]
				\qquad
				\text{for all~$x, y \in \glie$.}
			\]
		\item
			Let~$A$ be a commutative~\algebra{$\kf$}.
			A derivation of~$A$\index{derivation!of a commutative algebra} is a vector space endomorphism~$\delta$ of~$A$ such that
			\[
				\delta(ab)
				=
				\delta(a) b + a \delta(b)
				\qquad
				\text{for all~$a, b \in A$}.
			\]
			The~\vectorspace{$\kf$}~$\End_{\kf}(A)$ becomes an~\module{$A$} via the scalar multiplication
			\[
				(a \cdot f)(b)
				\defined
				a \cdot f(b)
				\qquad
				\text{for all~$a, b \in A$ and~$f \in \gllie(A)$.}
			\]
			It follows from the commutativity of~$A$ that~$\Der(A)$ is an~\submodule{$A$} of~$\End_{\kf}(A)$, because
			\begin{align*}
				(a \delta)(b c)
				&=
				a \delta(b c)
				\\
				&=
				a ( \delta(b) c + b \delta(c) )
				\\
				&=
				a \delta(b) c + a b \delta(c)
				\\
				&=
				a \delta(b) c + b a \delta(c)
				\\
				&=
				(a \delta)(b) c + b (a \delta)(c)
			\end{align*}
			for all~$a, b, c \in A$ and~$\delta \in \Der(A)$.
	\end{enumerate}
\end{remark}


\begin{example}
	Let~$\glie$ be an abelian Lie~algebra.
	Every~\linear{$\kf$} endomorphism~$\delta$ of~$\glie$ is already a derivation of~$\glie$ because
	\[
		\delta([x,y])
		=
		0
		=
		[0, y] + [x, 0]
		=
		[\delta(x), y] + [x, \delta(y)]
	\]
	for all~$x, y \in \glie$.
	We thus have the equality~$\Der(\glie) = \gllie(\glie)$.
\end{example}


\begin{example}
	\label{derivations of the two-dimensional non-abelian lie algebra}
	Let~$\glie$ be the two-dimensional, nonabelian Lie~algebra.
	We want to understand under what conditions a vector space endomorphism~$\delta$ of~$\glie$ is a derivation of~$\glie$.
	We use for this the basis~$x$,~$y$ of~$\glie$ with~$[x,y] = y$.
	With respect to this basis we can represent the endomorphism~$\delta$ by a matrix
	\[
		\delta
		\equiv
		\begin{pmatrix}
			a_{11} & a_{12} \\
			a_{21} & a_{22}
		\end{pmatrix} \,.
	\]
	It sufficies to check the condition of a derivation for~$\delta$ on this basis.
	In other words, we want to understand under what conditions the identities
	\begin{alignat*}{2}
		\delta( [x,x] ) &= [ \delta(x), x ] + [ x, \delta(x) ] \,,
		&
		\qquad
		\delta( [y,y] ) &= [ \delta(y), y ] + [ y, \delta(y) ] \,,
		\\
		\delta( [x,y] ) &= [ \delta(x), y ] + [ x, \delta(y) ] \,,
		&
		\qquad
		\delta( [y,x] ) &= [ \delta(y), x ] + [ y, \delta(x) ]
	\end{alignat*}
	hold.
	The equations in the upper row are automatically satisfied because the Lie~bracket is alternating and skew-symmetric, whence both sides of these equations vanish.
	The equations in the lower row are equivalent by the skew-symmetry of the Lie~bracket.
	We therefore only have to worry about the single equation.
	\begin{equation}
		\label{equation for derivation of nonabelian two-dimensional lie algebra}
		\delta( [x,y] )
		=
		[ \delta(x), y ] + [ x, \delta(y) ] \,.
	\end{equation}
	We have
	\[
		[x,y] = y \,,
		\quad
		\delta(x) = a_{11} x + a_{21} y \,,
		\quad
		\delta(y) = a_{12} x + a_{22} y \,.
	\]
	The required equation~\eqref{equation for derivation of nonabelian two-dimensional lie algebra} thus becomes
	\begin{align*}
		{}&
		\delta( [x,y] )
		=
		[ \delta(x), y ] + [ x, \delta(y) ]
		\\
		\iff{}&
		\delta( y )
		=
		[ \delta(x), y ] + [ x, \delta(y) ]
		\\
		\iff{}&
		a_{12} x + a_{22} y
		=
		a_{11} [x,y] + a_{21} [y,y]
		+ a_{12} [x,x] + a_{22} [x,y]
		\\
		\iff{}&
		a_{12} x + a_{22} y
		=
		a_{11} y + a_{22} y
		\\
		\iff{}&
		a_{11} = 0,
		a_{12} = 0 \,.
	\end{align*}

	We have now seen that a vector space endomorphism of~$\glie$ is a derivation of~$\glie$ if and only if its image is contained in the span of~$y$.
	It follows in particular that the Lie~algebra~$\Der(\glie)$ has a basis given by the two vector space endomorphisms~$e_1$ and~$e_2$ of~$\glie$ with
	\[
		e_1(x) = y \,,
		\quad
		e_1(y) = 0 \,,
		\qquad
		e_2(x) = 0 \,,
		\quad
		e_2(y) = y \,.
	\]
	We have
	\[
		[e_1, e_2](x)
		=
		e_1( e_2(x) ) - e_2( e_1(x) )
		=
		e_1(0) - e_2(y)
		=
		0 - y
		=
		- y
	\]
	and
	\[
		[e_1, e_2](y)
		=
		e_1( e_2(y) ) - e_2( e_1(y) )
		=
		e_1( y ) - e_2 ( 0 )
		=
		0 - 0
		=
		0 \,.
	\]
	We thus have~$[e_1, e_2] = -e_1$, or equivalently~$[e_2, e_1] = e_1$.
	This shows that~$\Der(\glie)$ is again the two-dimensional, nonabelian Lie~algebra.
\end{example}


\begin{example}[Derivation of direct sum]
	\index{derivation!of a direct sum}
	\label{derivations of direct sum}
	Let~$\glie$ and~$\hlie$ be two Lie~algebras.
	We give in a following a description of the Lie~algebra~$\Der(\glie \oplus \hlie)$.

	We recall that we may write every linear map~$f$ from~$\glie \oplus \hlie$ to~$\glie \oplus \hlie$ as a matrix
	\[
		\begin{pmatrix}
			a & b \\
			c & d
		\end{pmatrix}
	\]
	whose entries~$a$,~$b$,~$c$ and~$d$ are linear maps.
	These linear maps are given as the composites
	\begin{align*}
		a
		&\colon 
		\glie
		\to
		\glie \oplus \hlie
		\xto{f}
		\glie \oplus \hlie
		\to
		\glie \,,
		\\
		b
		&\colon 
		\hlie
		\to
		\glie \oplus \hlie
		\xto{f}
		\glie \oplus \hlie
		\to
		\glie \,,
		\\
		c
		&\colon 
		\glie
		\to
		\glie \oplus \hlie
		\xto{f}
		\glie \oplus \hlie
		\to
		\hlie \,,
		\\
		d
		&\colon 
		\hlie
		\to
		\glie \oplus \hlie
		\xto{f}
		\glie \oplus \hlie
		\to
		\hlie \,.
	\end{align*}
	The application of~$f$ to an element~$(x,y)$ of~$\glie \oplus \hlie$ is given by
	\[
		f( (x,y) )
		=
		( a(x) + b(y), c(x) + d(y) ) \,.
	\]
	(If one writes the pair~$(x,y)$ as a column vector, then this is the usual matrix-vector multiplication.)

	The composition of linear endomorphisms of~$\glie \oplus \hlie$ corresponds to the multiplication of the corresponding matrices.
	The commutator of two endomorphisms does therefore correpsond to the usual commutator of matrices.

	Let now~$\delta$ be a linear endomorphism of~$\glie \oplus \hlie$ corresponding to a matrix with entries~$a$,~$b$,~$c$,~$d$ as above.
	We need to find out what conditions these matrix entries have to satisfy for~$\delta$ to be a derivation, i.e. to satisfy the identity
	\begin{equation}
		\label{condition for derivation}
		\delta( [x,y] )
		=
		[ \delta(x), y ] + [ x, \delta(y) ]
	\end{equation}
	for all~$x, y \in \glie \oplus \hlie$.
	We may write these elements~$x$ and~$y$ as pairs~$x = (x_1, x_2)$ and~$y = (y_1, y_2)$ for elements~$x_1$,~$y_1$ of~$\glie$ and elements~$x_2$,~$y_2$ of~$\hlie$.
	Then
	\begin{align*}
		\delta( [x, y] )
		&=
		\delta( [ (x_1, x_2), (y_1, y_2) ] )
		\\
		&=
		\delta( ( [x_1, y_1], [x_2, y_2] ) )
		\\
		&=
		\Bigl(
			a( [x_1, y_1] ) + b( [x_2, y_2] ) , \;
			c( [x_1, y_1] ) + d( [x_2, y_2] )
		\Bigr)
	\end{align*}
	as well as
	\begin{align*}
		{}&
		[ \delta(x), y ] + [ x, \delta(y) ]
		\\
		={}&
		[ \delta( (x_1, x_2) ), (y_1, y_2) ]
		+ [ (x_1, x_2), \delta( (y_1, y_2) ) ]
		\\
		={}&
		[ ( a(x_1) + b(x_2), c(x_1) + d(x_2) ) , (y_1, y_2) ]
		+ [ (x_1, x_2), ( a(y_1) + b(y_2), c(y_1) + d(y_2) ) ]
		\\
		={}&
		( [ a(x_1) + b(x_2), y_1 ], [ c(x_1) + d(x_2), y_2 ] )
		+ ( [ x_1, a(y_1) + b(y_2) ] , [ x_2, c(y_1) + d(y_2) ] )
		\\
		={}&
		\Bigl(
			[ a(x_1), y_1 ] + [ b(x_2), y_1 ] + [ x_1, a(y_1) ] + [ x_1, b(y_2) ] ,
		\\
		{}&
		\phantom{ \Bigl( }
			[ c(x_1), y_2 ] + [ d(x_2), y_2 ] + [ x_2, c(y_1) ] + [ x_2, d(y_2) ]
		\Bigr) \,.
	\end{align*}
	We hence need that
	\begin{align*}
		a( [x_1, y_1] ) + b( [x_2, y_2] )
		&=
		[ a(x_1), y_1 ] + [ b(x_2), y_1 ] + [ x_1, a(y_1) ] + [ x_1, b(y_2) ] , \\
		c( [x_1, y_1] ) + d( [x_2, y_2] )
		&=
		[ c(x_1), y_2 ] + [ d(x_2), y_2 ] + [ x_2, c(y_1) ] + [ x_2, d(y_2) ]
	\end{align*}
	for all~$x_1, y_1 \in \glie$ and all~$x_2, y_2 \in \hlie$.
	By considering some special cases we can split up these conditions.
	\begin{itemize}
		\item
			If both~$x_2$ and~$y_2$ vanish then we need for all~$x_1, y_1 \in \glie$ that
			\[
				a( [x_1, y_1] )
				=
				[a(x_1), y_1] + [x_1, a(y_1)] \,,
				\qquad
				c( [x_1, y_1] )
				=
				0 \,.
			\]
		\item
			If both~$x_2$ and~$y_1$ vanish then we need for all~$x_1 \in \glie$ and~$y_2 \in \hlie$ that
			\[
				0
				=
				[ x_1, b(y_2) ] \,,
				\qquad
				0
				=
				[ c(x_1), y_2 ] \,.
			\]
		\item
			If both~$x_1$ and~$y_2$ vanish then we need for all~$x_2 \in \glie$ and~$y \in \hlie$ that
			\[
				0
				=
				[ b(x_2), y_1 ] \,,
				\qquad
				0
				=
				[ x_2, c(y_1) ] \,.
			\]
		\item
			If both~$x_1$ and~$y_1$ vanish then we need for all~$x_2, y_2 \in \ hlie$ that
			\[
				b( [x_2, y_2] )
				=
				0 \,,
				\qquad
				d( [x_2, y_2] )
				=
				[ d(x_2), y_2 ] + [ x_2, d(y_2) ] \,.
			\]
	\end{itemize}
	We find from these special cases that the linear endomorphism~$\delta$ of~$\glie \oplus \hlie$ is a derivation of~$\glie \oplus \hlie$ if and only if the matrix entries~$a$,~$b$,~$c$,~$d$ satisfy the conditions
	\begin{align*}
		a( [x_1, x_2] ) &= [ a(x_1), x_2 ] + [ x_1, a(x_2) ] \,\\
		d( [x_2, y_2] ) &= [ d(y_1), y_2 ] + [ y_1, d(y_2) ] \,\\
		b( [x_2, y_2] ) &= 0 \,, \\
		[ b(x_2), y_1]  &= 0 \,, \\
		[ x_1, b(y_2) ] &= 0 \,, \\
		c( [x_1, y_1] ) &= 0 \,, \\
		[ c(x_1), y_2 ) &= 0 \,, \\
		[ x_2, c(y_1) ] &= 0
	\end{align*}
	for all~$x_1, y_1 \in \glie$,~$x_2, y_2 \in \hlie$.
	The first condition tells us that~$a$ needs to be a derivations of~$\glie$ and the second condition tells us that~$d$ needs to be a derivation of~$\hlie$.
	The next three conditions tell us that~$b$ needs to take values in the center of~$\glie$ and needs to vanish on the commutator ideal~$[\hlie, \hlie]$.
	This means that~$b$ needs to be a homomorphism of Lie~algebras from~$\hlie$ to~$\centerlie(\glie)$.
	The last three conditions tell us in the same way that~$c$ needs to be a homomorphism of Lie~algebras from~$\glie$ to~$\centerlie(\hlie)$.

	We have now seen the following:
	We can identify the Lie~bracket of~$\gllie( \glie \oplus \hlie)$ as a vector space with
	\[
		\left\{
			\begin{pmatrix}
				a & b \\
				c & d
			\end{pmatrix}
		\suchthat*
			\begin{aligned}
				a &\in \Hom_{\kf}(\glie, \glie),  \\
				b &\in \Hom_{\kf}(\hlie, \glie),  \\
				c &\in \Hom_{\kf}(\glie, \hlie),  \\
				d &\in \Hom_{\kf}(\hlie, \hlie)   \\
			\end{aligned}
		\right\} \,.
	\]
	The commutator bracket of~$\gllie( \glie \oplus \hlie )$ corresponds under this description to the usual commutator bracket of matrices.
	The Lie~subalgebra~$\Der(\glie \oplus \hlie)$ of~$\gllie( \glie \oplus \hlie )$ corresponds to the linear subspace (and thus Lie~subalgebra)
	\[
		\left\{
			\begin{pmatrix}
				a & b \\
				c & d
			\end{pmatrix}
		\suchthat*
			\begin{aligned}
				a &\in \Der(\glie),                           \\
				b &\in \Hom_{\Lie}(\hlie, \centerlie(\glie)), \\
				c &\in \Hom_{\Lie}(\glie, \centerlie(\hlie)), \\
				d &\in \Der(\hlie)
			\end{aligned}
		\right\} \,.
	\]
\end{example}


\begin{remark}
	\index{derivation!of a direct sum}
	One can generalize~\cref{derivations of direct sum} to any finite direct sum~$\glie_1 \oplus \dotsb \oplus \glie_n$ of~\liealgebras{$\kf$}~$\glie_1, \dotsc, \glie_n$.
	One finds from the above discussion by induction over~$n$ that under the identification of~$\gllie( \glie_1 \oplus \dotsb \oplus \glie_n )$ with
	\[
		\left\{
			\begin{pmatrix}
				a_{11}  & \cdots  & a_{1n}  \\
				\vdots  & \ddots  & \vdots  \\
				a_{n1}  & \cdots  & a_{nn}
			\end{pmatrix}
		\suchthat*
			a_{ij} \in \Hom_{\kf}( \glie_j, \glie_i )
		\right\}
	\]
	the Lie~subalgebra~$\Der(\glie_1 \oplus \dotsb \oplus \glie_n)$ corresponds to the Lie~subgalgebra
	\[
		\left\{
			\begin{pmatrix}
				a_{11}  & \cdots  & a_{1n}  \\
				\vdots  & \ddots  & \vdots  \\
				a_{n1}  & \cdots  & a_{nn}
			\end{pmatrix}
		\suchthat*
			\begin{tabular}{@{}l@{}}
				$a_{ii} \in \Der(\glie_i)$ for all~$1 = 1, \dotsc, n$, \\
				$a_{ij} \in \Hom_{\Lie}(\glie_j, \centerlie(\glie_i))$ whenever~$i \neq j$
			\end{tabular}
		\right\} \,.
	\]
\end{remark}


\begin{lemma}
	\label{about the kernel of a derivation}
	Let~$A$ be an~\enquote{\algebra{$\kf$}} and let~$\delta$ be a derivation of~$A$.
	\begin{enumerate}
		\item
			If~$A$ is unital then~$\delta(1) = 0$.
		\item
			The set~$A' \defined \{ a \in A \suchthat \delta(a) = 0 \}$ is a subalgebra of~$A$.
			If~$A$ is unital then~$A'$ is a unital subalgebra, in the sense that~$1 \in A'$.
	\end{enumerate}
\end{lemma}


\begin{proof}
	\leavevmode
	\begin{enumerate}
		\item
			It follows from the identity~$1 = 1 \cdot 1$ that
			\[
				\delta(1)
				=
				\delta(1 \cdot 1)
				=
				\delta(1) \cdot 1 + 1 \cdot \delta(1)
				=
				\delta(1) + \delta(1) \,.
			\]
			By subtracting the term~$\delta(1)$ from both sides of this equation we find that~$\delta(1) = 0$.
		\item
			The set~$A'$ is a linear subspace of the algebra~$A$ because the derivation~$\delta$ is~\linear{$\kf$}.
			It holds for all~$a, b \in A'$ that
			\[
				\delta(ab)
				=
				\delta(a) b + a \delta(b)
				=
				0 \cdot b + a \cdot 0
				=
				0 \,,
			\]
			and thus~$ab \in A'$.
			If~$A$ is unital then it follows from the previous assertion that~$\delta(1) = 0$ and thus~$1 \in A'$.
		\qedhere
	\end{enumerate}
\end{proof}


\begin{proposition}
	\label{dervation is uniquely determined by algebra generators}
	Let~$A$ be a~\algebra{$\kf$} and let~$\delta_1$ and~$\delta_2$ be two derivations of~$A$.
	Let~$X$ be an algebra generating set of~$A$ and suppose that~$\delta_1(x) = \delta_2(x)$ for every element~$x$ of~$X$.
	Then already~$\delta_1 = \delta_2$.
\end{proposition}


\begin{proof}
	The difference~$\delta \defined \delta_1 - \delta_2$ is again a derivation of~$A$.
	It follows from \cref{about the kernel of a derivation} that the set
	\[
		A'
		\defined
		\{
			a \in A
		\suchthat
			\delta_1(a) = \delta_2(a)
		\}
		=
		\{
			a \in A
		\suchthat
			\delta(a) = 0
		\}
	\]
	is a subalgebra of~$A$.
	This subalgebra contains by assumption the algebra generating set~$X$ of~$A$.
	This means that~$A' = A$ and thus~$\delta_1 = \delta_2$.
\end{proof}


\begin{example}[Derivations of a polynomial algebra]
	\index{derivation!of polynomial algebra}
	\label{derivations of commutative polynomial algebra}
	We consider the commutative~\algebra{$\kf$}
	\[
		A \defined \kf[x_1, \dotsc, x_n] \,.
	\]
	The partial derivative function
	\[
		\dd{x_i}
		\colon
		A
		\to
		A
	\]
	with~$i = 1, \dotsc, n$ satisfy the product rule
	\[
		\dd[(fg)]{x_i}
		=
		\dd[f]{x_i} g + f \dd[g]{x_i}
		\qquad
		\text{for all~$f, g \in A$},
	\]
	which means that each partial derivative function~$\dd{x_i}$ is a derivation of~$A$.
	It follows from \cref{derivations made explicit} that for all polynomials~$f_1, \dotsc, f_n$ the~\linear{$A$} combination
	\[
		\delta
		\defined
		f_1 \dd{x_1} + \dotsb + f_n \dd{x_n}
	\]
	is again a derivation of~$A$.
	We note that this derivation~$\delta$ is given on the algebra generators~$x_1, \dotsc, x_n$ of~$A$ by
	\[
		\delta(x_i)
		=
		\sum_{j=1}^n f_j \dd[x_i]{x_j}
		=
		\sum_{j=1}^n f_j \delta_{ij}
		=
		f_i
	\]
	for all~$i = 1, \dotsc, n$.
	This shows in particular that the polynomials~$f_1, \dotsc, f_n$ are uniquely determined by the derivation~$\delta$, from which it follows that the derivations~$\dd{x_1}, \dotsc, \dd{x_n}$ are linearly independent over~$A$.

	Suppose now that~$\delta$ is any derivation of~$A$.
	For all~$i = 1, \dotsc, n$ let
	\[
		f_i \defined \delta(x_i) \,,
	\]
	and let overall~$\delta'$ be the derivation of~$A$ given by
	\[
		\delta'
		\defined
		f_1 \dd{x_1} + \dotsb + f_n \dd{x_n} \,.
	\]
	It follows from the above calculations that
	\[
		\delta'(x_i) = f_i = \delta(x_i)
		\qquad
		\text{for all~$i = 1, \dotsc, n$.}
	\]
	According to \cref{dervation is uniquely determined by algebra generators} this shows that~$\delta = \delta'$.
	We have thus shown that the derivations~$\dd{x_1}, \dotsc, \dd{x_n}$ form an~\generating{$A$} set of~$\Der(A)$.

	We have altogether shown that~$\Der(A)$ is free as an~\module{$A$} with basis given by the partial derivative functions~$\dd{x_1}, \dotsc, \dd{x_n}$.
\end{example}


\begin{proposition}
	\label{derivation on inverse}
	Let~$A$ be a~\algebra{$\kf$}, let~$\delta$ be a derivation of~$A$ and let~$a$ be a unit of~$A$.
	The value~$\delta(a^{-1})$ is uniquely determined by the value~$\delta(a)$.
\end{proposition}


\begin{proof}
	It follows from the identity~$1 = a \cdot a^{-1}$ that
	\[
		0
		=
		\delta(1)
		=
		\delta(a \cdot a^{-1})
		=
		\delta(a) a^{-1} + a \delta(a^{-1}) \,.
	\]
	and therefore~$\delta(a^{-1}) = - a^{-1} \delta(a) a^{-1}$.
\end{proof}


\begin{example}
	\index{derivation!of Laurent polynomial algebra}
	Thanks to \cref{derivation on inverse} we can generalize \cref{derivations of commutative polynomial algebra} to the algebra of Laurent~polynomials~$A \defined \kf[X_1, X_1^{-1}, \dotsc, X_n, X_n^{-1}]$.
	We find that~$\Der(A)$ is free as an~\module{$A$} with basis~$\dd{x_1}, \dotsc, \dd{x_n}$.
\end{example}


\begin{remark}
	For an~\algebra{$\kf$}~$A$ we consider the algebra derivations of~$A$ as well as the Lie~algebra derivations of~$A$.
	These two notions do not need to coincide.

	Every algebra dervation~$\delta$ of~$A$ is also a Lie~algebra derivation since we have
	\begin{align*}
		\delta([a,b])
		&=
		\delta(ab - ba)
		\\
		&=
		\delta(ab) - \delta(ba)
		\\
		&=
		( \delta(a) b + a \delta(b) ) - ( \delta(b) a + b \delta(a) )
		\\
		&=
		\delta(a) b - b \delta(a) + a \delta(b) - \delta(b) a
		\\
		&=
		[\delta(a), b] + [a, \delta(b)]
	\end{align*}
	for all~$a, b \in A$.

	But not every algebra derivation of~$A$ also needs to be a Lie~algebra derivation of~$A$.
	To see this, we can consider the case that~$A$ is commutative and nonzero.
	Then~$A$ is abelian as a Lie~algebra and thus every vector space endomorphism of~$A$ is already a Lie~algebra derivation of~$A$.
	But every algebra derivation~$\delta$ of~$A$ must satisfy the condition~$\delta(1) = 0$.
	So~$\delta = \id_A$ is a Lie~algebra derivation of~$A$ that is not an algebra derivation.
\end{remark}

\subsection{Inner Derivations}

\begin{proposition}
	\label{lie algebras act adjoint by derivations}
	
	Let~$\glie$ be a Lie~algebra and let~$x$ be an element of~$\glie$.
	The map
	\[
		\ad(x)
		\colon
		\glie
		\to
		\glie,
		\quad
		y
		\mapsto
		[x,y]
	\]
	is a derivation of~$\glie$.
\end{proposition}


\begin{proof}
	The map~$\ad(x)$ is linear by the bilinearity of the Lie~bracket of~$\glie$.
	It follows from the Jacobi~identity that
	\[
		\ad(x)([y,z])
		=
		[x,[y,z]]
		=
		[[x,y],z] + [y,[x,z]] \\
		=
		[\ad(x)(y), z] + [y, \ad(x)(z)]
	\]
	for all~$y,z \in \glie$.
\end{proof}


\begin{definition}
	\label{definition of inner derivations}
 Let~$\glie$ be a Lie~algebra.
 A derivation of~$\glie$ is \defemph{inner}\index{derivation!inner}\index{inner!derivation} if it is of the form~$\ad(x)$ for some element~$x$ of~$\glie$.
 The set of inner derivations of~$\glie$ is denoted by~$\InnDer(\glie)$.
\end{definition}


\begin{example}
	Let~$\glie$ be the non-abelian, two-dimensional Lie~algebra.
	Let~$x$,~$y$ be a basis of~$\glie$ such that~$[x,y] = y$.
	The space of inner derivations of~$\glie$ is spanned by the two derivations~$\delta_x = [x,-]$ and~$\delta_y = [y,-]$.
	These derivations are given by
	\[
		\delta_x(x) = 0 \,,
		\quad
		\delta_x(y) = y \,,
		\qquad
		\delta_y(x) = -y \,,
		\quad
		\delta_y(y) = 0 \,.
	\]
	We find from the calculation of~$\Der(\glie)$ in \cref{derivations of the two-dimensional non-abelian lie algebra} that~$\delta_x$ and~$\delta_y$ form a basis of~$\Der(\glie)$.
	This shows that every derivation of~$\glie$ is inner, and that the homomorphism of Lie~algebras~$\ad$ from~$\glie$ to~$\Der(\glie)$ is an isomorphism of Lie~algebras.
\end{example}


\begin{lemma}
	\label{commutator of any derivation and inner derivation}
	Let~$\glie$ be a Lie~algebra, let~$\delta$ be a derivation of~$\glie$ and let~$x$ be an element of~$\glie$.
	Then
	\[
		[\delta, \ad(x)] = \ad(\delta(x)) \,.
	\]
\end{lemma}


\begin{proof}
	We have
	\begin{align*}
		\SwapAboveDisplaySkip
		[\delta, \ad(x)](y)
		&= 
		( \delta \circ \ad(x) - \ad(x) \circ \delta )(y)
		\\
		&=
		\delta([x,y]) - [x,\delta(y)]
		\\
		&=
		[\delta(x),y] + [x,\delta(y)] - [x,\delta(y)]
		\\
		&=
		[\delta(x),y]
		\\
		&=
		\ad(\delta(x))(y)
	\end{align*}
	for all~$y \in \glie$, and thus~$[\delta, \ad(x)] = \ad(\delta(x))$.
\end{proof}


\begin{corollary}
	\label{inner derivations are an ideal}
	Let~$\glie$ be a Lie~algebra.
	The set of inner derivations of~$\glie$ is an ideal of~$\Der(\glie)$.
	It is denoted by~$\InnDer(\glie)$\glsadd{inner derivations}.
\end{corollary}


\begin{proof}
	It follows from the linearity of the map~$\ad$ from~$\glie$ to~$\gllie(\glie)$ that~$\InnDer(\glie)$ is a linear subspace of~$\gllie(\glie)$, and thus a linear subspace of~$\Der(\glie)$ by \cref{lie algebras act adjoint by derivations}.
	It follows from \cref{commutator of any derivation and inner derivation} that~$\InnDer(\glie)$ is already an ideal of~$\Der(\glie)$. 
\end{proof}


\begin{proposition}
	Let~$\glie$ be a Lie~algebra.
	The quotient Lie~algebra~$\glie/{\centerlie(\glie)}$ is isomorphic to the linear Lie~algebra~$\InnDer(\glie)$.
\end{proposition}


\begin{proof}
	The adjoint map~$\ad$ from~$\glie$ to~$\gllie(\glie)$ is a homomorphism of Lie~algebras that has~$\centerlie(\glie)$ as its kernel and~$\InnDer(\glie)$ as its image.
	The assertion therefore follows from the \hyperref[first isomorphism theorem]{first isomorphism theorem}.
\end{proof}


\begin{remark}
	Let~$\glie$ be a Lie~algebra.
	The Lie~subalgebra~$\InnDer(\glie)$ of~$\gllie(\glie)$ is the canonical way of associating a linear Lie~algebra to~$\glie$.
	We will see later that questions about the original Lie~algebra~$\glie$ can sometimes be reduced to a question about the linear Lie~algebra~$\InnDer(\glie)$, to whose elements we can apply linear algebra.
\end{remark}


\begin{definition}
	Let~$\glie$ be a Lie~algebra.
	The quotient Lie~algebra~$\Der(\glie) / {\InnDer(\glie)}$ is the Lie~algebra of \defemph{outer derivations}\index{derivation!outer}\index{outer!derivation} of~$\glie$.
	It is denoted by~$\OutDer(\glie)$\glsadd{outer derivations}.
\end{definition}


\begin{remark}
	If one thinks about Lie~algebras as \enquote{derived} versions of (Lie) groups, then derivations are derived versions of automorphisms, and inner derivations are derived versions of inner automorphisms.
	We can therefore extend the comparision between groups and Lie~algebras from \cref{on the notion of ideals} to \cref{correspondence between groups and lie algebras}.
	\begin{table}
		\centering
		\begin{tabular}{ll}
			\toprule
			group theory
			&
			Lie~algebra theory
			\\
			\midrule
			subgroup
			&
			Lie~subalgebra
			\\
			normal subgroup
			&
			Lie~ideal
			\\
			automorphism
			&
			derivation
			\\
			inner automorphism
			&
			inner derivations
			\\
			outer automorphism
			&
			outer derivation
			\\
			\bottomrule
		\end{tabular}
		\caption{Correspondence between group theory and Lie~algebra theory.}
		\label{correspondence between groups and lie algebras}
	\end{table}

	That the inner dervivations of a Lie~algebra~$\glie$ form an ideal of the Lie~algebra~$\Der(\glie)$ corresponds to the group theoretic statement that the inner automorphisms of a group~$G$ form a normal subgroup of the automorphism group~$\Aut(G)$.
	Moreover, the center of~$\glie$ is precisely the kernel of the Lie~algebra homomorphism~$\ad \colon \glie \to \Der(\glie)$, just the center of~$G$ is precisely the kernel of the group homomorphism~$G \to \Aut(G)$.
\end{remark}



\subsection{Inner Automorphisms}


\begin{recall}
	Let~$V$ be a~\vectorspace{$\kf$} where~$\kf$ is a field of characteristic zero.
	Let~$f$ be a nilpotent endomorphism of~$V$.
	Then its exponential\index{exponential}
	\[
		\exp(f)
		\defined
		\sum_{n=0}^\infty
		\frac{f^n}{n!}
		\label{exponential}
	\]
	is again a well-defined endomorphism of~$V$.
	If~$\alpha$ is an automorphism of~$V$ then the conjugate~$\alpha f \alpha^{-1}$ is again nilpotent, and the two resulting endomorphisms~$\exp(f)$ and~$\exp(\alpha f \alpha^{-1})$ are related via
	\[
		\exp( \alpha f \alpha^{-1} )
		=
		\sum_{n=0}^\infty
		\frac{ (\alpha f \alpha^{-1})^n }{n!}
		=
		\sum_{n=0}^\infty
		\frac{ \alpha f^n \alpha^{-1} }{n!}
		=
		\alpha
		\Biggl(
			\sum_{n=0}^\infty
			\frac{f^n}{n!}
		\Biggr)
		\alpha^{-1}
		=
		\alpha \exp(f) \alpha^{-1} \,.
	\]

	Let now~$g$ be another nilpotent endomorphism of~$V$ and suppose that the endomorphisms~$f$ and~$g$ commute.
	The sum~$f + g$ is then again nilpotent.
	To be more precise, we have
	\[
		(f + g)^n
		=
		\sum_{k=0}^n
		\binom{n}{k}
		f^k g^{n-k}
	\]
	for every natural exponent~$n$.
	If~$n'$ and~$n''$ are two natural exponents with
	\[
		f^{n'} = 0
		\quad\text{and}\quad
		g^{n''} = 0 \,,
	\]
	then by choosing the exponent~$n$ to be at least~$n' + n'' - 1$ we find that~$f^k = 0$ or~$g^{n-k} = 0$ for all~$k = 0, \dotsc, n$, and thus~$(f + g)^n = 0$.

	We can therefore also consider the endomorphism~$\exp(f + g)$, and it follows from the commutativity of the endomorphisms~$f$ and~$g$ that
	\begingroup
	\allowdisplaybreaks
	\begin{align*}
		\exp(f + g)
		&=
		\sum_{n=0}^\infty
		\frac{(f + g)^n}{n!}
		\\
		&=
		\sum_{n=0}^\infty
		\frac{1}{n!}
		\sum_{k=0}^n
		\binom{n}{k}
		f^k g^{n-k}
		\\
		&=
		\sum_{n=0}^\infty
		\sum_{k=0}^n
		\frac{f^k g^{n-k}}{k!(n-k)!}
		\\
		&=
		\sum_{n=0}^\infty
		\sum_{k + l = n}
		\frac{f^k g^l}{k! l!}
		\\
		&=
		\sum_{k, l = 0}^\infty
		\frac{f^k g^l}{k! l!}
		\\
		&=
		\Biggl(
			\sum_{k=0}^\infty
			\frac{f^k}{k!}
		\Biggr)
		\Biggl(
			\sum_{l=0}^\infty
			\frac{g^l}{l!}
		\Biggr)
		\\
		&=
		\exp(f) \exp(g) \,.
	\end{align*}
	\endgroup
	It follows in particular for~$g = -f$ that
	\[
		\exp(f) \exp(-f) = \exp(f - f) = \exp(0) = \id_V \,,
	\]
	and similarly that~$\exp(-f) \exp(f) = \id_V$.
	This shows that the endomorphism~$\exp(f)$ of~$V$ is already an automorphism of~$V$, with inverse gilen by~$\exp(-f)$.
\end{recall}


\begin{lemma}
	Let~$A$ be a~\enquote{\algebra{$\kf$}} and let~$\delta$ be a derivation of~$A$.
	Then
	\[
		\delta^n(ab)
		=
		\sum_{k=0}^n
		\binom{n}{k}
		\delta^k(a) \delta^{n-k}(b)
		\qquad
		\text{for all~$n \in \Natural$,~$a, b \in A$.}
	\]
\end{lemma}


\begin{proof}[First proof]
	We prove the formula by induction.
	It holds for~$n = 0$.
	If the formula holds for some exponent~$n$ then it also holds for the exponent~$n + 1$ because
	\begingroup
	\allowdisplaybreaks
	\begin{align*}
		\delta^{n+1}(ab)
		&=
		\delta( \delta^n(ab) )
		\\
		&=
		\delta
		\Biggl(
			\sum_{k=0}^n
			\binom{n}{k}
			\delta^k(a) \delta^{n-k}(b)
		\Biggr)
		\\
		&=
		\sum_{k=0}^n
		\binom{n}{k}
		\delta
		\bigl(
			\delta^k(a) \delta^{n-k}(b)
		\bigr)
		\\
		&=
		\sum_{k=0}^n
		\binom{n}{k}
		\bigl(
			\delta^{k+1}(a) \delta^{n-k}(b)
			+
			\delta^k(a) \delta^{n+1-k}(b)
		\bigr)
		\\
		&=
		\sum_{k=0}^n
		\binom{n}{k}
		\delta^{k+1}(a) \delta^{n-k}(b)
		+
		\sum_{k=0}^n
		\binom{n}{k}
		\delta^k(a) \delta^{n+1-k}(b)
		\\
		&=
		\sum_{k=1}^{n+1}
		\binom{n}{k-1}
		\delta^{k}(a) \delta^{n+1-k}(b)
		+
		\sum_{k=0}^n
		\binom{n}{k}
		\delta^k(a) \delta^{n+1-k}(b)
		\\
		&=
		\delta^{n+1}(a) b
		+
		\sum_{k=1}^n
		\binom{n}{k-1}
		\delta^{k}(a) \delta^{n+1-k}(b)
		+
		\sum_{k=1}^n
		\binom{n}{k}
		\delta^k(a) \delta^{n+1-k}(b)
		+
		a \delta^{n+1}(b)
		\\
		&=
		\delta^{n+1}(a) b
		+
		\sum_{k=1}^n
		\Biggl(
			\binom{n}{k-1}
			+
			\binom{n}{k}
		\Biggr)
		\delta^k(a) \delta^{n+1-k}(b)
		+
		a \delta^{n+1}(b)
		\\
		&=
		\delta^{n+1}(a) b
		+
		\sum_{k=1}^n
		\binom{n+1}{k}
		\delta^k(a) \delta^{n+1-k}(b)
		+
		a \delta^{n+1}(b)
		\\
		&=
		\sum_{k=0}^{n+1}
		\binom{n+1}{k}
		\delta^k(a) \delta^{n+1-k}(b)
	\end{align*}
	\endgroup
	for all~$a, b \in A$.
\end{proof}


\begin{proof}[Second proof]
	Let
	\[
		m
		\colon
		A \tensor A
		\to
		A \,,
		\quad
		a \tensor b
		\mapsto
		ab
	\]
	be the multiplication map of~$A$.
	That~$\delta$ is a derivation of~$A$ means that
	\[
		\delta \circ m
		=
		m \circ (\delta \tensor \id + \id \tensor \delta) \,.
	\]
	The endomorphism~$\delta \tensor \id$ and~$\id \tensor \delta$ of~$A \tensor A$ commute.
	It follows inductively that
	\begin{align*}
		\delta^n \circ m
		&=
		m \circ (\delta \tensor \id + \id \tensor \delta)^n
		\\
		&=
		m \circ \sum_{k=0}^n \binom{n}{k} (\delta \tensor \id)^k (\id \tensor \delta)^{n-k}
		\\
		&=
		m \circ \sum_{k=0}^n \binom{n}{k} (\delta^k \tensor \id) (\id \tensor \delta^{n-k})
		\\
		&=
		m \circ \sum_{k=0}^n \binom{n}{k} \delta^k \tensor \delta^{n-k}
		\\
		&=
		\sum_{k=0}^n \binom{n}{k} m \circ (\delta^k \tensor \delta^{n-k}) \,.
	\end{align*}
	It follows that
	\[
		\delta^n( ab )
		=
		(\delta^n \circ m)(a \tensor b)
		=
		\biggl( \sum_{k=0}^n m \circ \delta^k \tensor \delta^{n-k} \biggr)(a \tensor b)
		=
		\sum_{k=0}^n \binom{n}{k} \delta^k(a) \delta^{n-k}(b)
	\]
	for all~$a, b \in A$.
\end{proof}


\begin{proposition}
	\label{exponential of derivation is automorphism}
	Let~$A$ be a~\enquote{\algebra{$\kf$}} where~$\kf$ is a field of characteristic zero and let~$\delta$ be a nilpotent derivation of~$A$.
	Then~$\exp(\delta)$ is an algebra automorphism of~$A$.
\end{proposition}


\begin{proof}
	Let~$\alpha$ be~$\exp(\delta)$.
	We have for any two element~$a$,~$b$ of~$A$ that
	\begingroup
	\allowdisplaybreaks
	\begin{align*}
		\alpha(ab)
		&=
		\sum_{n=0}^\infty
		\frac{\delta^n}{n!}(ab)
		\\
		&=
		\sum_{n=0}^\infty
		\frac{1}{n!}
		\delta^n(ab)
		\\
		&=
		\sum_{n=0}^\infty
		\frac{1}{n!}
		\sum_{k=0}^n
		\binom{n}{k}
		\delta^k(a) \delta^{n-k}(b)
		\\
		&=
		\sum_{n=0}^\infty
		\sum_{k=0}^n
		\frac{\delta^k(a) \delta^{n-k}(b)}{k! (n-k)!}
		\\
		&=
		\sum_{n=0}^\infty
		\sum_{k+l=n}
		\frac{\delta^k(a) \delta^{n-k}(b)}{k! l!}
		\\
		&=
		\sum_{k,l = 0}^\infty
		\frac{\delta^k(a) \delta^{n-k}(b)}{k! l!}
		\\
		&=
		\Biggl(
			\sum_{k=0}^\infty
			\frac{\delta^k(a)}{k!}
		\Biggr)
		\Biggl(
			\sum_{l=0}^\infty
			\frac{\delta^l(b)}{l!}
		\Biggr)
		\\
		&=
		\Biggl(
			\sum_{k=0}^\infty
			\frac{\delta^k}{k!}
		\Biggr)
		(a)
		\Biggl(
			\sum_{l=0}^\infty
			\frac{\delta^l}{l!}
		\Biggr)
		(b)
		\\
		&=
		\alpha(a) \alpha(b) \,. 
	\end{align*}
	\endgroup
	This shows that~$\alpha$ preserves multiplication.
	It is also a vector space automorphism.
	Together this shows that~$\alpha$ is an algebra automorphism.
\end{proof}


\begin{corollary}
	Let~$\glie$ be a~\liealgebra{$\kf$} where~$\kf$ is a field of characteristic zero.
	Let~$x$ be an element of~$\glie$ such that~$\ad(x)$ is nilpotent.
	Then~$\exp(\ad(x))$ is a Lie~algebra automorphism of~$\glie$.
\end{corollary}


\begin{proof}
	We have seen in \cref{lie algebras act adjoint by derivations} that~$\ad(x)$ is a derivation of~$\glie$.
	The assertion thus follows from \cref{exponential of derivation is automorphism}.
\end{proof}


\begin{definition}
	Let~$\glie$ be a~\liealgebra{$\kf$} where~$\kf$ is a field of characteristic zero.
	\begin{enumerate}
		\item
			The group of Lie~algebra automorphisms of~$\glie$ is denoted by~$\Aut(\glie)$\glsadd{automorphisms}.
		\item
			The \defemph{group of inner automorphisms} of~$\glie$ is the subgroup of~$\Aut(\glie)$ that is generated by all automorphism of the form~$\exp(\ad(x))$ where~$x$ is any element of~$\glie$ for which~$\ad(x)$ is nilpotent.
			The group of inner automorphisms of~$\glie$ is denoted by~$\InnAut(\glie)$\glsadd{inner automorphisms}.
		\item
			The elements of~$\InnAut(\glie)$ are the \defemph{inner automorphisms}\index{automorphism!inner}\index{inner!automorphism} of~$\glie$.
	\end{enumerate}
\end{definition}


\begin{lemma}
	\label{adjoint and automorphisms}
	Let~$\glie$ be a Lie~algebra.
	Let~$x$ be any element of~$\glie$ and let~$\alpha$ be an automorphism of~$\glie$.
	Then
	\[
		\ad(\alpha(x))
		=
		\alpha \circ \ad(x) \circ \alpha^{-1} \,.
	\]
\end{lemma}


\begin{proof}
	We have for every element~$y$ of~$\glie$ that
	\[
		\ad(\alpha(x))(\alpha(y))
		=
		[\alpha(x), \alpha(y)]
		=
		\alpha( [x,y] )
		=
		\alpha( \ad(x)(y) ) \,,
	\]
	and therefore overall
	\[
		\ad(\alpha(x)) \circ \alpha
		=
		\alpha \circ \ad(x) \,.
	\]
	Composing both sides of this equation with~$\alpha^{-1}$ from the right proves the assertion.
\end{proof}


\begin{lemma}
	\label{conjugation of inner automorphism}
	Let~$\glie$ be a~\liealgebra{$\kf$} where~$\kf$ is a field of characteristic zero.
	Let~$x$ be an element of~$\glie$ for which~$\ad(x)$ is nilpotent, and let~$\alpha$ be any automorphism of~$\glie$.
	Then~$\ad(\alpha(x))$ is again nilpotent and
	\[
		\alpha \circ \exp(\ad(x)) \circ \alpha^{-1}
		=
		\exp( \alpha(x) ) \,.
	\]
\end{lemma}


\begin{proof}
	It follows from \cref{adjoint and automorphisms} that the endomorphism~$\ad(\alpha(x)) = \alpha \circ \ad(x) \circ \alpha^{-1}$ is a conjugate of the nilpotent endomorphism~$\ad(x)$, and thus again nilpotent.
	We also find that
	\[
		\exp( \ad(\alpha(x)) )
		=
		\exp\bigl( \alpha \circ \ad(x) \circ \alpha^{-1} \bigr)
		=
		\alpha \circ \exp(\ad(x)) \circ \alpha^{-1} \,,
	\]
	as desired.
\end{proof}


\begin{proposition}
	Let~$\glie$ be a~\liealgebra{$\kf$} where~$\kf$ is a field of characteristic zero.
	Then the subgroup~$\InnAut(\glie)$ of~$\Aut(\glie)$ is a normal.
\end{proposition}


\begin{proof}
	The group~$\InnAut(\glie)$ is generated by the set of automorphisms
	\[
		\{
			\exp(\ad(x))
		\suchthat
			\text{$x \in \glie$ such that~$\ad(x)$ is nilpotent}
		\} \,.
	\]
	It follows from \cref{conjugation of inner automorphism} that this generating set is closed under the conjugation by any automorphism of~$\glie$.
	It follows that~$\InnAut(\glie)$ is also closed under conjugation.
\end{proof}


\begin{definition}
	Let~$\glie$ be a~\liealgebra{$\kf$} where~$\kf$ is a field of characteristic zero.
	The quotient group~$\Aut(\glie) / {\InnAut(\glie)}$ is the \defemph{group of outer automorphisms} of~$\glie$.
	It is denoted by~$\OutAut(\glie)$\glsadd{outer automorphisms}.
	The elements of~$\OutAut(\glie)$ are the \defemph{outer automorphisms}\index{automorphism!outer}\index{outer!automorphism} of~$\glie$.
\end{definition}





